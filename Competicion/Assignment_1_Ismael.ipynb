{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:49:08.174519Z",
          "start_time": "2020-03-31T13:49:08.165989Z"
        },
        "id": "gpbvNOH0zvIi"
      },
      "source": [
        "# **Competencia 1 - CC6205 Natural Language Processing 游닄**\n",
        "\n",
        "Departamento de Ciencias de la Computaci칩n, Universidad de Chile.\n",
        "\n",
        "CC6205: Procesamiento de Lenguaje Natural - Oto침o 2023\n",
        "\n",
        "**Integrantes:** [inserten sus nombres aqu칤]\n",
        "\n",
        "**Usuario del equipo en CodaLab:** [inserten su usuario aqu칤]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxlNrNf_p0ZY"
      },
      "source": [
        "## **Objetivo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrtvsKf2p3A4"
      },
      "source": [
        "En esta tarea grupal participar치n de una competencia al estilo [Kaggle](https://www.kaggle.com/) pero utilizando la p치gina [CodaLab](https://codalab.org/). El objetivo de la competencia es predecir si un texto contiene discurso de odio, incivilidad o es un texto normal.\n",
        "\n",
        "El discurso de odio es cualquier expresi칩n que promueva o incite a la discriminaci칩n, la hostilidad o la violencia hacia una persona o grupo de personas en una relaci칩n asim칠trica de poder, tal como la raza, la etnia, el g칠nero, la orientaci칩n sexual, la religi칩n, la nacionalidad, una discapacidad u otra caracter칤stica similar.\n",
        "\n",
        "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortes칤a y consideraci칩n en la interacci칩n entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
        "\n",
        "En esta competencia tendr치n a su disposici칩n un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en espa침ol de Chile. Con estos datos, deber치n entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
        "\n",
        "El corpus para esta tarea se compone de 3 datasets:  \n",
        "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
        "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
        "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
        "\n",
        "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabi치n Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computaci칩n, Universidad de Chile. \n",
        "\n",
        "Los datos solo pueden ser usados con fines de investigaci칩n y docencia. Est치 prohibida la difusi칩n externa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6lhhfl2zvIk"
      },
      "source": [
        "## **Instrucciones**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T14:34:38.796217Z",
          "start_time": "2020-04-07T14:34:38.782255Z"
        },
        "id": "7wTyult1zvIl"
      },
      "source": [
        "- La competencia consiste en resolver el problema de clasificaci칩n presentado. La evaluaci칩n de la competencia se realiza en base a 3 m칠tricas: `AUC`, `Kappa` y `Accuracy`. Los mejores puntajes en cada una de estas m칠tricas ser치n quienes ganen la competencia.\n",
        "\n",
        "- Para comenzar se les entregar치 en este notebook la estructura del informe a entregar y el c칩digo de un baseline con el cu치l pueden comparar los resultados de sus experimentos. Este baseline consiste en la creaci칩n de features y una clasificaci칩n simple siguiendo el paradigma de Machine Learning emp칤rico. Los puntajes obtenidos por el baseline los pueden visualizar en el link de CodaLab buscando al usuario **cc6205**. Esperamos que los superen f치cilmente 游땔\n",
        "\n",
        "- Para participar, deben registrarse en CodaLab y luego ingresar a la competencia usando el enlace que ser치 provisto a trav칠s de U-Cursos.\n",
        "\n",
        "- Est치 permitido hacer grupos de m치ximo 4 alumnos. Cada grupo debe tener un nombre de equipo, para ello en CodaLab pueden dirigirse a settings y luego cambiar el Team Name. S칩lo una persona debe administrar la cuenta del grupo y se verificar치 que no se hayan creado m칰ltiples cuentas por grupo.\n",
        "\n",
        "- En total pueden hacer un **m치ximo de 5 submissions**, hagan muchos experimentos probando en el conjunto de test antes de realizar el env칤o.\n",
        "\n",
        "- Es importante que hagan varios experimentos incorporando t칠cnicas como [cross-validation](https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada#:~:text=La%20validaci%C3%B3n%20cruzada%20o%20cross,datos%20de%20entrenamiento%20y%20prueba.), [random sampling](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c) o [bayesian optimization](https://optuna.org/) antes de enviar sus predicciones a CodaLab, ya que les puede dar un mejor indicio del nivel de generalizaci칩n de sus modelos.\n",
        "\n",
        "- Aseg칰rense de que la distribuci칩n de las clases se mantenga en las particiones de training y testing.\n",
        "\n",
        "- Verificar que el formato de la submission coincida con el de la competencia. De lo contrario, se les ser치 evaluado incorrectamente ya que el Script de evaluaci칩n espera como input dicho formato. En el c칩digo de las m칠tricas pueden verificar c칩mo son los inputs.\n",
        "\n",
        "- No se limiten a los contenidos vistos ni a scikit ni a este baseline. No tienen restricciones entre utilizar Deep Learning o Machine Learning emp칤rico. Si reutilizan gran cantidad de c칩digo de alguna p치gina por favor mostrar la referencia en su c칩digo. 춰Usen todo su conocimiento e ingenio en mejorar sus sistemas para poder ganar la competencia!\n",
        "\n",
        "- **Es requisito entregar el reporte con el c칩digo y haber participado en la competencia para ser evaluado. Un c칩digo sin reporte o un reporte sin c칩digo ser치n evaluados con la nota m칤nima.**\n",
        "\n",
        "- Todas las dudas escr칤banlas en el canal de Discord de competencias. Los emails que lleguen al equipo docente ser치n remitidos a ese medio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:25:19.677190Z",
          "start_time": "2020-04-07T15:25:19.671206Z"
        },
        "id": "jiDISxa-zvIn"
      },
      "source": [
        "**Importante**: Recuerden poner su nombre y el de su usuario o de equipo (en caso de que aplique) en el reporte. NO ser치n evaluados Notebooks sin nombre.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igf7TBfSzvIo"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6moqxkEwCe-"
      },
      "source": [
        "## **Reporte a entregar**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo7vfXV4wD8s"
      },
      "source": [
        "Uno de los puntos claves en la evaluaci칩n de esta competencia es elaborar un informe claro y preciso, argumentando las decisiones tomadas al momento de crear sus modelos para que el cuerpo docente pueda entenderlos. La estructura que debe contener es la siguiente:\n",
        "\n",
        "1. **Introducci칩n**: Presentar brevemente el problema a resolver, incluyendo la formalizaci칩n de la task (c칩mo son los inputs y outputs del problema) y los desaf칤os que ven al analizar el corpus entregado. (**0.5 puntos**)\n",
        "2. **Representaciones**: Describir los atributos y representaciones usadas como entrada de los clasificadores, **recordar** que para entrenar modelos el input debe tener su representaci칩n num칠rica. Si bien, con Bag of Words (**baseline**) ya se comienzan a percibir buenos resultados, pueden mejorar su evaluaci칩n agregando m치s atributos y representaciones dise침adas a mano, sean lo m치s creativos posible. M치s abajo encontrar치n una lista de estos posibles atributos que les podr치 ser de utilidad. (**1 punto**)\n",
        "3. **Algoritmos**: Describir **brevemente** los algoritmos de clasificaci칩n usados, tanto si fueron algoritmos ya vistos en clases o bien arquitecturas de Deep Learning. (**0.5 puntos**)\n",
        "4. **M칠tricas de evaluaci칩n**: Describir brevemente las m칠tricas utilizadas en la evaluaci칩n, indicando qu칠 miden y su interpretaci칩n. (**0.5 puntos**)\n",
        "\n",
        "5. **Dise침o experimental**: Esta es una de las secciones m치s importantes del reporte. Deben describir minuciosamente los experimentos que realizar치n en la siguiente secci칩n. Describir las variables de control que manejar치n, algunos ejemplos pueden ser: Los par치metros de los clasificadores, par치metros en las funciones con que procesan los textos y los transforman, par치metros para el cross-validation, particiones de datos utilizadas, etc. En caso que utilicen redes neuronales, ser claros con el conjunto de hiperpar치metros que probar치n, la decisi칩n en las funciones de optimizaci칩n, funci칩n de p칠rdida, regulaci칩n, etc. B치sicamente explicar qu칠 es lo que veremos en la siguiente secci칩n.\n",
        "   (**1 punto**)\n",
        "\n",
        "6. **Experimentos**: Incluyan todo el c칩digo de sus experimentos aqu칤. 춰Es vital haber realizado varios experimentos para sacar una buena nota! (**1.5 puntos**)\n",
        "\n",
        "7. **Resultados**: Comparar los resultados obtenidos utilizando diferentes algoritmos y representaciones. Pueden mostrar los resultados sobre la partici칩n de validaci칩n en caso que la generen o sobre los resultados del conjunto de testing. Mostrar los resultados en alguna tabla, pueden poner aqu칤 tambi칠n los resultados obtenidos al realizar la submission. (**0.5 puntos**)\n",
        "\n",
        "8. **Conclusiones**: Discutir resultados, proponer trabajo futuro. (**0.5 puntos**)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMSn_tDYwOb1"
      },
      "source": [
        "## **Descripci칩n Baseline**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-21T19:18:43.301002Z",
          "start_time": "2019-08-21T19:18:43.298037Z"
        },
        "id": "30fPWG5pzvIm"
      },
      "source": [
        "El baseline de la secci칩n **Experimentos** contiene un c칩digo b치sico que resuelve la task y es el modelo subido por **cc6205-baseline** a la competencia. Pueden modificar el c칩digo como quieran siempre y cuando no cambien las funciones de las m칠tricas y el formato en que se suben los archivos a la competencia, ya que ese es el formato en que realizamos la evaluaci칩n. En concretro, el baseline hace lo siguiente:\n",
        "\n",
        "- Obtiene los datasets desde el repositorio del curso.\n",
        "- Divide los datasets en train (datos que est치n etiquetados) y target set (datos no etiquetados para la competencia). Adem치s, por cada dataset en train, se divide en un conjunto de entrenamiento y uno de prueba. Aqu칤 la mejor pr치ctica ser칤a cambiar el c칩digo para obtener un conjunto de entrenamiento, validaci칩n y prueba.\n",
        "\n",
        "- Crea un Pipeline que:\n",
        "  - Crea features personalizados para la representaci칩n num칠rica.\n",
        "  - Transforma los dataset a bag of words (BoW).\n",
        "  - Entrena un clasificador usando cada train set.\n",
        "- Clasifica y evalua el sistema creado usando el test set.\n",
        "- Clasifica el target set.\n",
        "- Genera una submission con el target en formato zip en el directorio en donde se est치 ejecutando el notebook.\n",
        "\n",
        "Algunas pistas sobre como mejorar el rendimiento de los sistemas que creen. (Esto tendr치 mas sentido cuando vean el c칩digo)\n",
        "\n",
        "- **Datos**: Pueden utilizar t칠cnicas de preprocesamiento y data augmentation para mejorar sus resultados. Algunos paquetes 칰tiles para ello son:\n",
        "\n",
        "  - [nlpaug](https://github.com/makcedward/nlpaug)\n",
        "  - [spanish_nlp](https://github.com/jorgeortizfuentes/spanish_nlp)\n",
        "  - [spacy](https://spacy.io/usage/spacy-101)\n",
        "\n",
        "- **Vectorizador**: Investigar los modulos de `nltk`, en particular, `TweetTokenizer`, `mark_negation` para reemplazar los tokenizadores. Tambi칠n, el par치metro `ngram_range` (Ojo que el clf naive bayes no deber칤a usarse con n-gramas, ya que rompe el supuesto de independencia). Adem치s, implementar los atributos que crean 칰tiles desde el listado del enunciado. Investigar tambi칠n el vectorizador tf-idf.\n",
        "\n",
        "- **Clasificador**: Investigar otros clasificadores m치s efectivos que Naive Bayes. Estos deben poder retornar la probabilidad de pertenecia de las clases (ie: implementar la funci칩n `predict_proba`). Algunos clasificadores que pueden probar son:\n",
        "\n",
        "  - SVM\n",
        "  - Random Forest\n",
        "  - XGBoost\n",
        "  - Redes Neuronales (MLP)\n",
        "\n",
        "- **Features**: Recuerden que pueden implementar todas las features que se les ocurra! Aqu칤 les adjuntamos algunos ejemplos:\n",
        "\n",
        "  - N-gramas de palabras.\n",
        "  - N-gramas de caracteres.\n",
        "  - Part-of-speech tags.\n",
        "  - Lexicones de sentimiento (Lexicon = Conjunto de palabras con una etiqueta o valor asociado).\n",
        "    - Cuenta el n칰mero de palabras positivas y negativas dentro de una frase.\n",
        "    - Si el l칠xico tiene asociada la intensidad del sentimiento (por ejemplo, en un decimal), saque la media de la intensidad de la frase seg칰n el sentimiento, la suma, etc.\n",
        "    - Pueden encontrar un lexicon en [este siguiente enlace](https://github.com/kicorangel/RD-Lab/tree/master/resources/Afffectivity/Spanish%20Opinion%20Lexicon)\n",
        "  - El n칰mero de palabras alargadas (palabras con un car치cter repetido m치s de dos veces).\n",
        "  - El n칰mero de palabras con todos los caracteres en may칰sculas.\n",
        "  - La presencia y el n칰mero de emoticonos positivos o negativos.\n",
        "  - El n칰mero de negaciones individuales.\n",
        "  - El n칰mero de secuencias contiguas de puntos, signos de interrogaci칩n y exclamaci칩n.\n",
        "  - Word Embeddings: Aqu칤 tienen algunos modelos preentrenados para vectorizar los textos.\n",
        "    - [Spanish Word Embeddings](https://github.com/dccuchile/spanish-word-embeddings)\n",
        "    - [Sentence BERT](https://www.sbert.net/docs/quickstart.html)\n",
        "\n",
        "- **Reducci칩n de dimensionalidad**: Tambi칠n puede serles de ayuda. Referencias [aqu칤](https://scikit-learn.org/stable/modules/unsupervised_reduction.html).\n",
        "\n",
        "- Por 칰ltimo, pueden encontrar mas referencias de c칩mo mejorar sus features, el vectorizador y el clasificador [aqu칤](https://affectivetweets.cms.waikato.ac.nz/benchmark/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT7ZpVRuzGAF"
      },
      "source": [
        "# **Entregable.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:34:25.683540Z",
          "start_time": "2020-03-31T13:34:25.673430Z"
        },
        "id": "E29LEMZ9zvIo"
      },
      "source": [
        "## **1. Introducci칩n**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W20NnoduzvIo"
      },
      "source": [
        "    Escriba su introducci칩n aqu칤\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:47:13.474238Z",
          "start_time": "2020-03-31T13:47:13.454068Z"
        },
        "id": "OTAIEnSJzvIp"
      },
      "source": [
        "## **2. Representaciones**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:47:17.719268Z",
          "start_time": "2020-03-31T13:47:17.709207Z"
        },
        "id": "EV1qBv-MzvIp"
      },
      "source": [
        "    Escriba sus decisiones para la representaci칩n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMOjYSQezvIq"
      },
      "source": [
        "## **3. Algoritmos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bPiFs33zilS"
      },
      "source": [
        "    Explique los algoritmos utilizados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:47:52.064631Z",
          "start_time": "2020-03-31T13:47:52.044451Z"
        },
        "id": "ECjkdgdwzvIq"
      },
      "source": [
        "## **4. M칠tricas de Evaluaci칩n**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6eHJdHBzvIr"
      },
      "source": [
        "- AUC: ...\n",
        "- Kappa: ...\n",
        "- Accuracy: ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJyTrr2onLOo"
      },
      "source": [
        "## **5. Dise침o experimental**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnhEwjh_nP9M"
      },
      "source": [
        "    Descripci칩n de la metodolog칤a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX5Ib_pCzvIr"
      },
      "source": [
        "## **6. Experimentos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:31:40.023344Z",
          "start_time": "2020-03-31T13:31:40.003541Z"
        },
        "id": "aK24MJ8jzvIr"
      },
      "source": [
        "### Importar librer칤as\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:20.587160Z",
          "start_time": "2020-04-07T15:44:19.319386Z"
        },
        "id": "FukgFUTUzvIs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    cohen_kappa_score,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FevBPus0zvIs"
      },
      "source": [
        "### Definir m칠todos de evaluaci칩n (**NO tocar este c칩digo**)\n",
        "\n",
        "Estas funciones est치n a cargo de evaluar los resultados de la tarea. No deber칤an cambiarlas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:20.604066Z",
          "start_time": "2020-04-07T15:44:20.589106Z"
        },
        "id": "9wlllV7PzvIs"
      },
      "outputs": [],
      "source": [
        "def auc_score(test_set, predicted_set):\n",
        "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
        "    medium_predicted = np.array(\n",
        "        [prediction[1] for prediction in predicted_set]\n",
        "    )\n",
        "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
        "    inc_test = np.where(test_set == \"incivilidad\", 1.0, 0.0)\n",
        "    odio_test = np.where(test_set == \"odio\", 1.0, 0.0)\n",
        "    normal_test = np.where(test_set == \"normal\", 1.0, 0.0)\n",
        "    auc_high = roc_auc_score(inc_test, high_predicted)\n",
        "    auc_med = roc_auc_score(odio_test, medium_predicted)\n",
        "    auc_low = roc_auc_score(normal_test, low_predicted)\n",
        "    auc_w = (\n",
        "        normal_test.sum() * auc_low\n",
        "        + odio_test.sum() * auc_med\n",
        "        + inc_test.sum() * auc_high\n",
        "    ) / (normal_test.sum() + odio_test.sum() + inc_test.sum())\n",
        "    return auc_w\n",
        "\n",
        "\n",
        "def evaluate(predicted_probabilities, y_test, labels):\n",
        "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
        "    # entregar el arreglo de clases aprendido por el clasificador.\n",
        "    # (que comunmente, es distinto a ['normal', 'odio', 'incivilidad'])\n",
        "    predicted_labels = [\n",
        "        labels[np.argmax(item)] for item in predicted_probabilities\n",
        "    ]\n",
        "\n",
        "    print(\"Matriz de confusi칩n\")\n",
        "    print(\n",
        "        confusion_matrix(\n",
        "            y_test, predicted_labels, labels=[\"normal\", \"odio\", \"incivilidad\"]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print(\"\\nReporte de clasificaci칩n:\\n\")\n",
        "    print(\n",
        "        classification_report(\n",
        "            y_test, predicted_labels, labels=[\"normal\", \"odio\", \"incivilidad\"]\n",
        "        )\n",
        "    )\n",
        "    # Reorder predicted probabilities array.\n",
        "    labels = labels.tolist()\n",
        "\n",
        "    predicted_probabilities = predicted_probabilities[\n",
        "        :,\n",
        "        [\n",
        "            labels.index(\"normal\"),\n",
        "            labels.index(\"odio\"),\n",
        "            labels.index(\"incivilidad\"),\n",
        "        ],\n",
        "    ]\n",
        "\n",
        "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
        "    print(\"M칠tricas:\\n\\nAUC: \", auc, end=\"\\t\")\n",
        "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
        "    print(\"Kappa:\", kappa, end=\"\\t\")\n",
        "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"------------------------------------------------------\\n\")\n",
        "    return np.array([auc, kappa, accuracy])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkOP6ugwzvIt"
      },
      "source": [
        "### Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.068137Z",
          "start_time": "2020-04-07T15:44:20.606061Z"
        },
        "id": "D1XhFPhrzvIt"
      },
      "outputs": [],
      "source": [
        "# Dataset de entrenamiento.\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Dataset que deber치n predecir para la competencia.\n",
        "target = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/target/target.tsv\", sep=\"\\t\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.088707Z",
          "start_time": "2020-04-07T15:44:21.069757Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "flg2Zw2mzvIt",
        "outputId": "35dbd565-4dfe-4702-90a7-1ee81ff37f63"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1327</th>\n",
              "      <td>1668</td>\n",
              "      <td>Lo que me da paja de poner en duda los relatos...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10661</th>\n",
              "      <td>13376</td>\n",
              "      <td>@user Me cago en la puta, me quer칤a ir a dormi...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2482</th>\n",
              "      <td>2849</td>\n",
              "      <td>Que rabia conchetumareeee游땴游땴\\nBolivianos qls 游뱗游뱗...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5252</th>\n",
              "      <td>2205</td>\n",
              "      <td>Venezolanos viviendo como si no pasara nada. S...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6648</th>\n",
              "      <td>11570</td>\n",
              "      <td>Odiar gais no es homofobia......... https://t....</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              texto        clase\n",
              "1327    1668  Lo que me da paja de poner en duda los relatos...       normal\n",
              "10661  13376  @user Me cago en la puta, me quer칤a ir a dormi...       normal\n",
              "2482    2849  Que rabia conchetumareeee游땴游땴\\nBolivianos qls 游뱗游뱗...  incivilidad\n",
              "5252    2205  Venezolanos viviendo como si no pasara nada. S...  incivilidad\n",
              "6648   11570  Odiar gais no es homofobia......... https://t....         odio"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejemplo de algunas filas aleatorias del dataset etiquetado:\n",
        "train.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "XB7hb7KH2DFK",
        "outputId": "dcb19d55-ebf9-4dd5-d9ad-a1f4b75d2b3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2241</th>\n",
              "      <td>5934</td>\n",
              "      <td>Esto es lo q ocasiona una mujer q odia al Per칰...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1932</th>\n",
              "      <td>13360</td>\n",
              "      <td>@user @user Vaya puto chad (tu, el otro es un ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>2005</td>\n",
              "      <td>@user A patadas en el poto se va a ir a vacunar</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>10306</td>\n",
              "      <td>@user Sabrosa tu mujer</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1078</th>\n",
              "      <td>1176</td>\n",
              "      <td>@user Y uds perdedoras ignorantes</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                              texto  clase\n",
              "2241   5934  Esto es lo q ocasiona una mujer q odia al Per칰...    NaN\n",
              "1932  13360  @user @user Vaya puto chad (tu, el otro es un ...    NaN\n",
              "269    2005    @user A patadas en el poto se va a ir a vacunar    NaN\n",
              "1370  10306                             @user Sabrosa tu mujer    NaN\n",
              "1078   1176                  @user Y uds perdedoras ignorantes    NaN"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejemplo de algunas filas aleatorias del dataset no etiquetado\n",
        "target.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5aNqEfVzvIv"
      },
      "source": [
        "### Analizar los datos\n",
        "\n",
        "En esta secci칩n analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.117633Z",
          "start_time": "2020-04-07T15:44:21.090703Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5007JRgzvIv",
        "outputId": "c65708bf-61c4-4786-da51-a4eafade45b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "incivilidad    5424\n",
              "normal         4280\n",
              "odio           2510\n",
              "Name: clase, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[\"clase\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZ6ig5hzvIv"
      },
      "source": [
        "### Custom Features\n",
        "\n",
        "Para crear features personalizadas implementaremos nuestros propios Transformers (estandar de scikit para crear nuevas features entre otras cosas). Para esto:\n",
        "\n",
        "1. Creamos nuestra clase Transformer extendiendo BaseEstimator y TransformerMixin. En este ejemplo, definiremos `CharsCountTransformer` que cuenta caracteres relevantes ('!', '?', '#', '@') en los tweets.\n",
        "2. Definimos una funci칩n c칩mo `get_relevant_chars` que opera por cada tweet y retorna un arreglo.\n",
        "3. Hacemos un override de la funci칩n `transform` en donde iteramos por cada tweet, llamamos a la funci칩n que hicimos antes y agregamos sus resultados a un arreglo. Finalmente lo retornamos.\n",
        "\n",
        "Esto nos facilitar치 el trabajo mas adelante. Una Guia completa de las transformaciones predefinidas en scikit pueden encontrarla [aqu칤](https://scikit-learn.org/stable/data_transforms.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.128600Z",
          "start_time": "2020-04-07T15:44:21.119624Z"
        },
        "id": "tNPB8zc9zvIw"
      },
      "outputs": [],
      "source": [
        "class CharsCountTransformer(BaseEstimator, TransformerMixin):\n",
        "    def get_relevant_chars(self, tweet):\n",
        "        num_hashtags = tweet.count(\"#\")\n",
        "        num_exclamations = tweet.count(\"!\")\n",
        "        num_interrogations = tweet.count(\"?\")\n",
        "        num_at = tweet.count(\"@\")\n",
        "        return [num_hashtags, num_exclamations, num_interrogations, num_at]\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        chars = []\n",
        "        for tweet in X:\n",
        "            chars.append(self.get_relevant_chars(tweet))\n",
        "\n",
        "        return np.array(chars)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.145564Z",
          "start_time": "2020-04-07T15:44:21.131593Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCQzsuAbzvIw",
        "outputId": "0ababf21-82ca-48a3-c0c7-e2d0b0c6e3a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Textos originales: @user Y este mapuche flojo, ignorante, borracho y manipulado dice eso ? Las patitas, lo que hace el copete, me recuerda un se침or Varas de un reality. Que m칠rito tiene es hombre ?? Solo haber comprado el cuento del PC, nada m치s y ser un tonto 칰til, cosa que el copete le impide ver.\n",
            "Features creados: [0 0 3 1]\n"
          ]
        }
      ],
      "source": [
        "# Veamos que sucede si ejecutamos el transformer\n",
        "sample = train.sample(5, random_state=42)[\"texto\"]\n",
        "sample_features = CharsCountTransformer().transform(sample)\n",
        "\n",
        "# Se puede verificar que el conteo de s칤mbolos es consistente con el transformer creado.\n",
        "print(f\"Textos originales: {sample.iloc[0]}\")\n",
        "print(f\"Features creados: {sample_features[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO_yIepczvIx"
      },
      "source": [
        "### Definir la representaci칩n y el clasificador\n",
        "\n",
        "Para esto, definiremos Pipelines. Un `Pipeline` es una lista de transformaciones y un estimador(clasificador) ubicado al final el cual define el flujo que seguiran nuestros datos dentro del sistema que creemos. Nos permite ejecutar facilmente el mismo proceso sobre todos los datasets que usemos, simplificando as칤 nuestra programaci칩n.\n",
        "\n",
        "El pipeline m치s b치sico que podemos hacer es transformar el dataset a Bag of Words y despu칠s usar clasificar el BoW usando NaiveBayes:\n",
        "\n",
        "```python\n",
        "    Pipeline([('bow', CountVectorizer()), ('clf', MultinomialNB())])\n",
        "```\n",
        "\n",
        "Ahora, si queremos usar nuestra transformaci칩n para agregar las features que creamos, usaremos `FeatureUnion`. Esta simplemente concatenar치 los vectores resultantes de ejecutar BoW y los Transformer en un solo vector.\n",
        "\n",
        "```python\n",
        "    Pipeline([('features',FeatureUnion([('bow', CountVectorizer()),\n",
        "                                        ('chars_count',CharsCountTransformer())])),\n",
        "              ('clf', MultinomialNB())])\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDbHjXv-zvIx"
      },
      "source": [
        "Recuerden que cada pipeline representa un sistema de clasificaci칩n distinto. Por lo mismo, deben instanciar uno por cada problema que resuelvan. De lo contrario, podr칤an solapar resultados. Para esto, les recomendamos crear los pipeline en distintas funciones, como la siguiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.155528Z",
          "start_time": "2020-04-07T15:44:21.149545Z"
        },
        "id": "z_R6tyMCzvIy"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "\n",
        "def get_experiment_0_pipeline():\n",
        "\n",
        "    return Pipeline(\n",
        "        [\n",
        "            (\n",
        "                \"features\",\n",
        "                FeatureUnion(\n",
        "                    [\n",
        "                        (\"bow\", CountVectorizer()),\n",
        "                        (\"chars_count\", CharsCountTransformer()),\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            (\"clf\", MultinomialNB()),\n",
        "        ]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ahora creamos un pipeline con un modemo Random Forest:\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "def get_experiment_1_pipeline():\n",
        "    return Pipeline(\n",
        "        [\n",
        "            (\n",
        "                \"features\",\n",
        "                FeatureUnion(\n",
        "                    [\n",
        "                        (\"bow\", CountVectorizer()),\n",
        "                        (\"chars_count\", CharsCountTransformer()),\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            (\"clf\", RandomForestClassifier(random_state=42)),\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ahora creamos un pipeline con unbalnced random forest:\n",
        "#install imblearn\n",
        "#pip install imblearn\n",
        "import imblearn\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "\n",
        "def get_experiment_2_pipeline():\n",
        "    return Pipeline(\n",
        "        [\n",
        "            (\n",
        "                \"features\",\n",
        "                FeatureUnion(\n",
        "                    [\n",
        "                        (\"bow\", CountVectorizer()),\n",
        "                        (\"chars_count\", CharsCountTransformer()),\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            (\"clf\", BalancedRandomForestClassifier(random_state=42)),\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ahora creamos un pipeline con GradientBoostingClassifier:\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "def get_experiment_3_pipeline():\n",
        "    return Pipeline(\n",
        "        [\n",
        "            (\n",
        "                \"features\",\n",
        "                FeatureUnion(\n",
        "                    [\n",
        "                        (\"bow\", CountVectorizer()),\n",
        "                        (\"chars_count\", CharsCountTransformer()),\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            (\"clf\", GradientBoostingClassifier(random_state=42)),\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creamos un pipeline con TF-IDF vectorizer:\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def get_experiment_4_pipeline():\n",
        "    return Pipeline(\n",
        "        [\n",
        "            (\n",
        "                \"features\",\n",
        "                FeatureUnion(\n",
        "                    [\n",
        "                        ('tfidf', TfidfVectorizer()),\n",
        "                        (\"chars_count\", CharsCountTransformer()),\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            (\"clf\", BalancedRandomForestClassifier(random_state=42)),\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Textos originales: @user es una forma medio rara de usar un subjuntivo con indicativo. Yo no lo usar칤a\n",
            "Features creados:   (0, 140)\t0.28966903376554404\n",
            "  (0, 65)\t0.24624514285741414\n",
            "  (0, 81)\t0.15550251391009007\n",
            "  (0, 149)\t0.24624514285741414\n",
            "  (0, 56)\t0.28966903376554404\n",
            "  (0, 19)\t0.28966903376554404\n",
            "  (0, 126)\t0.28966903376554404\n",
            "  (0, 136)\t0.21543540194368221\n",
            "  (0, 139)\t0.28966903376554404\n",
            "  (0, 25)\t0.15550251391009007\n",
            "  (0, 108)\t0.28966903376554404\n",
            "  (0, 74)\t0.28966903376554404\n",
            "  (0, 48)\t0.28966903376554404\n",
            "  (0, 137)\t0.21543540194368221\n",
            "  (0, 43)\t0.19153751027470034\n",
            "  (0, 141)\t0.17201151103555232\n"
          ]
        }
      ],
      "source": [
        "# probamos un ejemplo de extraccion de caracteristicas:\n",
        "sample = train.sample(10)[\"texto\"]\n",
        "sample_features = TfidfVectorizer().fit_transform(sample)\n",
        "#sample_features = CountVectorizer().fit_transform(sample)\n",
        "\n",
        "\n",
        "# Se puede verificar que el conteo de s칤mbolos es consistente con el transformer creado.\n",
        "print(f\"Textos originales: {sample.iloc[0]}\")\n",
        "print(f\"Features creados: {sample_features[0]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ismael/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ambos</th>\n",
              "      <th>baja</th>\n",
              "      <th>cierren</th>\n",
              "      <th>de</th>\n",
              "      <th>deber칤an</th>\n",
              "      <th>el</th>\n",
              "      <th>eleccionesgobernador2021</th>\n",
              "      <th>ellos</th>\n",
              "      <th>en</th>\n",
              "      <th>entre</th>\n",
              "      <th>...</th>\n",
              "      <th>que</th>\n",
              "      <th>quejar</th>\n",
              "      <th>qui칠n</th>\n",
              "      <th>rm</th>\n",
              "      <th>se</th>\n",
              "      <th>tengo</th>\n",
              "      <th>todo</th>\n",
              "      <th>vial</th>\n",
              "      <th>votar</th>\n",
              "      <th>vote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "      <td>0.137361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows 칑 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ambos      baja   cierren        de  deber칤an        el  \\\n",
              "0  0.137361  0.137361  0.137361  0.137361  0.137361  0.137361   \n",
              "\n",
              "   eleccionesgobernador2021     ellos        en     entre  ...       que  \\\n",
              "0                  0.137361  0.137361  0.137361  0.137361  ...  0.137361   \n",
              "\n",
              "     quejar     qui칠n        rm        se     tengo      todo      vial  \\\n",
              "0  0.137361  0.137361  0.137361  0.137361  0.137361  0.137361  0.137361   \n",
              "\n",
              "      votar      vote  \n",
              "0  0.137361  0.137361  \n",
              "\n",
              "[1 rows x 34 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Imprimimo la matriz sparse de features en formato dataframe:\n",
        "TF_IDF_matrix = pd.DataFrame.sparse.from_spmatrix(sample_features, columns=TfidfVectorizer().fit(sample).get_feature_names())\n",
        "TF_IDF_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_60444/111803607.py:2: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  TF_IDF_matrix.to_csv('TF_IDF_matrix.csv')\n"
          ]
        }
      ],
      "source": [
        "#Exportamos TF_IDF_matrix a un archivo csv:\n",
        "TF_IDF_matrix.to_csv('TF_IDF_matrix.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Las formulas para calcular la matrix TF-IDF son:\n",
        "#TF(t) = (N칰mero de veces que aparece el t칠rmino t en un documento) / (N칰mero total de t칠rminos en el documento)\n",
        "#IDF(t) = log_e(Total de documentos / N칰mero de documentos con el t칠rmino t en 칠l)\n",
        "\n",
        "#TF-IDF(t) = TF(t) * IDF(t)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Textos originales: @user @user Escandaloso el penal cobrado a Chile ayer, ni la toc칩 maripan, @user mafiosos ctm y el 치rbitro y la ctm igual, pelao re qlo ladr칩n, en el var le mostraron solo una imagen, el 치rbitro deber칤a ser m치s objetivo y ver todos los 치ngulos posibles, hijos de la perraaaaa &gt;:(\n",
            "   ayer  chile  cobrado  ctm  de  deber칤a  el  en  escandaloso  gt  ...  ser  \\\n",
            "0     1      1        1    2   1        1   4   1            1   1  ...    1   \n",
            "\n",
            "   solo  toc칩  todos  una  user  var  ver  치ngulos  치rbitro  \n",
            "0     1     1      1    1     3    1    1        1        2  \n",
            "\n",
            "[1 rows x 39 columns]\n",
            "Textos originales: @user @user Escandaloso el penal cobrado a Chile ayer, ni la toc칩 maripan, @user mafiosos ctm y el 치rbitro y la ctm igual, pelao re qlo ladr칩n, en el var le mostraron solo una imagen, el 치rbitro deber칤a ser m치s objetivo y ver todos los 치ngulos posibles, hijos de la perraaaaa &gt;:(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ismael/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/home/ismael/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#para un mismo texto comparamas el resultado de CountVectorizer y TfidfVectorizer:\n",
        "sample = train.sample(1)[\"texto\"]\n",
        "\n",
        "metodo = CountVectorizer()\n",
        "#sample_features = TfidfVectorizer().fit_transform(sample)\n",
        "sample_features = metodo.fit_transform(sample)\n",
        "# Se puede verificar que el conteo de s칤mbolos es consistente con el transformer creado.\n",
        "print(f\"Textos originales: {sample.iloc[0]}\")\n",
        "#Imprimimo la matriz sparse de features en formato dataframe:\n",
        "TF_IDF_matrix = pd.DataFrame.sparse.from_spmatrix(sample_features, columns=metodo.fit(sample).get_feature_names())\n",
        "print(TF_IDF_matrix)\n",
        "\n",
        "metodo = TfidfVectorizer()\n",
        "sample_features = metodo.fit_transform(sample)\n",
        "# Se puede verificar que el conteo de s칤mbolos es consistente con el transformer creado.\n",
        "print(f\"Textos originales: {sample.iloc[0]}\")\n",
        "#Imprimimo la matriz sparse de features en formato dataframe:\n",
        "TF_IDF_matrix = pd.DataFrame.sparse.from_spmatrix(sample_features, columns=metodo.fit(sample).get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmMdm98vzvIy"
      },
      "source": [
        "### Ejecutar el pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.167498Z",
          "start_time": "2020-04-07T15:44:21.157540Z"
        },
        "id": "_eX0cEu-zvIz",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def run(dataset, pipeline):\n",
        "    \"\"\"Creamos el pipeline y luego lo ejecutamos el pipeline sobre un dataset.\n",
        "    Retorna el modelo ya entrenado mas sus labels asociadas y los scores obtenidos al evaluarlo.\"\"\"\n",
        "\n",
        "    # Dividimos el dataset en train y test, a칰n no se transforma de Strings a valores num칠ricos.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        dataset.texto,\n",
        "        dataset.clase,\n",
        "        shuffle=True,\n",
        "        test_size=0.33,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    print(f\"# Datos de entrenamiento en dataset: {len(X_train)}\")\n",
        "    print(f\"# Datos de testing en dataset: {len(X_test)}\")\n",
        "\n",
        "    # Entrenamos el clasificador (Ejecuta el entrenamiento sobre todo el pipeline).\n",
        "    # En este caso el Bag of Words es el encargado de transformar de Strings a vectores num칠ricos.\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predecimos las probabilidades de intensidad de cada elemento del set de prueba.\n",
        "    predicted_probabilities = pipeline.predict_proba(X_test)\n",
        "\n",
        "    # Obtenemos el orden de las clases aprendidas.\n",
        "    learned_labels = pipeline.classes_\n",
        "\n",
        "    # Evaluamos:\n",
        "    scores = evaluate(predicted_probabilities, y_test, learned_labels)\n",
        "    return pipeline, learned_labels, scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z96C1ZOfzvIz"
      },
      "source": [
        "### Ejecutar el sistema creado por cada train set\n",
        "\n",
        "Este c칩digo crea y entrena los 4 sistemas de clasificaci칩n y luego los evalua. Para los experimentos, pueden copiar este c칩digo variando el pipeline cuantas veces estimen conveniente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.384119Z",
          "start_time": "2020-04-07T15:44:21.170488Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXAxZBdVzvI0",
        "outputId": "4dee8ba0-d607-45d1-cc0c-2402b578f739",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Datos de entrenamiento en dataset: 8183\n",
            "# Datos de testing en dataset: 4031\n",
            "Matriz de confusi칩n\n",
            "[[1102  137  218]\n",
            " [ 180  531  126]\n",
            " [ 349  118 1270]]\n",
            "\n",
            "Reporte de clasificaci칩n:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.68      0.76      0.71      1457\n",
            "        odio       0.68      0.63      0.65       837\n",
            " incivilidad       0.79      0.73      0.76      1737\n",
            "\n",
            "    accuracy                           0.72      4031\n",
            "   macro avg       0.71      0.71      0.71      4031\n",
            "weighted avg       0.72      0.72      0.72      4031\n",
            "\n",
            "M칠tricas:\n",
            "\n",
            "AUC:  0.87\tKappa: 0.563\tAccuracy: 0.72\n",
            "------------------------------------------------------\n",
            "\n",
            "AUC: 0.87\n",
            "Kappa: 0.563\n",
            "Accuracy: 0.72\n"
          ]
        }
      ],
      "source": [
        "# Creamos el pipeline\n",
        "pipeline = get_experiment_4_pipeline()\n",
        "\n",
        "\n",
        "\n",
        "# Ejecutamos el pipeline sobre el dataset y guardamos el clasificador, las labels aprendidas y los scores obtenidos\n",
        "classifier, learned_labels, scores = run(train, pipeline)\n",
        "\n",
        "# Imprimimos las m칠tricas en el conjunto de testing\n",
        "print(f\"AUC: {scores[0]}\")\n",
        "print(f\"Kappa: {scores[1]}\")\n",
        "print(f\"Accuracy: {scores[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-21T19:37:43.169737Z",
          "start_time": "2019-08-21T19:37:43.166744Z"
        },
        "id": "IUKwcde_zvI0"
      },
      "source": [
        "### Predecir los target set y crear la submission\n",
        "\n",
        "Aqu칤 predecimos los target set usando los clasificadores creados y creamos los archivos de las submissions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.392097Z",
          "start_time": "2020-04-07T15:44:21.386114Z"
        },
        "id": "mWDUoSmbzvI1"
      },
      "outputs": [],
      "source": [
        "def predict_target(dataset, classifier, labels):\n",
        "    # Predecir las probabilidades de intensidad de cada elemento del target set.\n",
        "    predicted = pd.DataFrame(\n",
        "        classifier.predict_proba(dataset.texto), columns=labels\n",
        "    )\n",
        "\n",
        "    # Agregar ids\n",
        "    predicted[\"id\"] = dataset.id.values\n",
        "    # Reordenar las columnas\n",
        "    predicted = predicted[[\"id\", \"normal\", \"odio\", \"incivilidad\"]]\n",
        "    return predicted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.588573Z",
          "start_time": "2020-04-07T15:44:21.394094Z"
        },
        "id": "5CJ4PTwZzvI1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "predicted_target = {}\n",
        "\n",
        "# Crear carpeta ./predictions\n",
        "if not os.path.exists(\"./predictions\"):\n",
        "    os.mkdir(\"./predictions\")\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree(\"./predictions\")\n",
        "    os.mkdir(\"./predictions\")\n",
        "\n",
        "\n",
        "# Predecir\n",
        "predicted_target = predict_target(target, classifier, learned_labels)\n",
        "\n",
        "# Guardar predicciones en archivos separados.\n",
        "predicted_target.to_csv(\n",
        "    \"./predictions/prediction.txt\", sep=\"\\t\", header=False, index=False\n",
        ")\n",
        "\n",
        "# Crear archivo zip\n",
        "a = shutil.make_archive(\"predictions\", \"zip\", \"./predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCAyJIj8nTlU"
      },
      "source": [
        "## **7. Resultados**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAYwupS3naYX"
      },
      "source": [
        "Muestre y analice sus resultados aqu칤\n",
        "\n",
        "A continuaci칩n una tabla de ejemplo para mostrar los resultados. En este caso s칩lo est치 el experimento del baseline m치s otro clasificador, pero ustedes debiesen generar una mayor cantidad de experimentos.\n",
        "\n",
        "| No. | Approach        |               | AUC   | Kappa | Accuracy |\n",
        "| --- | --------------- | ------------- | ----- | ----- | -------- |\n",
        "|     | Features        | Clasifier     |       |       |          |\n",
        "| 0   | bow+chars_count | MultinomialNB | 0.875 | 0.559 | 0.727    |\n",
        "| 1   | tus features    | tu clasifier  |       |       |          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqlew0iizvI1"
      },
      "source": [
        "## **8. Conclusiones**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFTikGbszZuc"
      },
      "source": [
        "    Escriba aqu칤 sus conclusiones\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
