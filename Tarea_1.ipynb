{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbrMqMPyncTC"
      },
      "source": [
        "# **Tarea 1 - CC6205 Natural Language Processing 📚**\n",
        "\n",
        "**Integrantes:** \n",
        "\n",
        "**Fecha límite de entrega 📆:** Martes 4 de Abril.\n",
        "\n",
        "**Tiempo estimado de dedicación:** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1HFX-9PpxF9"
      },
      "source": [
        "` ` \n",
        "\n",
        "\n",
        "Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos teóricos de las primeras semanas de clases, enfocado principalmente en ***Information Retrieval (IR)*** y ***Vector Space Models***. Si aún no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una parte teórica que busca evaluar conceptos vistos en clases. Seguido por una parte práctica con el fín de introducirlos a la programación en Python enfocada en NLP. \n",
        "\n",
        "` ` \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **máximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a través de u-cursos a más tardar el día estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook.\n",
        "- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación. \n",
        "- Está **PROHIBIDO** usar cualquier librería que implemente los algoritmos pedidos (Spacy, scikit, etc). Sólo se podrán utilizar las librerías importadas al inicio de la sección de práctica.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a través del canal de Discord del curso. \n",
        "\n",
        "\n",
        "\n",
        "Ahora sí, empecemos! 😄🚀\n",
        "\n",
        "` ` \n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "\n",
        "Slides:\n",
        "    \n",
        "- [Introducción al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
        "\n",
        "Videos: \n",
        "\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducción parte I](https://www.youtube.com/watch?v=HEKTNOttGvU)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducción parte II](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)\n",
        "\n",
        "` ` \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJshpe1yrKJr"
      },
      "source": [
        "## **1 - Preguntas teóricas 📕 (2 puntos).** ##\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBEDKXBPoA7w"
      },
      "source": [
        "Las siguientes celdas contienen preguntas acerca del contenido visto en clases y en el material del curso.  Contestar cada pregunta en su celda correspondiente y **no extenderse más de 100 palabras** . 🙏\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNJPR1kMrw9R"
      },
      "source": [
        "**Pregunta 1 (0.2 puntos): ¿Por qué el análisis del lenguaje humano es una tarea compleja? Mencione dos razones según lo visto en clases. Debe citar la slide donde cree que está la respuesta.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTBYHEptdde"
      },
      "source": [
        "` ` \n",
        "Respuesta aquí\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVMXilrYsiSZ"
      },
      "source": [
        "**Pregunta 2 (0.4 puntos): ¿Cuáles son las diferencias entre usar Deep learning y Machine Learning clásico (empirismo) para un problema de NLP? Ejemplifique con alguna task.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qué según lo visto en clases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXWMzpTtBZL"
      },
      "source": [
        "` ` \n",
        "Respuesta aquí\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXc4XuVG7Loa"
      },
      "source": [
        " **Pregunta 3 (0.4 puntos) Según las primeras clases, ¿Qué método clásico nos permite rankear las similitudes existentes entre documentos?, ¿Cómo son las representaciones que genera y problemas que podrían experimentar estas soluciones simples?** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtaQ_aVE8LhH"
      },
      "source": [
        "` ` \n",
        "Respuesta aquí\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKNDNy047tcY"
      },
      "source": [
        "**Pregunta 4 (0.4 puntos) Usted se encuentra realizando un modelo de clasificación de sentimientos con texto, su jefe le señala que debe eliminar las palabras mas comunes para obtener una mejor clasificación. ¿Qué palabras le señala que elimine su jefe?, ¿es acaso esto una buena idea?.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qué según lo visto en clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRe4QaGS8MqY"
      },
      "source": [
        "` ` \n",
        "Respuesta aquí\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPkWmrmLHWnQ"
      },
      "source": [
        "**Pregunta 5 (0.6 puntos): Acorde al paper [A Vector Space Model for automatic indexing](https://dl.acm.org/doi/pdf/10.1145/361219.361220) un documento, $D_i$, puede ser definido formalmente como una tupla de términos, $(d_{i1}, d_{i2}, ..., d_{in})$, donde $d_{ij}$ representa el peso del j-esimo término. En clase vieron algunas formas medir los pesos de estos términos. Mencione cuales fueron y sus ventajas y desventajas (pueden responder en máximo 150 palabras).** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLqRTW08SzDN"
      },
      "source": [
        "` ` \n",
        "Respuesta aquí\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fpsz2pQt8x5"
      },
      "source": [
        "## **2 - Preguntas prácticas 💻 (4 puntos).** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB92kQXspvbR"
      },
      "source": [
        "Esta segunda sección incluye ejercicios de programación 🤙. Leer atentamente las instrucciones entregadas a continuación para facilitar el proceso de revisión de sus trabajos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosWgWgRxHKp"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "\n",
        "\n",
        "- Escribe tu código entre las lineas de comentarios **### Aquí inicia tu código ###** y **### Aquí termina tu código ###**.\n",
        "- Cuando el ejercicio incluya un bloque llamado ***Test***, comprueba que el resultado de la ejecución coincida con el resultado esperado.\n",
        "- Recuerde siempre mantener buenas prácticas de código.\n",
        "- Está permitido sólo utilizar las librerías importadas antes del Ejercicio 1.\n",
        "- **Recordar** que: *Documento = Oración. Dataset = Corpus. Vocabulario = Tokens*.\n",
        "- El **orden de los resultados** pueden variar dependiendo de su máquina, pero los valores de los resultados son los mismos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrmFHXhqUww"
      },
      "source": [
        "**Ejemplo:** Implemente una función **`hello_world()`** que imprima en pantalla `\"Hello World\"`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu7cIsawyJHx"
      },
      "outputs": [],
      "source": [
        "def hello_world():\n",
        "  ### Aquí inicia tu código ###\n",
        "  print(\"Hello World\")\n",
        "  ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6klw12lwbW"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac-WMk2dyQbp",
        "outputId": "9030f89c-ed23-4f5e-e317-9153250b150e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoiAMxtyUjQ"
      },
      "source": [
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td> Hello World </td> \n",
        "    </tr>\n",
        "</table> \n",
        "\n",
        "``\n",
        "``\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPyrPXiH0l4"
      },
      "source": [
        "Estas son las librerías permitidas. Si quieren utilizar alguna librería adicional, pueden realizar la consulta a través de Discord. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CtP6Emjo1kF0"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9Do0LdC9w2"
      },
      "source": [
        "En caso de desarrollar la tarea desde colab, utilizar el siguiente código para cargar los archivos desde el drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EXq1VDeC-ml",
        "outputId": "fab8dcac-3af9-49df-f273-99b0965f1b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#try:\n",
        "#    from google.colab import drive\n",
        "#\n",
        "#    drive.mount(\"/content/drive\")\n",
        "#    path = 'path/to/marcianeke.txt'\n",
        "#except: \n",
        "#    print('Ignorando conexión drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSN4bBoY2Td4"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Ejercicio 1 - *Tokenización* (0.5 puntos).** \n",
        "` `  \n",
        "` ` \n",
        "\n",
        "En el primer ejercicio veremos la dificultad 😨 de tokenizar textos no estructurados, destacando la importancia de tener librerías que realicen este trabajo. \n",
        "\n",
        "El archivo adjunto al enunciado de la tarea contiene la letra de una canción del marcianeke 👽. Utilice este texto para realizar su primera tokenización y ver qué tan bien funciona su función. \n",
        "\n",
        "Ejecute el código a continuación para cargar el ejemplo. Recuerde realizar la modificación al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnNUYlWo21g4",
        "outputId": "d38b4731-e05b-4bd7-b7b3-0e99d251cd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brr\n",
            "Marcianeke\n",
            "Vamo' a estar con Pailita\n",
            "Dimelo má\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar (brr)\n",
            "Tussi, keta quiere' mezclar\n",
            "Dimelo má\n",
            "\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta pura quiere' mezclar\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "\n",
            "Esperame que ahora entro yo\n",
            "Y lo que pide yo lo traje\n",
            "No visto de traje\n",
            "Puro corte calle, no de maquillaje\n",
            "Pronto coronamos y nos vamo' de viaje\n",
            "Tanto hit que hago que lo' culo bajen\n",
            "Ella se va de shopping\n",
            "Sale positivo si se hace el doping\n",
            "Baila twerk con un poco de popping\n",
            "Los fardos en el botín\n",
            "\n",
            "Si quieren letra llamen pa' mi booking\n",
            "Generando, sigo en la mía lowkey\n",
            "Cooking en el estudio con tu woman\n",
            "Tanto whisky, pisco que hasta lo' vecinos toman\n",
            "Si se tiran pa' aca puede que la arena coman\n",
            "Ja, en el chanteo titulado sin diploma\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "Di-dimelo má\n",
            "\n",
            "Ah, pe-peligrosa\n",
            "Quiero ver como perreando me acosa\n",
            "Eso de atra' con el Gucci me lo roza\n",
            "Tengo tussi del naranjo me aburrio el rosa\n",
            "Capaz que tosa con el blunt\n",
            "Sprite con Flemibron\n",
            "Louis Vuitton, le quito la polera Champion\n",
            "A tu pretendiente con la fory lo espanto\n",
            "Puro perro, le doy de comer Champion Dog\n",
            "Ese toto lo corono yo\n",
            "La movie en play no hay stop\n",
            "Flow de sobra no hay stock\n",
            "Me la topo en la disco queda en shock\n",
            "My love, rica en las redes y en persona\n",
            "No usa Photoshop\n",
            "La llevo a comprar blone' al growshop\n",
            "En ropa interior los do'\n",
            "Me roza su vicky con mi boxer Top\n",
            "Dimelo má\n",
            "Ando en busca de una cri\n",
            "minal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta quiere' mezclar\n",
            "Dimelo má\n",
            "\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta pura quiere' mezclar\n",
            "Marcianeke, Pailita\n",
            "Young Varas\n"
          ]
        }
      ],
      "source": [
        "text = codecs.open('marcianeke.txt', 'r', 'UTF-8').read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIaOYzMk3v1X"
      },
      "source": [
        "Implementen una función **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Son libres de elegir la forma de tokenizar mientras no utilicen librerías con tokenizadores ya implementados. Pueden utilizar la librería **re** importada para trabajar símbolos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dl42-hgIhqB"
      },
      "source": [
        "Ejemplo de uso:\n",
        "\n",
        "`get_tokens('Este es un ejemplo de prueba.')` \n",
        "\n",
        "Nos entregaría:\n",
        "\n",
        "`['Este', 'es', 'un', 'ejemplo', 'de', 'prueba', '.']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IF1RcIwq4G2x"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "  ### Inicio del código ###\n",
        "\n",
        "  # Elimina los signos de puntuación\n",
        "  text = re.sub(r'[^\\w\\s]','',text) # reemplaza todo lo que no sea un caracter alfanumérico o un espacio por nada.\n",
        "\n",
        "  # Convierte el texto a minúsculas\n",
        "  text = text.lower()\n",
        "\n",
        "  # Separa el texto en tokens\n",
        "  tokens = text.split()\n",
        "\n",
        "  return tokens\n",
        "\n",
        "  ### Fin del código ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KqlSpefv4_EH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['brr', 'marcianeke', 'vamo', 'a', 'estar', 'con', 'pailita', 'dimelo', 'má', 'ando', 'en', 'busca', 'de', 'una', 'criminal', 'ah', 'ah', 'esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', 'ratata', 'que', 'le', 'guste', 'flotar', 'y', 'fumar', 'brr', 'tussi', 'keta', 'quiere', 'mezclar', 'dimelo', 'má', 'ando', 'en', 'busca', 'de', 'una', 'criminal', 'ah', 'ah', 'esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', 'ratata', 'que', 'le', 'guste', 'flotar', 'y', 'fumar', 'tussi', 'keta', 'pura', 'quiere', 'mezclar', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'esperame', 'que', 'ahora', 'entro', 'yo', 'y', 'lo', 'que', 'pide', 'yo', 'lo', 'traje', 'no', 'visto', 'de', 'traje', 'puro', 'corte', 'calle', 'no', 'de', 'maquillaje', 'pronto', 'coronamos', 'y', 'nos', 'vamo', 'de', 'viaje', 'tanto', 'hit', 'que', 'hago', 'que', 'lo', 'culo', 'bajen', 'ella', 'se', 'va', 'de', 'shopping', 'sale', 'positivo', 'si', 'se', 'hace', 'el', 'doping', 'baila', 'twerk', 'con', 'un', 'poco', 'de', 'popping', 'los', 'fardos', 'en', 'el', 'botín', 'si', 'quieren', 'letra', 'llamen', 'pa', 'mi', 'booking', 'generando', 'sigo', 'en', 'la', 'mía', 'lowkey', 'cooking', 'en', 'el', 'estudio', 'con', 'tu', 'woman', 'tanto', 'whisky', 'pisco', 'que', 'hasta', 'lo', 'vecinos', 'toman', 'si', 'se', 'tiran', 'pa', 'aca', 'puede', 'que', 'la', 'arena', 'coman', 'ja', 'en', 'el', 'chanteo', 'titulado', 'sin', 'diploma', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'didimelo', 'má', 'ah', 'pepeligrosa', 'quiero', 'ver', 'como', 'perreando', 'me', 'acosa', 'eso', 'de', 'atra', 'con', 'el', 'gucci', 'me', 'lo', 'roza', 'tengo', 'tussi', 'del', 'naranjo', 'me', 'aburrio', 'el', 'rosa', 'capaz', 'que', 'tosa', 'con', 'el', 'blunt', 'sprite', 'con', 'flemibron', 'louis', 'vuitton', 'le', 'quito', 'la', 'polera', 'champion', 'a', 'tu', 'pretendiente', 'con', 'la', 'fory', 'lo', 'espanto', 'puro', 'perro', 'le', 'doy', 'de', 'comer', 'champion', 'dog', 'ese', 'toto', 'lo', 'corono', 'yo', 'la', 'movie', 'en', 'play', 'no', 'hay', 'stop', 'flow', 'de', 'sobra', 'no', 'hay', 'stock', 'me', 'la', 'topo', 'en', 'la', 'disco', 'queda', 'en', 'shock', 'my', 'love', 'rica', 'en', 'las', 'redes', 'y', 'en', 'persona', 'no', 'usa', 'photoshop', 'la', 'llevo', 'a', 'comprar', 'blone', 'al', 'growshop', 'en', 'ropa', 'interior', 'los', 'do', 'me', 'roza', 'su', 'vicky', 'con', 'mi', 'boxer', 'top', 'dimelo', 'má', 'ando', 'en', 'busca', 'de', 'una', 'cri', 'minal', 'ah', 'ah', 'esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', 'ratata', 'que', 'le', 'guste', 'flotar', 'y', 'fumar', 'tussi', 'keta', 'quiere', 'mezclar', 'dimelo', 'má', 'ando', 'en', 'busca', 'de', 'una', 'criminal', 'ah', 'ah', 'esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', 'ratata', 'que', 'le', 'guste', 'flotar', 'y', 'fumar', 'tussi', 'keta', 'pura', 'quiere', 'mezclar', 'marcianeke', 'pailita', 'young', 'varas']\n"
          ]
        }
      ],
      "source": [
        "tokens = get_tokens(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbgTvAW-stF"
      },
      "source": [
        "**Describa cuáles fueron sus supuestos para realizar la tokenización y compare sus tokens con los entregados por la librería nltk en el bloque de código de más abajo.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGQ7CJy3-3aH"
      },
      "source": [
        "Supuestos aqui\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYtmAXTr9KXK",
        "outputId": "4981a15d-89bc-4972-f91a-f4afe42659a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Brr',\n",
              " 'Marcianeke',\n",
              " 'Vamo',\n",
              " \"'\",\n",
              " 'a',\n",
              " 'estar',\n",
              " 'con',\n",
              " 'Pailita',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " '(',\n",
              " 'brr',\n",
              " ')',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Esperame',\n",
              " 'que',\n",
              " 'ahora',\n",
              " 'entro',\n",
              " 'yo',\n",
              " 'Y',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'pide',\n",
              " 'yo',\n",
              " 'lo',\n",
              " 'traje',\n",
              " 'No',\n",
              " 'visto',\n",
              " 'de',\n",
              " 'traje',\n",
              " 'Puro',\n",
              " 'corte',\n",
              " 'calle',\n",
              " ',',\n",
              " 'no',\n",
              " 'de',\n",
              " 'maquillaje',\n",
              " 'Pronto',\n",
              " 'coronamos',\n",
              " 'y',\n",
              " 'nos',\n",
              " 'vamo',\n",
              " \"'\",\n",
              " 'de',\n",
              " 'viaje',\n",
              " 'Tanto',\n",
              " 'hit',\n",
              " 'que',\n",
              " 'hago',\n",
              " 'que',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'culo',\n",
              " 'bajen',\n",
              " 'Ella',\n",
              " 'se',\n",
              " 'va',\n",
              " 'de',\n",
              " 'shopping',\n",
              " 'Sale',\n",
              " 'positivo',\n",
              " 'si',\n",
              " 'se',\n",
              " 'hace',\n",
              " 'el',\n",
              " 'doping',\n",
              " 'Baila',\n",
              " 'twerk',\n",
              " 'con',\n",
              " 'un',\n",
              " 'poco',\n",
              " 'de',\n",
              " 'popping',\n",
              " 'Los',\n",
              " 'fardos',\n",
              " 'en',\n",
              " 'el',\n",
              " 'botín',\n",
              " 'Si',\n",
              " 'quieren',\n",
              " 'letra',\n",
              " 'llamen',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'mi',\n",
              " 'booking',\n",
              " 'Generando',\n",
              " ',',\n",
              " 'sigo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'mía',\n",
              " 'lowkey',\n",
              " 'Cooking',\n",
              " 'en',\n",
              " 'el',\n",
              " 'estudio',\n",
              " 'con',\n",
              " 'tu',\n",
              " 'woman',\n",
              " 'Tanto',\n",
              " 'whisky',\n",
              " ',',\n",
              " 'pisco',\n",
              " 'que',\n",
              " 'hasta',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'vecinos',\n",
              " 'toman',\n",
              " 'Si',\n",
              " 'se',\n",
              " 'tiran',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'aca',\n",
              " 'puede',\n",
              " 'que',\n",
              " 'la',\n",
              " 'arena',\n",
              " 'coman',\n",
              " 'Ja',\n",
              " ',',\n",
              " 'en',\n",
              " 'el',\n",
              " 'chanteo',\n",
              " 'titulado',\n",
              " 'sin',\n",
              " 'diploma',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Ah',\n",
              " ',',\n",
              " 'pe',\n",
              " '-',\n",
              " 'peligrosa',\n",
              " 'Quiero',\n",
              " 'ver',\n",
              " 'como',\n",
              " 'perreando',\n",
              " 'me',\n",
              " 'acosa',\n",
              " 'Eso',\n",
              " 'de',\n",
              " 'atra',\n",
              " \"'\",\n",
              " 'con',\n",
              " 'el',\n",
              " 'Gucci',\n",
              " 'me',\n",
              " 'lo',\n",
              " 'roza',\n",
              " 'Tengo',\n",
              " 'tussi',\n",
              " 'del',\n",
              " 'naranjo',\n",
              " 'me',\n",
              " 'aburrio',\n",
              " 'el',\n",
              " 'rosa',\n",
              " 'Capaz',\n",
              " 'que',\n",
              " 'tosa',\n",
              " 'con',\n",
              " 'el',\n",
              " 'blunt',\n",
              " 'Sprite',\n",
              " 'con',\n",
              " 'Flemibron',\n",
              " 'Louis',\n",
              " 'Vuitton',\n",
              " ',',\n",
              " 'le',\n",
              " 'quito',\n",
              " 'la',\n",
              " 'polera',\n",
              " 'Champion',\n",
              " 'A',\n",
              " 'tu',\n",
              " 'pretendiente',\n",
              " 'con',\n",
              " 'la',\n",
              " 'fory',\n",
              " 'lo',\n",
              " 'espanto',\n",
              " 'Puro',\n",
              " 'perro',\n",
              " ',',\n",
              " 'le',\n",
              " 'doy',\n",
              " 'de',\n",
              " 'comer',\n",
              " 'Champion',\n",
              " 'Dog',\n",
              " 'Ese',\n",
              " 'toto',\n",
              " 'lo',\n",
              " 'corono',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'movie',\n",
              " 'en',\n",
              " 'play',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stop',\n",
              " 'Flow',\n",
              " 'de',\n",
              " 'sobra',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stock',\n",
              " 'Me',\n",
              " 'la',\n",
              " 'topo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'disco',\n",
              " 'queda',\n",
              " 'en',\n",
              " 'shock',\n",
              " 'My',\n",
              " 'love',\n",
              " ',',\n",
              " 'rica',\n",
              " 'en',\n",
              " 'las',\n",
              " 'redes',\n",
              " 'y',\n",
              " 'en',\n",
              " 'persona',\n",
              " 'No',\n",
              " 'usa',\n",
              " 'Photoshop',\n",
              " 'La',\n",
              " 'llevo',\n",
              " 'a',\n",
              " 'comprar',\n",
              " 'blone',\n",
              " \"'\",\n",
              " 'al',\n",
              " 'growshop',\n",
              " 'En',\n",
              " 'ropa',\n",
              " 'interior',\n",
              " 'los',\n",
              " 'do',\n",
              " \"'\",\n",
              " 'Me',\n",
              " 'roza',\n",
              " 'su',\n",
              " 'vicky',\n",
              " 'con',\n",
              " 'mi',\n",
              " 'boxer',\n",
              " 'Top',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'cri',\n",
              " 'minal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Marcianeke',\n",
              " ',',\n",
              " 'Pailita',\n",
              " 'Young',\n",
              " 'Varas']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize \n",
        "nltk_tokens = wordpunct_tokenize(text)\n",
        "nltk_tokens"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comentario: \n",
        "Al parecer el  metodo de tokenizacion de nltk incluye los caracteres no alfanumericos (comas, puntos, parentesis, etc). Mientras que n la implementacion manual estos caracteres fueron eliminados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5QKlXAZwN1L"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 2 - *Stopwords y Stemming* (1 punto).** \n",
        "` `  \n",
        "` ` \n",
        "\n",
        "Considere el siguiente corpus:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEp83zESwb2j"
      },
      "outputs": [],
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjdlJWuyS2E"
      },
      "source": [
        "Diseñe una función **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando. Puede utilizar la función del Ejercicio 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UudC-b6TzZgw"
      },
      "outputs": [],
      "source": [
        "def get_vocab(dataset):\n",
        "  ### Aquí inicia tu código ###\n",
        "  \n",
        "  ...\n",
        "\n",
        "  ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-m32IoNmSwM"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNzPKiAx0Aa1"
      },
      "outputs": [],
      "source": [
        "vocab = get_vocab(dataset)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZLV2hWf9FN7"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td> \n",
        "    </tr>\n",
        "</table> \n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3KB0fL2zk2v"
      },
      "source": [
        "Ahora diseñe reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una función que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario actualizado. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7g67Ml0aby"
      },
      "source": [
        "    Explique sus reglas aquí:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwQS8lcLJczI"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocab):\n",
        "  ### Aquí inicia tu código ###\n",
        "  pass\n",
        "  ### Aquí termina tu código ###\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onOSuS-_mL2F"
      },
      "outputs": [],
      "source": [
        "vocab = pre_processing(vocab)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65IwHx11uA75"
      },
      "source": [
        "\n",
        "**Ejercicio 3 - *Bag of Words* 🐶🐈(0.5 puntos).** \n",
        " \n",
        "\n",
        "\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n",
        "\n",
        "**disclaimer: El orden de los resultados pueden variar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh-utMuozhsK"
      },
      "outputs": [],
      "source": [
        "d0 = 'El perro se come la comida y después se duerme'\n",
        "d1 = 'El perro se despierta y después empieza a ladrar'\n",
        "d2 = 'El perro ladra y después se come la comida'\n",
        "d3 = 'El gato se come la comida y después se duerme'\n",
        "d4 = 'El gato se despierta y después empieza a maullar'\n",
        "d5 = 'El gato maulla y después se come la comida'\n",
        "dataset = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH7ne8C6ltvE"
      },
      "source": [
        "El objetivo de este ejercicio es determinar cuáles de  los documentos entregados son los más similares entre sí. Para ello utilizaremos la técnica TF-IDF. \n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores numéricos. La representación más simple vista en clases es el **Bag of Words**, método mediante el cuál se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la función **`bag_of_words()`**, que reciba como input un arreglo de documentos y devuelva un pandas dataframe con la representación Bag of Words de los documentos entregados. En esta representación las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el bow de un determinado documento.\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente dataset: \n",
        "\n",
        "```\n",
        "dataset = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXDMAyFmnq5j"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(dataset):\n",
        "  ### Aquí inicia tu código ###\n",
        "  ...\n",
        "  ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okfo-nEQmW1R"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_Kk9GwCoDW8"
      },
      "outputs": [],
      "source": [
        "dataset_bow = bag_of_words(dataset)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeR5ADGz-MPa"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    | El | perro | se | come | la | comida | y | después | duerme | despierta | empieza | a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|---:|------:|---:|-----:|---:|-------:|--:|--------:|-------:|----------:|--------:|--:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 |  1 |     1 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    0 |       0 |      0 |\n",
        "| d1 |  1 |     1 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      1 |     0 |    0 |       0 |      0 |\n",
        "| d2 |  1 |     1 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     1 |    0 |       0 |      0 |\n",
        "| d3 |  1 |     0 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      0 |\n",
        "| d4 |  1 |     0 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      0 |     0 |    1 |       1 |      0 |\n",
        "| d5 |  1 |     0 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      1 |\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4OXMz7opWcd"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 4 - *Calcular TF* (0.5 puntos):** Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la máxima frecuencia ${max_i({\\text{tf}_{i,j})}}$, donde\n",
        "i corresponde al índice de las filas (bow) y j al de las columnas (palabras). Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca más veces en ese vector. \n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWE16xhBpswc"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow):\n",
        "    ### Aquí inicia tu código ###\n",
        "    pass\n",
        "    ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZQPZe3JmYqy"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ2h8jEYp4nZ"
      },
      "outputs": [],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOzdRwx9_UMM"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El | perro |  se | come |  la | comida |   y | después | duerme | despierta | empieza |   a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|----:|------:|----:|-----:|----:|-------:|----:|--------:|-------:|----------:|--------:|----:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 | 0.5 |   0.5 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d1 | 1.0 |   1.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    1.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d2 | 1.0 |   1.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   1.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d3 | 0.5 |   0.0 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.5 |     0.0 |    0.0 |\n",
        "| d4 | 1.0 |   0.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    0.0 |   0.0 |  1.0 |     1.0 |    0.0 |\n",
        "| d5 | 1.0 |   0.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  1.0 |     0.0 |    1.0 |\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqgW4Ni4t0xC"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 5 - *Calcular IDF* (0.5 punto):**\n",
        "\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ número de documentos y $n_i = $ Número de documentos que contienen la palabra $t_i$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thhDY1-Ht6T5"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    ### Aquí inicia tu código ###\n",
        "    pass\n",
        "    ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR_j3pYemcAc"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro-OMGpduC0R"
      },
      "outputs": [],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ioy_HicQDr-a"
      },
      "source": [
        "***Resultado esperado***: \n",
        "\n",
        "```python\n",
        "{'El': 0.0, \n",
        " 'a': 0.47712125471966244,\n",
        " 'come': 0.17609125905568124,\n",
        " 'comida': 0.17609125905568124,\n",
        " 'despierta': 0.47712125471966244,\n",
        " 'después': 0.0,\n",
        " 'duerme': 0.47712125471966244,\n",
        " 'empieza': 0.47712125471966244,\n",
        " 'gato': 0.3010299956639812,\n",
        " 'la': 0.17609125905568124,\n",
        " 'ladra': 0.7781512503836436,\n",
        " 'ladrar': 0.7781512503836436,\n",
        " 'maulla': 0.7781512503836436,\n",
        " 'maullar': 0.7781512503836436,\n",
        " 'perro': 0.3010299956639812,\n",
        " 'se': 0.0,\n",
        " 'y': 0.0}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzKAzJtSJ7gx"
      },
      "source": [
        "Puede notar el bajo puntaje otorgado a las palabras que más se repiten! 😮"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D17lm6l9uJPo"
      },
      "source": [
        "**Ejercicio 6 - *Calcular TF-IDF & concluir similitud de documentos.* (1 punto)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7FTQ19Kcwo"
      },
      "source": [
        "Programe la función `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9knMl0KguMwo"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "    ### Aquí inicia tu código ###\n",
        "\n",
        "    pass\n",
        "\n",
        "    ### Aquí termina tu código ### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRzIr1nQmepp"
      },
      "source": [
        "***Test.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8z6jaq2uPEo"
      },
      "outputs": [],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBG2qfwv_6HK"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El |    perro |  se |     come |       la |   comida |   y | después |   duerme | despierta |  empieza |        a |   ladrar |    ladra |     gato |  maullar |   maulla |\n",
        "|----|----:|---------:|----:|---------:|---------:|---------:|----:|--------:|---------:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
        "| d0 | 0.0 | 0.150515 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d1 | 0.0 | 0.301030 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.778151 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d2 | 0.0 | 0.301030 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.778151 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d3 | 0.0 | 0.000000 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.150515 | 0.000000 | 0.000000 |\n",
        "| d4 | 0.0 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.000000 | 0.000000 | 0.301030 | 0.778151 | 0.000000 |\n",
        "| d5 | 0.0 | 0.000000 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.301030 | 0.000000 | 0.778151 |\n",
        "\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmVlbpzMp5NU"
      },
      "source": [
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante será una matriz simétrica. Implemente la función *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos vectores. Concluya cuáles son los dos documentos más similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEgUtgBkQAae"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "  ### Aquí inicia tu código ###\n",
        "  \n",
        "  pass\n",
        "\n",
        "  ### Aquí termina tu código ### \n",
        "\n",
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUAc1zX0Lg16"
      },
      "source": [
        "![gato](https://live.staticflickr.com/4652/38904147065_0b6c446945_b.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1A95IaXLHaB"
      },
      "source": [
        "**Cualquier recomendación que nos quisieran dar para una futura tarea es bienvenid@!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
