{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbrMqMPyncTC"
      },
      "source": [
        "# **Tarea 1 - CC6205 Natural Language Processing 游닄**\n",
        "\n",
        "**Integrantes:**\n",
        "Ismael Fernandez\n",
        "Yerko Garrido \n",
        "\n",
        "**Fecha l칤mite de entrega 游늱:** Martes 4 de Abril.\n",
        "\n",
        "**Tiempo estimado de dedicaci칩n:** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1HFX-9PpxF9"
      },
      "source": [
        "` ` \n",
        "\n",
        "\n",
        "Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te칩ricos de las primeras semanas de clases, enfocado principalmente en ***Information Retrieval (IR)*** y ***Vector Space Models***. Si a칰n no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una parte te칩rica que busca evaluar conceptos vistos en clases. Seguido por una parte pr치ctica con el f칤n de introducirlos a la programaci칩n en Python enfocada en NLP. \n",
        "\n",
        "` ` \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **m치ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a trav칠s de u-cursos a m치s tardar el d칤a estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook.\n",
        "- Al momento de la revisi칩n tu c칩digo ser치 ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci칩n. \n",
        "- Est치 **PROHIBIDO** usar cualquier librer칤a que implemente los algoritmos pedidos (Spacy, scikit, etc). S칩lo se podr치n utilizar las librer칤as importadas al inicio de la secci칩n de pr치ctica.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav칠s del canal de Discord del curso. \n",
        "\n",
        "\n",
        "\n",
        "Ahora s칤, empecemos! 游땏游\n",
        "\n",
        "` ` \n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "\n",
        "Slides:\n",
        "    \n",
        "- [Introducci칩n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
        "\n",
        "Videos: \n",
        "\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducci칩n parte I](https://www.youtube.com/watch?v=HEKTNOttGvU)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducci칩n parte II](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)\n",
        "\n",
        "` ` \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJshpe1yrKJr"
      },
      "source": [
        "## **1 - Preguntas te칩ricas 游늿 (2 puntos).** ##\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBEDKXBPoA7w"
      },
      "source": [
        "Las siguientes celdas contienen preguntas acerca del contenido visto en clases y en el material del curso.  Contestar cada pregunta en su celda correspondiente y **no extenderse m치s de 100 palabras** . 游똂\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNJPR1kMrw9R"
      },
      "source": [
        "**Pregunta 1 (0.2 puntos): 쯇or qu칠 el an치lisis del lenguaje humano es una tarea compleja? Mencione dos razones seg칰n lo visto en clases. Debe citar la slide donde cree que est치 la respuesta.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTBYHEptdde"
      },
      "source": [
        "``\n",
        "* El lenguaje humano es muy ambiguo: en la diapo n춿4 de la introducci칩n se presenta el ejemplo de la oraci칩n de comer pizza, que a pesar de tener la misma estructura gramatical, se va modificando el sentido del verbo en funci칩n de la 칰ltima palabra. Es decir de comer pizza con amigos, comer pizza con olivas o comer pizza con tenedor. \n",
        "\n",
        "* El Lenguaje humano esta siempre evolucionando: En la diapo n춿4 de la introuducci칩n, se presenta que el lenguaje esta en constante evoluci칩n y que el idioma espa침ol actual, es distinto al idioma espa침ol de nuestros antepasados.\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVMXilrYsiSZ"
      },
      "source": [
        "**Pregunta 2 (0.4 puntos): 쮺u치les son las diferencias entre usar Deep learning y Machine Learning cl치sico (empirismo) para un problema de NLP? Ejemplifique con alguna task.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qu칠 seg칰n lo visto en clases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXWMzpTtBZL"
      },
      "source": [
        "` ` \n",
        "El deep learning es capaz de extraer las relaciones a partir de los datos, en cambio el Machine Learning necesitan de texto etiquetado. Etiquetar es costoso y puede ser sesgado. Por ejemplo en clasificaci칩n de texto si se realiza con entrenamiento con documentos con informaci칩n deportiva no se comportara bien cuando se intente clasificar documentos de politica.\n",
        "\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXc4XuVG7Loa"
      },
      "source": [
        " **Pregunta 3 (0.4 puntos) Seg칰n las primeras clases, 쯈u칠 m칠todo cl치sico nos permite rankear las similitudes existentes entre documentos?, 쮺칩mo son las representaciones que genera y problemas que podr칤an experimentar estas soluciones simples?** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtaQ_aVE8LhH"
      },
      "source": [
        "` ` \n",
        "El metodo cl치sico es el de indice invertido. Genera una representaci칩n del tipo diccionario. Mapea los terminos del vocabulario dentro del texto del siguiente modo: < term > -> < docId >*\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKNDNy047tcY"
      },
      "source": [
        "**Pregunta 4 (0.4 puntos) Usted se encuentra realizando un modelo de clasificaci칩n de sentimientos con texto, su jefe le se침ala que debe eliminar las palabras mas comunes para obtener una mejor clasificaci칩n. 쯈u칠 palabras le se침ala que elimine su jefe?, 쯘s acaso esto una buena idea?.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qu칠 seg칰n lo visto en clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRe4QaGS8MqY"
      },
      "source": [
        "` ` \n",
        "El jefe se refiere a que se deben eliminar las stopwords. Depende de el modelo. Puede ser que dentro de las stop words que son articulos, sustantivos, etc. En analisis de sentiemientos, puede generar problemas al borrar palabras que permiten la negaci칩n.\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPkWmrmLHWnQ"
      },
      "source": [
        "**Pregunta 5 (0.6 puntos): Acorde al paper [A Vector Space Model for automatic indexing](https://dl.acm.org/doi/pdf/10.1145/361219.361220) un documento, $D_i$, puede ser definido formalmente como una tupla de t칠rminos, $(d_{i1}, d_{i2}, ..., d_{in})$, donde $d_{ij}$ representa el peso del j-esimo t칠rmino. En clase vieron algunas formas medir los pesos de estos t칠rminos. Mencione cuales fueron y sus ventajas y desventajas (pueden responder en m치ximo 150 palabras).** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLqRTW08SzDN"
      },
      "source": [
        "` ` \n",
        "Respuesta aqu칤\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fpsz2pQt8x5"
      },
      "source": [
        "## **2 - Preguntas pr치cticas 游눹 (4 puntos).** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB92kQXspvbR"
      },
      "source": [
        "Esta segunda secci칩n incluye ejercicios de programaci칩n 游뱇. Leer atentamente las instrucciones entregadas a continuaci칩n para facilitar el proceso de revisi칩n de sus trabajos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosWgWgRxHKp"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "\n",
        "\n",
        "- Escribe tu c칩digo entre las lineas de comentarios **### Aqu칤 inicia tu c칩digo ###** y **### Aqu칤 termina tu c칩digo ###**.\n",
        "- Cuando el ejercicio incluya un bloque llamado ***Test***, comprueba que el resultado de la ejecuci칩n coincida con el resultado esperado.\n",
        "- Recuerde siempre mantener buenas pr치cticas de c칩digo.\n",
        "- Est치 permitido s칩lo utilizar las librer칤as importadas antes del Ejercicio 1.\n",
        "- **Recordar** que: *Documento = Oraci칩n. Dataset = Corpus. Vocabulario = Tokens*.\n",
        "- El **orden de los resultados** pueden variar dependiendo de su m치quina, pero los valores de los resultados son los mismos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrmFHXhqUww"
      },
      "source": [
        "**Ejemplo:** Implemente una funci칩n **`hello_world()`** que imprima en pantalla `\"Hello World\"`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu7cIsawyJHx"
      },
      "outputs": [],
      "source": [
        "def hello_world():\n",
        "  ### Aqu칤 inicia tu c칩digo ###\n",
        "  print(\"Hello World\")\n",
        "  ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6klw12lwbW"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac-WMk2dyQbp",
        "outputId": "767f01f7-e88a-40c0-920d-c130e810c6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoiAMxtyUjQ"
      },
      "source": [
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td> Hello World </td> \n",
        "    </tr>\n",
        "</table> \n",
        "\n",
        "``\n",
        "``\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPyrPXiH0l4"
      },
      "source": [
        "Estas son las librer칤as permitidas. Si quieren utilizar alguna librer칤a adicional, pueden realizar la consulta a trav칠s de Discord. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CtP6Emjo1kF0"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9Do0LdC9w2"
      },
      "source": [
        "En caso de desarrollar la tarea desde colab, utilizar el siguiente c칩digo para cargar los archivos desde el drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EXq1VDeC-ml",
        "outputId": "52bb41a3-88ed-4cc6-e08c-98b95f4696df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#try:\n",
        "#    from google.colab import drive#\n",
        "\n",
        "#    drive.mount(\"/content/drive\")\n",
        "#    path = 'Colab Notebooks/NLP/Tarea_1/marcianeke.txt'\n",
        "#except: \n",
        "#    print('Ignorando conexi칩n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSN4bBoY2Td4"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Ejercicio 1 - *Tokenizaci칩n* (0.5 puntos).** \n",
        "` `  \n",
        "` ` \n",
        "\n",
        "En el primer ejercicio veremos la dificultad 游땯 de tokenizar textos no estructurados, destacando la importancia de tener librer칤as que realicen este trabajo. \n",
        "\n",
        "El archivo adjunto al enunciado de la tarea contiene la letra de una canci칩n del marcianeke 游놓. Utilice este texto para realizar su primera tokenizaci칩n y ver qu칠 tan bien funciona su funci칩n. \n",
        "\n",
        "Ejecute el c칩digo a continuaci칩n para cargar el ejemplo. Recuerde realizar la modificaci칩n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dYSf9S20bVPV"
      },
      "outputs": [],
      "source": [
        "path='marcianeke.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnNUYlWo21g4",
        "outputId": "fb1e9d8f-00dc-4ec7-a10e-7335c771d2de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brr\n",
            "Marcianeke\n",
            "Vamo' a estar con Pailita\n",
            "Dimelo m치\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar (brr)\n",
            "Tussi, keta quiere' mezclar\n",
            "Dimelo m치\n",
            "\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta pura quiere' mezclar\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "\n",
            "Esperame que ahora entro yo\n",
            "Y lo que pide yo lo traje\n",
            "No visto de traje\n",
            "Puro corte calle, no de maquillaje\n",
            "Pronto coronamos y nos vamo' de viaje\n",
            "Tanto hit que hago que lo' culo bajen\n",
            "Ella se va de shopping\n",
            "Sale positivo si se hace el doping\n",
            "Baila twerk con un poco de popping\n",
            "Los fardos en el bot칤n\n",
            "\n",
            "Si quieren letra llamen pa' mi booking\n",
            "Generando, sigo en la m칤a lowkey\n",
            "Cooking en el estudio con tu woman\n",
            "Tanto whisky, pisco que hasta lo' vecinos toman\n",
            "Si se tiran pa' aca puede que la arena coman\n",
            "Ja, en el chanteo titulado sin diploma\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "Di-dimelo m치\n",
            "\n",
            "Ah, pe-peligrosa\n",
            "Quiero ver como perreando me acosa\n",
            "Eso de atra' con el Gucci me lo roza\n",
            "Tengo tussi del naranjo me aburrio el rosa\n",
            "Capaz que tosa con el blunt\n",
            "Sprite con Flemibron\n",
            "Louis Vuitton, le quito la polera Champion\n",
            "A tu pretendiente con la fory lo espanto\n",
            "Puro perro, le doy de comer Champion Dog\n",
            "Ese toto lo corono yo\n",
            "La movie en play no hay stop\n",
            "Flow de sobra no hay stock\n",
            "Me la topo en la disco queda en shock\n",
            "My love, rica en las redes y en persona\n",
            "No usa Photoshop\n",
            "La llevo a comprar blone' al growshop\n",
            "En ropa interior los do'\n",
            "Me roza su vicky con mi boxer Top\n",
            "Dimelo m치\n",
            "Ando en busca de una cri\n",
            "minal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta quiere' mezclar\n",
            "Dimelo m치\n",
            "\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta pura quiere' mezclar\n",
            "Marcianeke, Pailita\n",
            "Young Varas\n"
          ]
        }
      ],
      "source": [
        "text = codecs.open(path, 'r', 'UTF-8').read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIaOYzMk3v1X"
      },
      "source": [
        "Implementen una funci칩n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Son libres de elegir la forma de tokenizar mientras no utilicen librer칤as con tokenizadores ya implementados. Pueden utilizar la librer칤a **re** importada para trabajar s칤mbolos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dl42-hgIhqB"
      },
      "source": [
        "Ejemplo de uso:\n",
        "\n",
        "`get_tokens('Este es un ejemplo de prueba.')` \n",
        "\n",
        "Nos entregar칤a:\n",
        "\n",
        "`['Este', 'es', 'un', 'ejemplo', 'de', 'prueba', '.']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IF1RcIwq4G2x"
      },
      "outputs": [],
      "source": [
        "from posixpath import split\n",
        "def get_tokens(text):\n",
        "  ### Inicio del c칩digo ###\n",
        "  tokens_=[]\n",
        "  tokens=re.sub(r'\\r\\n{1,}',' ',text)\n",
        "  tokens=tokens.split(' ')\n",
        "\n",
        "  for token in tokens:\n",
        "    for i in re.split(r'\\W',token):\n",
        "      if len(i)>=1:\n",
        "        tokens_+=[i]\n",
        "    tokens_+= re.findall(r'\\W',token)\n",
        "\n",
        "  ### Fin del c칩digo ###\n",
        "  return tokens_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqlSpefv4_EH",
        "outputId": "6588badf-0fc4-4089-d730-10dd53fc0aad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Brr',\n",
              " 'Marcianeke',\n",
              " 'Vamo',\n",
              " \"'\",\n",
              " 'a',\n",
              " 'estar',\n",
              " 'con',\n",
              " 'Pailita',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " 'ah',\n",
              " '(',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " 'rata',\n",
              " 'ta',\n",
              " '(',\n",
              " '-',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'brr',\n",
              " '(',\n",
              " ')',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " 'ah',\n",
              " '(',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " 'rata',\n",
              " 'ta',\n",
              " '(',\n",
              " '-',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Esperame',\n",
              " 'que',\n",
              " 'ahora',\n",
              " 'entro',\n",
              " 'yo',\n",
              " 'Y',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'pide',\n",
              " 'yo',\n",
              " 'lo',\n",
              " 'traje',\n",
              " 'No',\n",
              " 'visto',\n",
              " 'de',\n",
              " 'traje',\n",
              " 'Puro',\n",
              " 'corte',\n",
              " 'calle',\n",
              " ',',\n",
              " 'no',\n",
              " 'de',\n",
              " 'maquillaje',\n",
              " 'Pronto',\n",
              " 'coronamos',\n",
              " 'y',\n",
              " 'nos',\n",
              " 'vamo',\n",
              " \"'\",\n",
              " 'de',\n",
              " 'viaje',\n",
              " 'Tanto',\n",
              " 'hit',\n",
              " 'que',\n",
              " 'hago',\n",
              " 'que',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'culo',\n",
              " 'bajen',\n",
              " 'Ella',\n",
              " 'se',\n",
              " 'va',\n",
              " 'de',\n",
              " 'shopping',\n",
              " 'Sale',\n",
              " 'positivo',\n",
              " 'si',\n",
              " 'se',\n",
              " 'hace',\n",
              " 'el',\n",
              " 'doping',\n",
              " 'Baila',\n",
              " 'twerk',\n",
              " 'con',\n",
              " 'un',\n",
              " 'poco',\n",
              " 'de',\n",
              " 'popping',\n",
              " 'Los',\n",
              " 'fardos',\n",
              " 'en',\n",
              " 'el',\n",
              " 'bot칤n',\n",
              " 'Si',\n",
              " 'quieren',\n",
              " 'letra',\n",
              " 'llamen',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'mi',\n",
              " 'booking',\n",
              " 'Generando',\n",
              " ',',\n",
              " 'sigo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'm칤a',\n",
              " 'lowkey',\n",
              " 'Cooking',\n",
              " 'en',\n",
              " 'el',\n",
              " 'estudio',\n",
              " 'con',\n",
              " 'tu',\n",
              " 'woman',\n",
              " 'Tanto',\n",
              " 'whisky',\n",
              " ',',\n",
              " 'pisco',\n",
              " 'que',\n",
              " 'hasta',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'vecinos',\n",
              " 'toman',\n",
              " 'Si',\n",
              " 'se',\n",
              " 'tiran',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'aca',\n",
              " 'puede',\n",
              " 'que',\n",
              " 'la',\n",
              " 'arena',\n",
              " 'coman',\n",
              " 'Ja',\n",
              " ',',\n",
              " 'en',\n",
              " 'el',\n",
              " 'chanteo',\n",
              " 'titulado',\n",
              " 'sin',\n",
              " 'diploma',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Di',\n",
              " 'dimelo',\n",
              " '-',\n",
              " 'm치',\n",
              " 'Ah',\n",
              " ',',\n",
              " 'pe',\n",
              " 'peligrosa',\n",
              " '-',\n",
              " 'Quiero',\n",
              " 'ver',\n",
              " 'como',\n",
              " 'perreando',\n",
              " 'me',\n",
              " 'acosa',\n",
              " 'Eso',\n",
              " 'de',\n",
              " 'atra',\n",
              " \"'\",\n",
              " 'con',\n",
              " 'el',\n",
              " 'Gucci',\n",
              " 'me',\n",
              " 'lo',\n",
              " 'roza',\n",
              " 'Tengo',\n",
              " 'tussi',\n",
              " 'del',\n",
              " 'naranjo',\n",
              " 'me',\n",
              " 'aburrio',\n",
              " 'el',\n",
              " 'rosa',\n",
              " 'Capaz',\n",
              " 'que',\n",
              " 'tosa',\n",
              " 'con',\n",
              " 'el',\n",
              " 'blunt',\n",
              " 'Sprite',\n",
              " 'con',\n",
              " 'Flemibron',\n",
              " 'Louis',\n",
              " 'Vuitton',\n",
              " ',',\n",
              " 'le',\n",
              " 'quito',\n",
              " 'la',\n",
              " 'polera',\n",
              " 'Champion',\n",
              " 'A',\n",
              " 'tu',\n",
              " 'pretendiente',\n",
              " 'con',\n",
              " 'la',\n",
              " 'fory',\n",
              " 'lo',\n",
              " 'espanto',\n",
              " 'Puro',\n",
              " 'perro',\n",
              " ',',\n",
              " 'le',\n",
              " 'doy',\n",
              " 'de',\n",
              " 'comer',\n",
              " 'Champion',\n",
              " 'Dog',\n",
              " 'Ese',\n",
              " 'toto',\n",
              " 'lo',\n",
              " 'corono',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'movie',\n",
              " 'en',\n",
              " 'play',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stop',\n",
              " 'Flow',\n",
              " 'de',\n",
              " 'sobra',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stock',\n",
              " 'Me',\n",
              " 'la',\n",
              " 'topo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'disco',\n",
              " 'queda',\n",
              " 'en',\n",
              " 'shock',\n",
              " 'My',\n",
              " 'love',\n",
              " ',',\n",
              " 'rica',\n",
              " 'en',\n",
              " 'las',\n",
              " 'redes',\n",
              " 'y',\n",
              " 'en',\n",
              " 'persona',\n",
              " 'No',\n",
              " 'usa',\n",
              " 'Photoshop',\n",
              " 'La',\n",
              " 'llevo',\n",
              " 'a',\n",
              " 'comprar',\n",
              " 'blone',\n",
              " \"'\",\n",
              " 'al',\n",
              " 'growshop',\n",
              " 'En',\n",
              " 'ropa',\n",
              " 'interior',\n",
              " 'los',\n",
              " 'do',\n",
              " \"'\",\n",
              " 'Me',\n",
              " 'roza',\n",
              " 'su',\n",
              " 'vicky',\n",
              " 'con',\n",
              " 'mi',\n",
              " 'boxer',\n",
              " 'Top',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'cri',\n",
              " 'minal',\n",
              " 'ah',\n",
              " '(',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " 'rata',\n",
              " 'ta',\n",
              " '(',\n",
              " '-',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " 'ah',\n",
              " '(',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " 'rata',\n",
              " 'ta',\n",
              " '(',\n",
              " '-',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Marcianeke',\n",
              " ',',\n",
              " 'Pailita',\n",
              " 'Young',\n",
              " 'Varas']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = get_tokens(text)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbgTvAW-stF"
      },
      "source": [
        "**Describa cu치les fueron sus supuestos para realizar la tokenizaci칩n y compare sus tokens con los entregados por la librer칤a nltk en el bloque de c칩digo de m치s abajo.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGQ7CJy3-3aH"
      },
      "source": [
        "Supuestos aqui\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYtmAXTr9KXK",
        "outputId": "4981a15d-89bc-4972-f91a-f4afe42659a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Brr',\n",
              " 'Marcianeke',\n",
              " 'Vamo',\n",
              " \"'\",\n",
              " 'a',\n",
              " 'estar',\n",
              " 'con',\n",
              " 'Pailita',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " '(',\n",
              " 'brr',\n",
              " ')',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Esperame',\n",
              " 'que',\n",
              " 'ahora',\n",
              " 'entro',\n",
              " 'yo',\n",
              " 'Y',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'pide',\n",
              " 'yo',\n",
              " 'lo',\n",
              " 'traje',\n",
              " 'No',\n",
              " 'visto',\n",
              " 'de',\n",
              " 'traje',\n",
              " 'Puro',\n",
              " 'corte',\n",
              " 'calle',\n",
              " ',',\n",
              " 'no',\n",
              " 'de',\n",
              " 'maquillaje',\n",
              " 'Pronto',\n",
              " 'coronamos',\n",
              " 'y',\n",
              " 'nos',\n",
              " 'vamo',\n",
              " \"'\",\n",
              " 'de',\n",
              " 'viaje',\n",
              " 'Tanto',\n",
              " 'hit',\n",
              " 'que',\n",
              " 'hago',\n",
              " 'que',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'culo',\n",
              " 'bajen',\n",
              " 'Ella',\n",
              " 'se',\n",
              " 'va',\n",
              " 'de',\n",
              " 'shopping',\n",
              " 'Sale',\n",
              " 'positivo',\n",
              " 'si',\n",
              " 'se',\n",
              " 'hace',\n",
              " 'el',\n",
              " 'doping',\n",
              " 'Baila',\n",
              " 'twerk',\n",
              " 'con',\n",
              " 'un',\n",
              " 'poco',\n",
              " 'de',\n",
              " 'popping',\n",
              " 'Los',\n",
              " 'fardos',\n",
              " 'en',\n",
              " 'el',\n",
              " 'bot칤n',\n",
              " 'Si',\n",
              " 'quieren',\n",
              " 'letra',\n",
              " 'llamen',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'mi',\n",
              " 'booking',\n",
              " 'Generando',\n",
              " ',',\n",
              " 'sigo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'm칤a',\n",
              " 'lowkey',\n",
              " 'Cooking',\n",
              " 'en',\n",
              " 'el',\n",
              " 'estudio',\n",
              " 'con',\n",
              " 'tu',\n",
              " 'woman',\n",
              " 'Tanto',\n",
              " 'whisky',\n",
              " ',',\n",
              " 'pisco',\n",
              " 'que',\n",
              " 'hasta',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'vecinos',\n",
              " 'toman',\n",
              " 'Si',\n",
              " 'se',\n",
              " 'tiran',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'aca',\n",
              " 'puede',\n",
              " 'que',\n",
              " 'la',\n",
              " 'arena',\n",
              " 'coman',\n",
              " 'Ja',\n",
              " ',',\n",
              " 'en',\n",
              " 'el',\n",
              " 'chanteo',\n",
              " 'titulado',\n",
              " 'sin',\n",
              " 'diploma',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Ah',\n",
              " ',',\n",
              " 'pe',\n",
              " '-',\n",
              " 'peligrosa',\n",
              " 'Quiero',\n",
              " 'ver',\n",
              " 'como',\n",
              " 'perreando',\n",
              " 'me',\n",
              " 'acosa',\n",
              " 'Eso',\n",
              " 'de',\n",
              " 'atra',\n",
              " \"'\",\n",
              " 'con',\n",
              " 'el',\n",
              " 'Gucci',\n",
              " 'me',\n",
              " 'lo',\n",
              " 'roza',\n",
              " 'Tengo',\n",
              " 'tussi',\n",
              " 'del',\n",
              " 'naranjo',\n",
              " 'me',\n",
              " 'aburrio',\n",
              " 'el',\n",
              " 'rosa',\n",
              " 'Capaz',\n",
              " 'que',\n",
              " 'tosa',\n",
              " 'con',\n",
              " 'el',\n",
              " 'blunt',\n",
              " 'Sprite',\n",
              " 'con',\n",
              " 'Flemibron',\n",
              " 'Louis',\n",
              " 'Vuitton',\n",
              " ',',\n",
              " 'le',\n",
              " 'quito',\n",
              " 'la',\n",
              " 'polera',\n",
              " 'Champion',\n",
              " 'A',\n",
              " 'tu',\n",
              " 'pretendiente',\n",
              " 'con',\n",
              " 'la',\n",
              " 'fory',\n",
              " 'lo',\n",
              " 'espanto',\n",
              " 'Puro',\n",
              " 'perro',\n",
              " ',',\n",
              " 'le',\n",
              " 'doy',\n",
              " 'de',\n",
              " 'comer',\n",
              " 'Champion',\n",
              " 'Dog',\n",
              " 'Ese',\n",
              " 'toto',\n",
              " 'lo',\n",
              " 'corono',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'movie',\n",
              " 'en',\n",
              " 'play',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stop',\n",
              " 'Flow',\n",
              " 'de',\n",
              " 'sobra',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stock',\n",
              " 'Me',\n",
              " 'la',\n",
              " 'topo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'disco',\n",
              " 'queda',\n",
              " 'en',\n",
              " 'shock',\n",
              " 'My',\n",
              " 'love',\n",
              " ',',\n",
              " 'rica',\n",
              " 'en',\n",
              " 'las',\n",
              " 'redes',\n",
              " 'y',\n",
              " 'en',\n",
              " 'persona',\n",
              " 'No',\n",
              " 'usa',\n",
              " 'Photoshop',\n",
              " 'La',\n",
              " 'llevo',\n",
              " 'a',\n",
              " 'comprar',\n",
              " 'blone',\n",
              " \"'\",\n",
              " 'al',\n",
              " 'growshop',\n",
              " 'En',\n",
              " 'ropa',\n",
              " 'interior',\n",
              " 'los',\n",
              " 'do',\n",
              " \"'\",\n",
              " 'Me',\n",
              " 'roza',\n",
              " 'su',\n",
              " 'vicky',\n",
              " 'con',\n",
              " 'mi',\n",
              " 'boxer',\n",
              " 'Top',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'cri',\n",
              " 'minal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Marcianeke',\n",
              " ',',\n",
              " 'Pailita',\n",
              " 'Young',\n",
              " 'Varas']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize \n",
        "nltk_tokens = wordpunct_tokenize(text)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5QKlXAZwN1L"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 2 - *Stopwords y Stemming* (1 punto).** \n",
        "` `  \n",
        "` ` \n",
        "\n",
        "Considere el siguiente corpus:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sEp83zESwb2j"
      },
      "outputs": [],
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjdlJWuyS2E"
      },
      "source": [
        "Dise침e una funci칩n **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando. Puede utilizar la funci칩n del Ejercicio 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UudC-b6TzZgw"
      },
      "outputs": [],
      "source": [
        "def get_vocab(dataset):\n",
        "  \n",
        "  ### Aqu칤 inicia tu c칩digo ###\n",
        "  vocab=[]\n",
        "  for data in dataset:\n",
        "    vocab_ = get_tokens(data)\n",
        "    #apply lowercase:\n",
        "    vocab_ = [word.lower() for word in vocab_]\n",
        "    vocab+=vocab_\n",
        "  return list(set(vocab))\n",
        "  ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-m32IoNmSwM"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNzPKiAx0Aa1",
        "outputId": "6b0d9286-e90d-4d76-b352-273d43883972"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'languages',\n",
              " 'favorite',\n",
              " 'spanish',\n",
              " 'programming',\n",
              " 'my',\n",
              " 'is',\n",
              " 'language',\n",
              " 'like',\n",
              " 'human']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = get_vocab(dataset)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZLV2hWf9FN7"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td> \n",
        "    </tr>\n",
        "</table> \n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3KB0fL2zk2v"
      },
      "source": [
        "Ahora dise침e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci칩n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario actualizado. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7g67Ml0aby"
      },
      "source": [
        "    Explique sus reglas aqu칤:\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remover StopWords:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dise침amos una lista de stopwords especifico para este dataset:\n",
        "stopwords = ['is', 'my', 'i']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is a stopword\n"
          ]
        }
      ],
      "source": [
        "#check if a word is a stopword:\n",
        "if 'my' in stop_words:\n",
        "  print('is a stopword')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#download a stopwords list\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "#print only the first 10 stopwords\n",
        "stop_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is is a stopword\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#function to remove stopwords\n",
        "def remove_stopwords(tokens, stopwords):\n",
        "\n",
        "    tokens_=[]\n",
        "    for token in tokens:\n",
        "        if token not in stopwords:\n",
        "            tokens_.append(token)\n",
        "    return tokens_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I',\n",
              " 'languages',\n",
              " 'favorite',\n",
              " 'Spanish',\n",
              " 'programming',\n",
              " 'my',\n",
              " 'is',\n",
              " 'language',\n",
              " 'like',\n",
              " 'human']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove stopwords from the tokens\n",
        "vocab_sin_SW = remove_stopwords(vocab, stop_words)\n",
        "vocab_sin_SW"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Aplicar Steaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#funcion que aplica stemming a una lista de tokens:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwQS8lcLJczI"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocab):\n",
        "\n",
        "  pass\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onOSuS-_mL2F"
      },
      "outputs": [],
      "source": [
        "vocab = pre_processing(vocab)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65IwHx11uA75"
      },
      "source": [
        "\n",
        "**Ejercicio 3 - *Bag of Words* 游냤游낻(0.5 puntos).** \n",
        " \n",
        "\n",
        "\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n",
        "\n",
        "**disclaimer: El orden de los resultados pueden variar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh-utMuozhsK"
      },
      "outputs": [],
      "source": [
        "d0 = 'El perro se come la comida y despu칠s se duerme'\n",
        "d1 = 'El perro se despierta y despu칠s empieza a ladrar'\n",
        "d2 = 'El perro ladra y despu칠s se come la comida'\n",
        "d3 = 'El gato se come la comida y despu칠s se duerme'\n",
        "d4 = 'El gato se despierta y despu칠s empieza a maullar'\n",
        "d5 = 'El gato maulla y despu칠s se come la comida'\n",
        "dataset = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH7ne8C6ltvE"
      },
      "source": [
        "El objetivo de este ejercicio es determinar cu치les de  los documentos entregados son los m치s similares entre s칤. Para ello utilizaremos la t칠cnica TF-IDF. \n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num칠ricos. La representaci칩n m치s simple vista en clases es el **Bag of Words**, m칠todo mediante el cu치l se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funci칩n **`bag_of_words()`**, que reciba como input un arreglo de documentos y devuelva un pandas dataframe con la representaci칩n Bag of Words de los documentos entregados. En esta representaci칩n las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el bow de un determinado documento.\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente dataset: \n",
        "\n",
        "```\n",
        "dataset = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXDMAyFmnq5j"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(dataset):\n",
        "  ### Aqu칤 inicia tu c칩digo ### \n",
        "  \n",
        "  column=[]\n",
        "  for i in dataset:\n",
        "    column+=get_tokens(i)\n",
        "  column=['docId']+list(set(column)) \n",
        "\n",
        "  df=pd.DataFrame()\n",
        "  for i,j in enumerate(dataset):\n",
        "    token=get_tokens(j)\n",
        "    data={'docId':[f'd{i}']*len(token),'token':token, 'valor':[1]*len(token)}\n",
        "    df_=pd.DataFrame(data=data)\n",
        "    df=pd.concat([df,df_], axis=0, ignore_index=False)\n",
        "  df=pd.pivot_table(df,values='valor', index='docId', columns='token',aggfunc='sum',fill_value=0).reset_index()\n",
        "  df=df.fillna(0)\n",
        "  df=pd.DataFrame(data=df[column].values.tolist(),columns=column)\n",
        "  df.columns=column\n",
        "  dfi=df.set_index('docId')\n",
        "  del df\n",
        "  return dfi\n",
        "\n",
        "\n",
        "  ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okfo-nEQmW1R"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "T_Kk9GwCoDW8",
        "outputId": "513d7b6d-55f7-4a56-8574-8c0edc6c048a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-97767f86-b0bf-47d0-ab00-ee9c1880c8aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>la</th>\n",
              "      <th>come</th>\n",
              "      <th>y</th>\n",
              "      <th>despierta</th>\n",
              "      <th>se</th>\n",
              "      <th>empieza</th>\n",
              "      <th>gato</th>\n",
              "      <th>El</th>\n",
              "      <th>maullar</th>\n",
              "      <th>maulla</th>\n",
              "      <th>comida</th>\n",
              "      <th>duerme</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>despu칠s</th>\n",
              "      <th>ladra</th>\n",
              "      <th>perro</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>docId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97767f86-b0bf-47d0-ab00-ee9c1880c8aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97767f86-b0bf-47d0-ab00-ee9c1880c8aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97767f86-b0bf-47d0-ab00-ee9c1880c8aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       a  la  come  y  despierta  se  empieza  gato  El  maullar  maulla  \\\n",
              "docId                                                                      \n",
              "d0     0   1     1  1          0   2        0     0   1        0       0   \n",
              "d1     1   0     0  1          1   1        1     0   1        0       0   \n",
              "d2     0   1     1  1          0   1        0     0   1        0       0   \n",
              "d3     0   1     1  1          0   2        0     1   1        0       0   \n",
              "d4     1   0     0  1          1   1        1     1   1        1       0   \n",
              "d5     0   1     1  1          0   1        0     1   1        0       1   \n",
              "\n",
              "       comida  duerme  ladrar  despu칠s  ladra  perro  \n",
              "docId                                                 \n",
              "d0          1       1       0        1      0      1  \n",
              "d1          0       0       1        1      0      1  \n",
              "d2          1       0       0        1      1      1  \n",
              "d3          1       1       0        1      0      0  \n",
              "d4          0       0       0        1      0      0  \n",
              "d5          1       0       0        1      0      0  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(dataset)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeR5ADGz-MPa"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    | El | perro | se | come | la | comida | y | despu칠s | duerme | despierta | empieza | a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|---:|------:|---:|-----:|---:|-------:|--:|--------:|-------:|----------:|--------:|--:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 |  1 |     1 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    0 |       0 |      0 |\n",
        "| d1 |  1 |     1 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      1 |     0 |    0 |       0 |      0 |\n",
        "| d2 |  1 |     1 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     1 |    0 |       0 |      0 |\n",
        "| d3 |  1 |     0 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      0 |\n",
        "| d4 |  1 |     0 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      0 |     0 |    1 |       1 |      0 |\n",
        "| d5 |  1 |     0 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      1 |\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4OXMz7opWcd"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 4 - *Calcular TF* (0.5 puntos):** Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m치xima frecuencia ${max_i({\\text{tf}_{i,j})}}$, donde\n",
        "i corresponde al 칤ndice de las filas (bow) y j al de las columnas (palabras). Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca m치s veces en ese vector. \n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWE16xhBpswc"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow):\n",
        "    ### Aqu칤 inicia tu c칩digo ###\n",
        "    df=pd.DataFrame()\n",
        "    for i,index in enumerate(dataset_bow.index):\n",
        "      df_= dataset_bow.iloc[i, :]/np.max(dataset_bow.iloc[i, :].values.tolist()) \n",
        "      df=pd.concat([df,df_],axis=1)\n",
        "    \n",
        "    return df.T\n",
        "    ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZQPZe3JmYqy"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "YQ2h8jEYp4nZ",
        "outputId": "bbe06c48-1ee9-465d-9ed9-03b8e21615fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8042ecce-1188-45af-886b-f76f7e3f91e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>la</th>\n",
              "      <th>come</th>\n",
              "      <th>y</th>\n",
              "      <th>despierta</th>\n",
              "      <th>se</th>\n",
              "      <th>empieza</th>\n",
              "      <th>gato</th>\n",
              "      <th>El</th>\n",
              "      <th>maullar</th>\n",
              "      <th>maulla</th>\n",
              "      <th>comida</th>\n",
              "      <th>duerme</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>despu칠s</th>\n",
              "      <th>ladra</th>\n",
              "      <th>perro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8042ecce-1188-45af-886b-f76f7e3f91e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8042ecce-1188-45af-886b-f76f7e3f91e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8042ecce-1188-45af-886b-f76f7e3f91e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      a   la  come    y  despierta   se  empieza  gato   El  maullar  maulla  \\\n",
              "d0  0.0  0.5   0.5  0.5        0.0  1.0      0.0   0.0  0.5      0.0     0.0   \n",
              "d1  1.0  0.0   0.0  1.0        1.0  1.0      1.0   0.0  1.0      0.0     0.0   \n",
              "d2  0.0  1.0   1.0  1.0        0.0  1.0      0.0   0.0  1.0      0.0     0.0   \n",
              "d3  0.0  0.5   0.5  0.5        0.0  1.0      0.0   0.5  0.5      0.0     0.0   \n",
              "d4  1.0  0.0   0.0  1.0        1.0  1.0      1.0   1.0  1.0      1.0     0.0   \n",
              "d5  0.0  1.0   1.0  1.0        0.0  1.0      0.0   1.0  1.0      0.0     1.0   \n",
              "\n",
              "    comida  duerme  ladrar  despu칠s  ladra  perro  \n",
              "d0     0.5     0.5     0.0      0.5    0.0    0.5  \n",
              "d1     0.0     0.0     1.0      1.0    0.0    1.0  \n",
              "d2     1.0     0.0     0.0      1.0    1.0    1.0  \n",
              "d3     0.5     0.5     0.0      0.5    0.0    0.0  \n",
              "d4     0.0     0.0     0.0      1.0    0.0    0.0  \n",
              "d5     1.0     0.0     0.0      1.0    0.0    0.0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOzdRwx9_UMM"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El | perro |  se | come |  la | comida |   y | despu칠s | duerme | despierta | empieza |   a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|----:|------:|----:|-----:|----:|-------:|----:|--------:|-------:|----------:|--------:|----:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 | 0.5 |   0.5 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d1 | 1.0 |   1.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    1.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d2 | 1.0 |   1.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   1.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d3 | 0.5 |   0.0 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.5 |     0.0 |    0.0 |\n",
        "| d4 | 1.0 |   0.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    0.0 |   0.0 |  1.0 |     1.0 |    0.0 |\n",
        "| d5 | 1.0 |   0.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  1.0 |     0.0 |    1.0 |\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqgW4Ni4t0xC"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 5 - *Calcular IDF* (0.5 punto):**\n",
        "\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ n칰mero de documentos y $n_i = $ N칰mero de documentos que contienen la palabra $t_i$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thhDY1-Ht6T5"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    ### Aqu칤 inicia tu c칩digo ###\n",
        "    N=dataset_bow.shape[0]    \n",
        "    dataset_bow=dataset_bow.T\n",
        "    palabras=dataset_bow.shape[0]\n",
        "    diccionario={}\n",
        "\n",
        "    for i in range(0,palabras):\n",
        "      token=dataset_bow.reset_index().iloc[i,0]\n",
        "      ni=np.sum(dataset_bow.iloc[i,0:].values.tolist())\n",
        "      idf=np.log10(N/ni)\n",
        "      diccionario[f'{token}']= 0 if idf <0 else idf    \n",
        "    \n",
        "      del token\n",
        "      del ni\n",
        "      del idf\n",
        "      \n",
        "    return diccionario\n",
        "    \n",
        "\n",
        "\n",
        "    ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR_j3pYemcAc"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro-OMGpduC0R",
        "outputId": "c9192bbf-16a8-454c-b901-41c8700d8da1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': 0.47712125471966244,\n",
              " 'la': 0.17609125905568124,\n",
              " 'come': 0.17609125905568124,\n",
              " 'y': 0.0,\n",
              " 'despierta': 0.47712125471966244,\n",
              " 'se': 0,\n",
              " 'empieza': 0.47712125471966244,\n",
              " 'gato': 0.3010299956639812,\n",
              " 'El': 0.0,\n",
              " 'maullar': 0.7781512503836436,\n",
              " 'maulla': 0.7781512503836436,\n",
              " 'comida': 0.17609125905568124,\n",
              " 'duerme': 0.47712125471966244,\n",
              " 'ladrar': 0.7781512503836436,\n",
              " 'despu칠s': 0.0,\n",
              " 'ladra': 0.7781512503836436,\n",
              " 'perro': 0.3010299956639812}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ioy_HicQDr-a"
      },
      "source": [
        "***Resultado esperado***: \n",
        "\n",
        "```python\n",
        "{'El': 0.0, \n",
        " 'a': 0.47712125471966244,\n",
        " 'come': 0.17609125905568124,\n",
        " 'comida': 0.17609125905568124,\n",
        " 'despierta': 0.47712125471966244,\n",
        " 'despu칠s': 0.0,\n",
        " 'duerme': 0.47712125471966244,\n",
        " 'empieza': 0.47712125471966244,\n",
        " 'gato': 0.3010299956639812,\n",
        " 'la': 0.17609125905568124,\n",
        " 'ladra': 0.7781512503836436,\n",
        " 'ladrar': 0.7781512503836436,\n",
        " 'maulla': 0.7781512503836436,\n",
        " 'maullar': 0.7781512503836436,\n",
        " 'perro': 0.3010299956639812,\n",
        " 'se': 0.0,\n",
        " 'y': 0.0}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzKAzJtSJ7gx"
      },
      "source": [
        "Puede notar el bajo puntaje otorgado a las palabras que m치s se repiten! 游땵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D17lm6l9uJPo"
      },
      "source": [
        "**Ejercicio 6 - *Calcular TF-IDF & concluir similitud de documentos.* (1 punto)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7FTQ19Kcwo"
      },
      "source": [
        "Programe la funci칩n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9knMl0KguMwo"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "    ### Aqu칤 inicia tu c칩digo ###\n",
        "\n",
        "    return tf*idf\n",
        "\n",
        "    ### Aqu칤 termina tu c칩digo ### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRzIr1nQmepp"
      },
      "source": [
        "***Test.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "H8z6jaq2uPEo",
        "outputId": "28a2746f-8f51-4a8b-92bc-b547e701edcd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-017bdfcd-5b61-4328-ac56-9854063d78fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>la</th>\n",
              "      <th>come</th>\n",
              "      <th>y</th>\n",
              "      <th>despierta</th>\n",
              "      <th>se</th>\n",
              "      <th>empieza</th>\n",
              "      <th>gato</th>\n",
              "      <th>El</th>\n",
              "      <th>maullar</th>\n",
              "      <th>maulla</th>\n",
              "      <th>comida</th>\n",
              "      <th>duerme</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>despu칠s</th>\n",
              "      <th>ladra</th>\n",
              "      <th>perro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.238561</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.301030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.238561</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-017bdfcd-5b61-4328-ac56-9854063d78fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-017bdfcd-5b61-4328-ac56-9854063d78fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-017bdfcd-5b61-4328-ac56-9854063d78fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           a        la      come    y  despierta   se   empieza      gato  \\\n",
              "d0  0.000000  0.088046  0.088046  0.0   0.000000  0.0  0.000000  0.000000   \n",
              "d1  0.477121  0.000000  0.000000  0.0   0.477121  0.0  0.477121  0.000000   \n",
              "d2  0.000000  0.176091  0.176091  0.0   0.000000  0.0  0.000000  0.000000   \n",
              "d3  0.000000  0.088046  0.088046  0.0   0.000000  0.0  0.000000  0.150515   \n",
              "d4  0.477121  0.000000  0.000000  0.0   0.477121  0.0  0.477121  0.301030   \n",
              "d5  0.000000  0.176091  0.176091  0.0   0.000000  0.0  0.000000  0.301030   \n",
              "\n",
              "     El   maullar    maulla    comida    duerme    ladrar  despu칠s     ladra  \\\n",
              "d0  0.0  0.000000  0.000000  0.088046  0.238561  0.000000      0.0  0.000000   \n",
              "d1  0.0  0.000000  0.000000  0.000000  0.000000  0.778151      0.0  0.000000   \n",
              "d2  0.0  0.000000  0.000000  0.176091  0.000000  0.000000      0.0  0.778151   \n",
              "d3  0.0  0.000000  0.000000  0.088046  0.238561  0.000000      0.0  0.000000   \n",
              "d4  0.0  0.778151  0.000000  0.000000  0.000000  0.000000      0.0  0.000000   \n",
              "d5  0.0  0.000000  0.778151  0.176091  0.000000  0.000000      0.0  0.000000   \n",
              "\n",
              "       perro  \n",
              "d0  0.150515  \n",
              "d1  0.301030  \n",
              "d2  0.301030  \n",
              "d3  0.000000  \n",
              "d4  0.000000  \n",
              "d5  0.000000  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBG2qfwv_6HK"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El |    perro |  se |     come |       la |   comida |   y | despu칠s |   duerme | despierta |  empieza |        a |   ladrar |    ladra |     gato |  maullar |   maulla |\n",
        "|----|----:|---------:|----:|---------:|---------:|---------:|----:|--------:|---------:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
        "| d0 | 0.0 | 0.150515 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d1 | 0.0 | 0.301030 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.778151 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d2 | 0.0 | 0.301030 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.778151 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d3 | 0.0 | 0.000000 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.150515 | 0.000000 | 0.000000 |\n",
        "| d4 | 0.0 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.000000 | 0.000000 | 0.301030 | 0.778151 | 0.000000 |\n",
        "| d5 | 0.0 | 0.000000 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.301030 | 0.000000 | 0.778151 |\n",
        "\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmVlbpzMp5NU"
      },
      "source": [
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser치 una matriz sim칠trica. Implemente la funci칩n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos vectores. Concluya cu치les son los dos documentos m치s similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEgUtgBkQAae"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "  ### Aqu칤 inicia tu c칩digo ###\n",
        "  num=np.dot(v1,v2)\n",
        "  den=np.linalg.norm(v1)*np.linalg.norm(v2)\n",
        "  return num/den\n",
        "\n",
        "\n",
        "  ### Aqu칤 termina tu c칩digo ### \n",
        "\n",
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE0YD3issnZ3",
        "outputId": "05775e6a-a166-4b74-cdb8-ac3d7dd2abf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.12032418, 0.3223436 , 0.77967014, 0.        ,\n",
              "        0.1632828 ],\n",
              "       [0.12032418, 1.        , 0.08686457, 0.        , 0.4952126 ,\n",
              "        0.        ],\n",
              "       [0.3223436 , 0.08686457, 1.        , 0.1632828 , 0.        ,\n",
              "        0.11787732],\n",
              "       [0.77967014, 0.        , 0.1632828 , 1.        , 0.12032418,\n",
              "        0.3223436 ],\n",
              "       [0.        , 0.4952126 , 0.        , 0.12032418, 1.        ,\n",
              "        0.08686457],\n",
              "       [0.1632828 , 0.        , 0.11787732, 0.3223436 , 0.08686457,\n",
              "        1.        ]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarity_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUAc1zX0Lg16"
      },
      "source": [
        "![gato](https://live.staticflickr.com/4652/38904147065_0b6c446945_b.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1A95IaXLHaB"
      },
      "source": [
        "**Cualquier recomendaci칩n que nos quisieran dar para una futura tarea es bienvenid@!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
