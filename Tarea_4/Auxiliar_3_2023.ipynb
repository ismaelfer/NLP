{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rc4NC3hnhjZ"
      },
      "source": [
        "<h1><center>Auxiliar 3: Introducci√≥n a Pytorch üî•</center></h1>\n",
        "\n",
        "<center><strong>CC6205: Procesamiento del Lenguaje Natural</strong></center>\n",
        "\n",
        "\n",
        "## üìö **Objetivos de la clase** üìö\n",
        "\n",
        "La clase auxiliar de esta semana tendr√° varios objetivos:\n",
        "\n",
        "- Introducir PyTorch, un Framework para trabajar con Deep Learning\n",
        "- Definir y explicar el concepto de Tensor.\n",
        "- Motivar el uso de Mini-Batch.\n",
        "- Explicar el uso de GPU en Deep Learning.\n",
        "- Explicar el c√°lculo de derivadas con PyTorch.\n",
        "- Construir un modelo de Embedding m√°s una red Feed Forward üò≤\n",
        "- Construir un modelo de Embedding m√°s una CNN üò≤\n",
        "\n",
        "Una vez resuelto, pueden utilizar cualquier parte del c√≥digo que les parezca prudente para futuras tareas üòä."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLLTxJRSwscP"
      },
      "source": [
        "# **Parte 1: Introducci√≥n**\n",
        "\n",
        "<!-- Tomar en consideracion que los chicos no han visto nada practico en deep learning. No se les explicaron cosas como optimizers, schedulers, etc asique hay que ser pedagogicos.\n",
        "\n",
        "* Motivacion, trabajo con tensores, dimensionalidad alta, optimizacion en gpu, utilidad de computo por batch (eficiencia, robustez del modelo, etc)\n",
        "\n",
        "\n",
        "* introducir la api, las operaciones basicas, operaciones de creacion, operaciones inplace, cambiar la forma de los tensores, etc\n",
        "\n",
        "* mostrar el uso de la gpu con ejemplos (mostrar nvidia-smi), revisar codigo agnostico al dispositivo -->\n",
        "\n",
        "\n",
        "------------------------------------------------------\n",
        "En esta auxiliar vamos a introducir PyTorch, un framework para hacer deep learning, y tambi√©n mostrar dos aplicaciones. Esta herramienta va a ser usada de aqu√≠ hasta el final del curso, as√≠ que es importante que tengan un conocimiento base sobre este framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2EvTlRNbfSV"
      },
      "source": [
        "## **¬øQu√© es PyTorch exactamente?**\n",
        "\n",
        "PyTorch es un framework para hacer Deep Learning. Las caracter√≠sticas principales que ofrece son:\n",
        "\n",
        "- Operaciones basicas con **tensores**.\n",
        "- Usar facilmente y de forma transparente la **GPU**, si es que existe.\n",
        "- Utilidades ya implementadas para acelerar el desarrollo de **redes neuronales**. Capas lineales, capas recurrentes, capas convolucionales, funciones de activaci√≥n, funciones de p√©rdida, etc.\n",
        "- Motor de **diferenciaci√≥n y propagaci√≥n de gradientes autom√°tico**. Se guarda un registro de las operaciones que se realizan sobre un tensor y luego se puede calcular autom√°ticamente la derivada de un tensor de salida con respecto a los par√°metros que estuvieron involucrados es un c√°lculo.\n",
        "\n",
        "<!-- Como les decia, PyTorch es un framework para hacer deep learning. Las caracteristicas principales de un framework de este tipo es que permite trabajar y realizar operaciones basicas con tensores (abajo explicamos que son y por qu√© nos interesan), permite usar facilmente y de forma transparente la GPU, si es que existe (mas delante explicamos por que querriamos hacer esto)  y tambien viene con varias utilidades ya implementadas para acelerar el desarrollo de redes neuronales. Por ejemplo, viene con varios modulos de redes neuronales, como capas lineales (como las que vieron en clases), capas recurrentes, capas convulocionales (estas se ven mas adelante), funciones de activacion, funciones de perdida, etc. Finalmente, y quiza lo mas importante del framework, es que viene con un motor de diferenciacion y propagacion de gradientes automatico, es decir, se guarda un registro de las operaciones que se realizan sobre un tensor y luego se puede calcular automaticamente la derivada de un tensor de salida con respecto a los parametros que estuvieron involucrados en su calculo.\n",
        "\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woZQw3j2bkPw"
      },
      "source": [
        "## **¬øQu√© es un tensor?**\n",
        "\n",
        "Un tensor es una estructura matem√°tica para organizar datos. De toda la vida hemos sabido lo que es un **n√∫mero**. En √°lgebra lineal vimos que podemos organizar (de forma indexada) varios n√∫meros en lo que llamamos **vector**, y luego extendimos esta organizaci√≥n a una estructura bidimensional, una **matriz**, con filas y columnas.\n",
        "\n",
        "Los **tensores** son una forma de generalizar esta idea. Decimos que un numero wacho es un tensor de 0 dimensiones, un **vector** es un tensor de **1 dimensi√≥n** y una **matriz** es un tensor de **2 dimensiones**. Este concepto nos permite generalizar esta organizaci√≥n de los datos sobre dimensiones mayores. Podemos hablar, por ejemplo, de un **cubo** (un tensor de 3 dimensiones), que se podr√≠a interpretar como varias matrices apiladas, o m√°s generalmente un **tensor de N dimensiones** donde N es un n√∫mero cualquiera (entre mas grande N mas dif√≠cil de imaginar :D).\n",
        "\n",
        "Los tensores de dimensiones mayores se los pueden imaginar como listas, donde sus elementos son tensores de dimensiones menores. Esto lo pueden ver en la siguiente fotaza:\n",
        "\n",
        "(source: knoldus)\n",
        "\n",
        "![visualizacion tensor](https://i.stack.imgur.com/Lv1qU.jpg)\n",
        "\n",
        "Otro Ejemplo un poco mas burdo:\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1tb7popMBUSSj4YzD-Ypytoo6n7PbXzuJ\" width=300 height=300 />\n",
        "</center>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-CrbVL5bsrm"
      },
      "source": [
        "## **¬øPor qu√© me interesan los tensores?**\n",
        "\n",
        "Cuando uno trabaja en Deep Learning, es muy com√∫n encontrarse con datos de **alta dimensionalidad**.\n",
        "\n",
        "En **NLP** por ejemplo, en el capitulo de embeddings vimos que es √∫til representar una **palabra** como un **vector** que captura informaci√≥n de la palabra, ya sea de su contexto, de los caracteres que contiene, etc.\n",
        "\n",
        "![imagen.png](data:image/png;base64,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)\n",
        "\n",
        "Tomando esto en cuenta, vemos que una lista de palabras (una frase) la podemos representar como una **matriz**. A estas alturas ya tenemos un **tensor de 2 dimensiones**\n",
        "\n",
        "![imagen.png](data:image/png;base64,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)\n",
        "\n",
        "¬øQu√© pasa si por alguna raz√≥n queremos operar sobre varias frases a la vez? ¬øQu√© pasa si tenemos una lista de frases? Bueno, ahora tenemos un \"cubo\", un tensor de 3 dimensiones, donde la primera dimensiones corresponde a cada frase dentro del conjunto, la segunda a cada palabra dentro de la frase y finalmente la tercera a cada una las posiciones dentro del vector de embeddings.\n",
        "\n",
        "![imagen.png](data:image/png;base64,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)\n",
        "\n",
        "Esto se repite en muchas m√°s √°reas, por ejemplo una imagen RGB es un tensor de 3 dimensiones, un video, donde hay una lista de im√°genes se puede interpretar como un tensor de 4 dimensiones, y as√≠.\n",
        "\n",
        "Analizar **varios elementos a la vez** es una pr√°ctica com√∫n en Deep Learning. Esto hace que el manejo de **tensores** se vuelva importante debido a que normalmente aumentamos en uno el n√∫mero de dimensiones de los ejemplos al hacer esto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQgtuoz9p9W_"
      },
      "source": [
        "## **Mini-Batches y entrenamiento**\n",
        "\n",
        "En clases se vio que la forma en la que se entrenan las redes neuronales es un **proceso iterativo**, donde en primer lugar se realiza una **predicci√≥n que es mala**, **se calcula una funci√≥n de perdida**, **para cada par√°metro se calcula el gradiente de la _loss_ con respecto a este par√°metro** y luego **se desciende en la direcci√≥n de este gradiente para tratar de llevar los par√°metros a los valores que minimizan la funci√≥n de perdida**.\n",
        "\n",
        "Si este proceso iterativo se llevara a cabo de a un ejemplo a la vez, el valor de **la _loss_ ser√≠a muy dependiente del ejemplo concreto que se acaba de observar** y podr√≠a no ser representativo de la _loss_ general. Esto resulta en actualizaciones ruidosas de los par√°metros, porque la _loss_ para el siguiente ejemplo puede ser muy distinta al valor anterior y as√≠ es como los par√°metros pueden oscilar y tener dificultad para converger.\n",
        "\n",
        "Ac√° es donde nos viene a rescatar el concepto de **_mini-batch_**. Un **Mini-Batch** es un **peque√±o subconjunto aleatorio de muestras** de los datos de entrenamiento. Los ejemplos se pasan por la red en **grupos peque√±os** para que cada conjunto produzca una  **_loss_ m√°s representativa**. Esto le agrega robustez al modelo y lo **ayuda a converger**. El tama√±o del _mini-batch_ (cantidad de ejemplos que se pasan a la vez) se vuelve un hiper par√°metro de la red. Los valores √≥ptimos de tama√±o de _mini-batch_ pueden variar mucho, pero los n√∫meros que yo he visto var√≠an entre 8 y 32, aunque para algunas aplicaciones he visto valores del orden de 1000.\n",
        "\n",
        "\n",
        "Pueden leer un poco m√°s [ac√°](https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/) o [ac√°](https://ruder.io/optimizing-gradient-descent/), la secci√≥n introductoria lo explica un poco en m√°s detalle, y cita al libro [Deep Learning](https://www.deeplearningbook.org/), que es muy weno :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVtK2_G4bBsp"
      },
      "source": [
        "<br>\n",
        "<center>\n",
        "<img src=\"https://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif\" width=300 height=300 />\n",
        "</center>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqCm5gsibx5s"
      },
      "source": [
        "\n",
        "\n",
        "## **Ejemplos**\n",
        "La API realmente es muy similar a la de Numpy, asique veremos solo unos pocos ejemplos. La documentaci√≥n sobre los tensores la pueden ver [ac√°](https://pytorch.org/docs/stable/tensors.html) y la documentacion general de las operaciones sobre tensores que ofrece pytorch esta [ac√°](https://pytorch.org/docs/stable/torch.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTn7dZVwq-SO",
        "outputId": "c10c3966-1d64-40c0-faed-dd692d4307a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.7.0\n"
          ]
        }
      ],
      "source": [
        "# Instalamos portalocker para luego acceder a los datasets de Pytorch\n",
        "!pip install portalocker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsaS37KAzZoj",
        "outputId": "8f2687be-ed36-4084-d4dd-b5557c65630d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.15)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Nos aseguramos que pytorch y torchtext esten en la ultima version\n",
        "!pip install torch -U\n",
        "!pip install torchtext -U\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhqLuYsIYTtt",
        "outputId": "693866ab-36a9-4c6c-cfbe-72e1c2a31fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desde una lista de listas\n",
            " tensor([[2, 3, 4],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Dimensiones del tensor\n",
            " torch.Size([2, 3])\n",
            "\n",
            "Numero de dimensiones del tensor\n",
            " 2\n"
          ]
        }
      ],
      "source": [
        "# Creacion de un tensor a partir de otra estructura\n",
        "a = [[2,3,4], [4,5,6]]\n",
        "t = torch.tensor(a)\n",
        "print(\"Desde una lista de listas\\n\", t)\n",
        "print(\"\\nDimensiones del tensor\\n\", t.size())\n",
        "print(\"\\nNumero de dimensiones del tensor\\n\", t.dim())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbmxaTNpeeCI",
        "outputId": "d8366134-e2e6-4208-c524-75506de0dca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor vacio\n",
            " tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "# Creacion de un tensor \"vacio\"\n",
        "t = torch.empty(2,2,3)\n",
        "print(\"Tensor vacio\\n\", t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4oh5DZJehaF",
        "outputId": "fa2069a7-609a-4461-b32f-892ae9861a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puros unos\n",
            " tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "# Creacion de tensores con puros 1 o puros ceros\n",
        "t = torch.ones(2,3,4)\n",
        "# t = torch.zeros(2,3,4,5)\n",
        "print(\"Puros unos\\n\", t) # notar la tercera dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PLHgzdMe2cb",
        "outputId": "b7bb5ace-0d43-45e3-e206-9341e09b340e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribucion uniforme\n",
            " tensor([[0.3622, 0.7138],\n",
            "        [0.0177, 0.9653],\n",
            "        [0.7910, 0.9969]])\n",
            "\n",
            "Distribucion normal\n",
            " tensor([[-1.8151,  0.0762, -1.1272],\n",
            "        [ 1.5216,  0.9126, -0.3856]])\n"
          ]
        }
      ],
      "source": [
        "# Random sampling\n",
        "t = torch.empty(3, 2).uniform_() # notar operacion in-place\n",
        "print(\"Distribucion uniforme\\n\", t)\n",
        "\n",
        "t = torch.randn(2, 3)\n",
        "print(\"\\nDistribucion normal\\n\", t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33AQwoOXobdD",
        "outputId": "dbccc524-1ff8-488c-b466-d8f85414abb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operaciones con escalares\n",
            " tensor([[6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.]])\n"
          ]
        }
      ],
      "source": [
        "# Operaciones matematicas\n",
        "t = torch.ones(3,4)\n",
        "print(\"Operaciones con escalares\\n\", t + 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBINbVumph2W",
        "outputId": "ab65b020-2ce9-4788-e81f-1797419fe6e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Operaciones entre tensores\n",
        "t1 = torch.ones(2, 3)\n",
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2fJNHSJisbC",
        "outputId": "3b3b69d2-24d4-405b-bc32-6459a3cc36d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operaciones entre tensores\n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ],
      "source": [
        "t2 = torch.ones(2, 3) * 2\n",
        "print(\"Operaciones entre tensores\\n\", t1 + t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ouTAQYXxyH",
        "outputId": "30880b5d-a6f0-4d30-d00e-1496927c6985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suma in-place\n",
            " tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ]
        }
      ],
      "source": [
        "# Tambien se pueden hacer operaciones in-place, se modifica el mismo tensor\n",
        "t = torch.ones(2,3)\n",
        "t.add_(1)\n",
        "print(\"Suma in-place\\n\", t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N33ZYc3LYH94",
        "outputId": "7a1cf312-219d-4be6-b697-2ee2d39463f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de partida\n",
            " torch.Size([16])\n",
            "\n",
            "Usamos el metodo .view() y el -1 para que torch infiera dimensiones\n",
            " torch.Size([2, 8])\n",
            "\n",
            "Podemos volver a aplanar el tensor con .flatten()\n",
            " torch.Size([16])\n",
            "\n",
            "Podemos agregar dimensiones sin agregar datos con .unsqueeze()\n",
            " torch.Size([4, 1, 4])\n",
            "\n",
            "Con .squeeze() podemos sacar todas las dimensiones de tama√±o 1\n",
            " torch.Size([4, 4])\n"
          ]
        }
      ],
      "source": [
        "# Hay veces que es util reorganizar los datos de un tensor, o agregar\n",
        "# dimensiones\n",
        "t = torch.arange(16)\n",
        "print(\"Dimensiones de partida\\n\", t.shape)\n",
        "\n",
        "t = t.view(-1, 8)\n",
        "print(\"\\nUsamos el metodo .view() y el -1 para que torch infiera dimensiones\\n\", t.shape)\n",
        "\n",
        "t = t.flatten() # Aqui tambien se podria usar .view(-1)\n",
        "print(\"\\nPodemos volver a aplanar el tensor con .flatten()\\n\", t.shape)\n",
        "\n",
        "t = t.view(-1, 4).unsqueeze(1) # tambien podria ser .view(-1, 1, 4)\n",
        "print(\"\\nPodemos agregar dimensiones sin agregar datos con .unsqueeze()\\n\", t.shape)\n",
        "\n",
        "t = t.squeeze()\n",
        "print(\"\\nCon .squeeze() podemos sacar todas las dimensiones de tama√±o 1\\n\", t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6MMvvLpL3ro",
        "outputId": "8ebc9fbc-adcf-41b7-8d64-76e93ae746cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dim=0: tensor([-2.0317,  3.2109,  3.9659, -2.3611,  2.0870, -0.5390, -1.8922,  0.9365,\n",
            "         3.0435,  0.1149])\n",
            "dim=1: tensor([-2.1338,  3.8021, -1.3782,  1.7595,  4.4852])\n"
          ]
        }
      ],
      "source": [
        "# Podemos hacer las tipicas sumas\n",
        "t = torch.randn(5, 10)\n",
        "# dim = 0 es suma de filas y 1 de columnas\n",
        "print(f\"dim=0: {t.sum(dim=0)}\")\n",
        "print(f\"dim=1: {t.sum(dim=1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aoqanb1yNtTe"
      },
      "outputs": [],
      "source": [
        "# Tal como con numpy podemos hacer funciones\n",
        "def softmax(T, dim):\n",
        "  T = torch.as_tensor(T)\n",
        "  T = T - torch.max(T)\n",
        "  deno = torch.exp(T)\n",
        "  suma = torch.sum(torch.exp(T), dim=dim, keepdim=True)\n",
        "  output = deno/suma\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGcH3FZqOBOz",
        "outputId": "c47878ec-0bb6-4330-ae62-746ef3bd00e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0054, 0.0704, 0.0274, 0.0212, 0.0399, 0.0093, 0.0299, 0.0046, 0.0257,\n",
              "         0.0248, 0.0420, 0.0315, 0.0839, 0.0160, 0.0153, 0.0034, 0.0144, 0.0369,\n",
              "         0.0971, 0.0120, 0.0083, 0.0699, 0.0094, 0.0057, 0.0087, 0.0049, 0.0234,\n",
              "         0.0255, 0.2015, 0.0134, 0.0142, 0.0042],\n",
              "        [0.0179, 0.0024, 0.0129, 0.0122, 0.0180, 0.0012, 0.0079, 0.0133, 0.0211,\n",
              "         0.0165, 0.0125, 0.0069, 0.0048, 0.0537, 0.0606, 0.0137, 0.0153, 0.0039,\n",
              "         0.0510, 0.0365, 0.1179, 0.0415, 0.0071, 0.0267, 0.0082, 0.0115, 0.0094,\n",
              "         0.0126, 0.0048, 0.0270, 0.0010, 0.3496],\n",
              "        [0.0183, 0.0413, 0.0406, 0.0109, 0.0587, 0.0117, 0.0062, 0.0090, 0.0328,\n",
              "         0.1288, 0.0484, 0.0246, 0.0158, 0.0086, 0.0339, 0.0211, 0.1779, 0.0149,\n",
              "         0.0818, 0.0236, 0.0127, 0.0215, 0.0083, 0.0098, 0.0520, 0.0197, 0.0062,\n",
              "         0.0296, 0.0056, 0.0197, 0.0024, 0.0037],\n",
              "        [0.0109, 0.0152, 0.0126, 0.0249, 0.0393, 0.0289, 0.0264, 0.0079, 0.0632,\n",
              "         0.0146, 0.0581, 0.1166, 0.0272, 0.0814, 0.0149, 0.0100, 0.0116, 0.0171,\n",
              "         0.0618, 0.0087, 0.0042, 0.0254, 0.0020, 0.0035, 0.0044, 0.0050, 0.0148,\n",
              "         0.0759, 0.0332, 0.1598, 0.0083, 0.0118],\n",
              "        [0.0529, 0.0670, 0.0086, 0.0449, 0.0268, 0.1578, 0.0064, 0.0065, 0.0117,\n",
              "         0.0065, 0.0325, 0.0321, 0.0282, 0.0090, 0.0280, 0.0055, 0.0117, 0.0204,\n",
              "         0.0113, 0.0584, 0.0490, 0.0172, 0.0912, 0.0086, 0.0139, 0.0021, 0.0389,\n",
              "         0.0234, 0.0105, 0.0334, 0.0182, 0.0673]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.randn(5, 32)\n",
        "softmax(t, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noj-NgUarIXt"
      },
      "source": [
        "## **GPUs y Deep Learning**\n",
        "\n",
        "La **GPU** es lo mismo que la **tarjeta de video** de los computadores. Es un chip que esta dise√±ado para manipular gran cantidad de matrices de p√≠xeles, aplicarles transformaciones, y enviarlas a la pantalla para que las podamos ver. Lo interesante de las **GPU** es que est√°n pensadas espec√≠ficamente para paralelizar c√°lculos debido a su aplicaci√≥n en **matrices**.\n",
        "\n",
        "Como referencia un procesador multi-nucleo tiene entre 4 y 16 n√∫cleos actualmente, mientras que una **GPU** puede f√°cilmente superar los 1000 n√∫cleos (aunque son m√°s simples).\n",
        "\n",
        "La mayor√≠a de las operaciones tensoriales se pueden paralelizar, por lo que la GPU se aprovecha de esta propiedad y es capaz de realizar operaciones sobre una matriz completa en **un solo ciclo de reloj** (muy muy r√°pido). Esto puede mejorar el tiempo de computaci√≥n hasta por un factor de 100 en cierto casos.\n",
        "\n",
        "Es por esto que las GPUs se usan tanto en deep learning, porque el **deep learning esta basado en operaciones b√°sicas sobre tensores**, pero en cantidades enormes. Nos estamos aprovechando de a√±os de investigaci√≥n y desarrollo en c√≥mo subir los FPS de tu juego favorito para darle un uso ~~productivo~~ cient√≠fico.\n",
        "\n",
        "Si bien las GPU son la principal componente utilizada para realizar deep learning, el 2018 Google hizo publicas unos procesadores llamaods [TPU](https://cloud.google.com/tpu?hl=es-419), quienes permiten realizar una parelizaci√≥n extrema en las operaciones. A pesar de sus beneficios, actualmente estos dispositivos solo se encuentran disponibles en los nubes de Google (de puro taca√±os..)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "QKNjqMt5qFIJ",
        "outputId": "080fb94c-e167-45c5-871a-ca1c11b92916"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe \n",
              "    width=\"560\"\n",
              "    height=\"315\"\n",
              "    src=\"https://www.youtube.com/embed/-P28LKWTzrI\"\n",
              "    frameborder=\"0\"\n",
              "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
              "    allowfullscreen>\n",
              "</iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe\n",
        "    width=\"560\"\n",
        "    height=\"315\"\n",
        "    src=\"https://www.youtube.com/embed/-P28LKWTzrI\"\n",
        "    frameborder=\"0\"\n",
        "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
        "    allowfullscreen>\n",
        "</iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3in0Nv1fZ9N"
      },
      "source": [
        "\n",
        "## **Usando la GPU en PyTorch**\n",
        "\n",
        "Otra de las gracias de **PyTorch** es que permite **interactuar con la GPU** de forma muy transparente para el usuario. Mover **tensores** desde la CPU (que es donde se crean por default) hacia la GPU se hace en una pura l√≠nea, y adem√°s es muy simple escribir c√≥digo **agn√≥stico** al dispositivo, lo que significa que si el sistema donde se corre el c√≥digo dispone de GPUs estas se ocupan, pero si no, se ocupa la CPU nom√°s.\n",
        "\n",
        "A continuaci√≥n hay unos ejemplos, y pueden leer m√°s al respecto [ac√°](https://pytorch.org/docs/stable/notes/cuda.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8EjrIZnypw5",
        "outputId": "9ccb4855-89e5-4526-8481-127279a5efc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 18 18:19:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Primero usemos un comando de shell para obtener informacion de la GPU\n",
        "# Recuerden cambiar el runtime del colab\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgAok3BJzSWi",
        "outputId": "c2a89e00-092e-4f39-9f38-a75e95c2e19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Habemus GPU? True\n",
            "Cuantas GPUs me regala Google? 1\n"
          ]
        }
      ],
      "source": [
        "# Verificar si cuda esta disponible en el entorno\n",
        "print(\"Habemus GPU?\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available(): # Usar esto para codigo agnostico\n",
        "    print(\"Cuantas GPUs me regala Google?\", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1cyvw3mzeMP",
        "outputId": "e29828a5-7200-434f-dd52-4c1b6be1f70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los tensores se instancian en la cpu por default\n",
            "Pero se pueden mover al dispositivo cuda:0 usando el methodo .cuda()\n",
            "Tambien se pueden llevar a cuda:0 usando el metodo .to()\n"
          ]
        }
      ],
      "source": [
        "# Mover tensores entre gpu y cpu\n",
        "t = torch.empty(3, 4)\n",
        "print(f\"Los tensores se instancian en la {t.device} por default\")\n",
        "\n",
        "t = t.cuda() # .cuda() retorna un nuevo tensor en GPU\n",
        "print(f\"Pero se pueden mover al dispositivo {t.device} usando el methodo .cuda()\")\n",
        "\n",
        "t = torch.empty(3, 4).to(\"cuda\") # Tambien se puede usar con \"cpu\"\n",
        "print(f\"Tambien se pueden llevar a {t.device} usando el metodo .to()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeYMoyGFv9zO",
        "outputId": "5e4bf078-a931-4fbc-db8e-7874dee1d6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 18 18:19:35 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W /  70W |    601MiB / 15360MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Veamos el uso de la gpu\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IisFuXt1Bqi",
        "outputId": "42e0ad31-55b4-4e1c-9642-47d9e4fe8f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 18 18:19:35 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W /  70W |   6325MiB / 15360MiB |      2%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Ahora creemos un tensor tremendo\n",
        "t = torch.empty(6000, 1000, 1000, device=\"cuda\", dtype=torch.int8) # Cada elemento pesa 1 byte\n",
        "\n",
        "# Y veamos cuanta VRAM estamos usando\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi57aSyh12CV"
      },
      "source": [
        "## Oye pero mi GPU no es tan bac√°n, no tengo tanta VRAM, me voy a echar el ramo u.u\n",
        "\n",
        "Pucha, las GPUs son caras, pero por suerte Google se ba√±a en dinero y nos regala tiempo de GPU en Colab.\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "    Google \\downarrow\n",
        "\\end{equation}\n",
        "\n",
        "<center><img src=\"https://media.giphy.com/media/Xy2PrQq6BIw7u/giphy.gif\"></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn0RaV-s4kx_"
      },
      "source": [
        "## **Derivar con PyTorch**\n",
        "\n",
        "<center><img src=\"https://pytorch.org/assets/images/computational_graph_reverse_auto_differentiation.png\" height=300></center>\n",
        "\n",
        "Otra gracia m√°s de PyTorch (un framework muy agraciado) es que puede **almacenar el grafo de computaci√≥n** luego de realizar **operaciones sobre tensores**. Adem√°s, todas las **funciones** que usa el framework tienen sus respectivas **derivadas implementadas**, lo permite que se pueda calcular la derivada de un **nodo ra√≠z del grafo de computaci√≥n (tensores de salida)** con respecto una **hoja (tensores de entrada)**. M√°s informaci√≥n con respecto a autograd se puede revisar [ac√°](https://pytorch.org/docs/stable/notes/autograd.html).\n",
        "\n",
        "\n",
        "\n",
        "Veamos un ejemplo super simple (para mantenerlo simple, todas las operaciones son punto a punto). Queremos derivar la siguiente expresi√≥n:\n",
        "\n",
        "$$out = mean(x^2 + log(x))$$\n",
        "\n",
        "Asumamos que $x$ es un **tensor** de **una sola dimensi√≥n**, pero la explicaci√≥n aplica tambi√©n para tensores de m√°s dimensiones. Notemos tambi√©n que $out$ es un escalar.\n",
        "\n",
        "Podemos definir una variable auxiliar como:\n",
        "$$u = x^2 + log(x)$$\n",
        "\n",
        "Con lo cual:\n",
        "$$out = mean(u)$$\n",
        "\n",
        "Al derivarlo tenemos:\n",
        "$$\\frac{\\partial out}{\\partial x_i} = \\sum_j\\frac{\\partial out}{\\partial u_j}\\frac{\\partial u_j}{\\partial x_i}$$\n",
        "\n",
        "Reemplazando tenemos:\n",
        "$$\\frac{\\partial out}{\\partial x_i} = \\sum_j\\frac{\\partial mean(u)}{\\partial u_j}\\frac{\\partial (x_j^2 + log(x_j))}{\\partial x_i}$$\n",
        "\n",
        "\n",
        "###Primera parte de la derivada\n",
        "Veamos primero como queda la primera derivada.\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial mean(u)}{\\partial u_j} = \\frac{1}{len(u)}\\frac{u_1 + \\dots + u_j + \\dots + u_n}{\\partial u_j} = \\frac{1}{len(u)}, \\forall j\n",
        "\\end{equation}\n",
        "\n",
        "Si se fijan, el largo de un vector no depende de ning√∫n valor espec√≠fico, y como el promedio es una suma de los elementos del tensor, la derivada es $\\frac{1}{len(y)}$.\n",
        "\n",
        "###Segunda parte de la derivada\n",
        "La siguiente derivada es m√°s f√°cil, ya que son solo operaciones punto a punto. Todas las posiciones que no dependen de la posici√≥n _i-esima_ se van a cero. La derivada queda como sigue.\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\frac{\\partial (x_j^2 + log(x_j))}{\\partial x_i} & =\n",
        "\\begin{cases}\n",
        "2x_i + \\frac{1}{x_i} & \\text{ if } j = i \\\\\n",
        "0 & \\text{ if } j \\neq i\n",
        "\\end{cases} \\\\\n",
        "\\sum_j \\frac{\\partial (x_j^2 + log(x_j))}{\\partial x_i} & = 2x_i + \\frac{1}{x_i}\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Con estas dos derivadas calculadas podemos volver a la ecuaci√≥n incial y calcular el valor total de la derivada original. Queda de la siguiente forma (m√°s un poco de algebra para que la ecuaci√≥n quede bonita).\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial out}{\\partial x_i} = \\frac{2x_i^2 + 1}{x_ilen(x)}\n",
        "\\end{equation}\n",
        "\n",
        "Si probamos con el vector $x=[1,2,3,4]$, reemplazando en la formula deber√≠amos obtener que el gradiente con respecto a $x$ es $[\\frac{3}{4},\\frac{9}{8},\\frac{19}{12},\\frac{33}{16}] = [0.75, 1.125, 1.5833, 2.0625]$\n",
        "\n",
        "Ahora veamos como pytorch lo hace todo autom√°ticamente. ~~Para no hacer esto nunca m√°s~~."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxDqe1fn4juH",
        "outputId": "f8df2bde-99b0-4993-c724-909dfd75a85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradiente de out con respecto a x\n",
            " tensor([0.7500, 1.1250, 1.5833, 2.0625])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(1., 5., requires_grad=True) # Se registra en el grafo de computacion\n",
        "out = torch.mean(x**2 + torch.log(x))\n",
        "out.backward() # Se usa backpropagation para calcular gradientes\n",
        "\n",
        "print(\"Gradiente de out con respecto a x\\n\", x.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENHIYO-LOjuf",
        "outputId": "dae91013-f8f5-4b4f-e8ec-1649b4474573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2., 2.]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Otro ejemplo no esta de mas (mas simple)\n",
        "y = torch.ones(3,5, requires_grad=True)\n",
        "z = torch.sum(y**2+10)\n",
        "z.backward()\n",
        "y.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCldodKYqVVV"
      },
      "source": [
        "## **Recomendaciones**\n",
        "\n",
        "La api de PyTorch es **gigante** as√≠ que yo recomiendo que cuando quieran realizar alguna operaci√≥n sobre un tensor y no pillen f√°cilmente en la documentaci√≥n una forma directa de hacerlo, nos pregunten nom√°s. Preguntas del tipo: \"como hago x en pytorch\" o \"como hago y en pytorch\" son perfectamente razonables, no tengan verguenza de preguntar en el foro/discord :D\n",
        "\n",
        "Hasta ac√° llega la introducci√≥n a [PyTorch](https://pytorch.org/), cualquier duda extra nos pueden preguntar extensivamente en el foro o por Discord .\n",
        "\n",
        "\n",
        "_Eso es todo amigos_\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "u-AOSmuAsmA8",
        "outputId": "dd38bbb1-b1c8-4152-c113-8fb480abafbc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe \n",
              "    width=\"560\"\n",
              "    height=\"315\"\n",
              "    src=\"https://www.youtube.com/embed/Ga_RwPmx-N0\"\n",
              "    frameborder=\"0\"\n",
              "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
              "    allowfullscreen>\n",
              "</iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe\n",
        "    width=\"560\"\n",
        "    height=\"315\"\n",
        "    src=\"https://www.youtube.com/embed/Ga_RwPmx-N0\"\n",
        "    frameborder=\"0\"\n",
        "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
        "    allowfullscreen>\n",
        "</iframe>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z3WpurA4hIx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46jrmdTCxmC1"
      },
      "source": [
        "# Parte 2: Clasificaci√≥n de Texto usando la librer√≠a torchtext (Embeddings + FeedForward)\n",
        "\n",
        "Ahora usaremos capas de Embedding y en redes feed forward para la clasificaci√≥n de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2T2cua6q11t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCYwbzIolQZg"
      },
      "source": [
        "## Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_a7nTyllOUS"
      },
      "source": [
        "Descargu√©mos el dataset que usaremos en los ejmplos de esta parte de la auxiliar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiTRFyZBlV_4",
        "outputId": "39a6b030-7907-4a74-86c4-8ef1bcb4721b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-18 18:19:35--  http://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz [following]\n",
            "--2023-05-18 18:19:35--  https://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9304385 (8.9M) [application/octet-stream]\n",
            "Saving to: ‚Äòcomplete_data.csv.gz‚Äô\n",
            "\n",
            "complete_data.csv.g 100%[===================>]   8.87M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-18 18:19:36 (89.1 MB/s) - ‚Äòcomplete_data.csv.gz‚Äô saved [9304385/9304385]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n",
        "# !gunzip complete_data.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvUG4iRIlYHP",
        "outputId": "935ec2bd-56bd-49d5-a95a-6a50e63ab250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ejemplo aleatorio:\n",
            " ('Solidaridad', 'ser generoso con la comunidad y sobre todo con quienes se ven m√°s desprotegidos')\n",
            "\n",
            "Ejemplo aleatorio:\n",
            " ('Democracia', 'el cambio constitucional es un proceso ciudadano que trasladar√° a las instituciones, los valores, principios, derechos, deberes e instituciones.')\n",
            "\n",
            "Ejemplo aleatorio:\n",
            " ('Democracia', 'nuestra opini√≥n es importante porque nosotros formamos el estado. todos podemos elegir y no solo los que han recibido una educaci√≥n mejor.')\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import csv\n",
        "with gzip.open('complete_data.csv.gz', 'rt') as f:\n",
        "  data = csv.DictReader(f, strict=True, escapechar=\"\\\\\")\n",
        "\n",
        "  # Para este ejemplo solo voy a trabajar con documentos de la categoria 1, \"Valores\"\n",
        "  dataset = tuple(\n",
        "      # Usemos lowercase para que el vocabulario no quede tan grande\n",
        "      (row[\"constitutional_concept\"], row[\"argument\"].lower())\n",
        "      for row in data if row[\"topic\"] == \"1\" and row[\"argument\"]\n",
        "  )\n",
        "\n",
        "dataset = dataset[:10000]\n",
        "\n",
        "# Mostremos algunos ejemplos\n",
        "from random import sample\n",
        "for example in sample(dataset, 3):\n",
        "    print(\"\\nEjemplo aleatorio:\\n\", example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvvzxraUlaCY"
      },
      "source": [
        "## Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOIc2PHhldJ_",
        "outputId": "9ddc6851-8b19-4e5e-ad17-0fa8a5119bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Algunos ejemplos del dataset:\n",
            "('Respeto', 'es un valor fundamental el respeto, como signo vivo de la aceptaci√≥n incondicional de unos con otros, a pesar de nuestras diferencias pol√≠ticas, religiosas, sociales, etc')\n",
            "('Respeto', 'debido a que el concepto engloba valores y principios desglosados anteriormente.')\n",
            "('Descentralizaci√≥n', 'la pr√°ctica de los poderes centralizados no ha logrado superar las barreras geogr√°ficas que permitan tomar buenas y atingentes decisiones a la realidad de cada regi√≥n.')\n"
          ]
        }
      ],
      "source": [
        "# Ahora con este vocabulario podemos armar un set de train y uno de validacion\n",
        "import torch\n",
        "from torch.utils.data.dataset import random_split\n",
        "train_len = int(len(dataset) * .8)\n",
        "\n",
        "train_split, validation_split = random_split(dataset, [train_len, len(dataset) - train_len])\n",
        "\n",
        "print(\"Algunos ejemplos del dataset:\")\n",
        "for example in sample(list(train_split), 3):\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEgOXqAAlg7I"
      },
      "source": [
        "## Vocabulario (a partir del train split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zekFPQqWlnmY"
      },
      "source": [
        "Ahora construiremos el vocabulario, para esto necesitamos un tokenizador, pero ``torchtext`` no tiene un tokenizador para espa√±ol as√≠ que bajaremos uno de ``spacy``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_M21_JWlkkW",
        "outputId": "5ce833cb-716e-491e-f1ec-03bdaf936102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-18 18:19:40.748938: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-18 18:19:41.781464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-18 18:19:43.059097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-18 18:19:43.059561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-18 18:19:43.059736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[38;5;3m‚ö† As of spaCy v3.0, shortcuts like 'es' are deprecated. Please use the\n",
            "full pipeline package name 'es_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting es-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.5.0/es_core_news_sm-3.5.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xgDAsk4lpiv",
        "outputId": "50f05b60-01e7-48b2-d391-71c869fe87b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"es\" could not be loaded, trying \"es_core_news_sm\" instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\Tama√±o del vocabulario: 9493\n",
            "Algunas palabras del vocabulario: ['hablamos', 'dependa', 'particularidades', 'reprimido', 'cultivar']\n",
            "\n",
            "Cantidad de labels: 54\n",
            "Algunos labels: ['Ciudadan√≠a', 'Pluralismo', 'Respeto']\n"
          ]
        }
      ],
      "source": [
        "# Ahora si construiremos el vocabulario y la lista de labels\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer(\"spacy\", \"es\")\n",
        "min_freq = 1\n",
        "vocab = build_vocab_from_iterator((tokenizer(text[1]) for text in train_split), min_freq=min_freq)\n",
        "labels = list({doc[0] for doc in train_split})\n",
        "label_map = {label: index for index, label in enumerate(labels)}\n",
        "\n",
        "UNK_IDX = 0\n",
        "vocab.set_default_index(UNK_IDX)\n",
        "\n",
        "vocab.insert_token('<pad>', 1)\n",
        "\n",
        "stoi = vocab.get_stoi()\n",
        "\n",
        "print(\"\\Tama√±o del vocabulario:\", len(vocab))\n",
        "print(\"Algunas palabras del vocabulario:\", sample(vocab.get_itos(), 5))\n",
        "print(\"\\nCantidad de labels:\", len(labels))\n",
        "print(\"Algunos labels:\", sample(labels, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFWm6ulxlt4w",
        "outputId": "e1e95b0a-218a-47ec-e6f4-1156a62d5004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Identidad cultural': 0,\n",
              " 'Paz / Convivencia pac√≠fica': 1,\n",
              " 'Equidad de g√©nero': 2,\n",
              " 'Familia': 3,\n",
              " 'Familia basada en matrimonio heterosexual': 4,\n",
              " 'Solidaridad': 5,\n",
              " 'Respeto': 6,\n",
              " 'Participaci√≥n': 7,\n",
              " 'Respeto / Conservaci√≥n de la naturaleza o medio ambiente': 8,\n",
              " 'Democracia participativa': 9,\n",
              " 'Tolerancia': 10,\n",
              " 'Desarrollo': 11,\n",
              " 'Seguridad': 12,\n",
              " 'Ciudadan√≠a': 13,\n",
              " 'Rep√∫blica': 14,\n",
              " 'Estado laico': 15,\n",
              " 'Propiedad Privada': 16,\n",
              " 'Integraci√≥n': 17,\n",
              " 'Estado de Derecho': 18,\n",
              " 'Amistad c√≠vica': 19,\n",
              " 'Unidad': 20,\n",
              " 'Soberan√≠a': 21,\n",
              " 'Libertad de culto': 22,\n",
              " 'Libertad de expresi√≥n': 23,\n",
              " 'Bien Com√∫n / Comunidad': 24,\n",
              " 'Patriotismo': 25,\n",
              " 'Pluralismo': 26,\n",
              " 'Emprendimiento libre': 27,\n",
              " 'Descentralizaci√≥n': 28,\n",
              " 'Inclasificable/No corresponde': 29,\n",
              " 'Justicia': 30,\n",
              " 'Desarrollo integral': 31,\n",
              " 'Libertad': 32,\n",
              " 'Estado garante': 33,\n",
              " 'Equidad': 34,\n",
              " 'Otro': 35,\n",
              " 'Seguridad Social': 36,\n",
              " 'Dignidad': 37,\n",
              " 'Libertad de conciencia': 38,\n",
              " 'Inclusi√≥n': 39,\n",
              " 'Justicia social': 40,\n",
              " 'Autonom√≠a / Libertad': 41,\n",
              " 'Democracia': 42,\n",
              " 'Probidad': 43,\n",
              " 'Plurinacionalismo': 44,\n",
              " 'Derechos humanos': 45,\n",
              " 'Desarrollo sustentable': 46,\n",
              " 'Innovaci√≥n / Creatividad': 47,\n",
              " 'Subsidiaridad': 48,\n",
              " 'Diversidad': 49,\n",
              " 'Igualdad': 50,\n",
              " 'Multiculturalidad': 51,\n",
              " 'Responsabilidad': 52,\n",
              " 'Transparencia y publicidad': 53}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5WUbpwDlvtX"
      },
      "source": [
        "## Modelo con capa de Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRGbqpOwlxi9"
      },
      "outputs": [],
      "source": [
        "# Pum ahora hagamos la arquitectura\n",
        "# simplecita, un capa de embedding, y luego una red feed forward de\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Red neuronal con una sola capa oculta\n",
        "class ArgumentClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class, hidden_size, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # capa de embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, pad_idx)\n",
        "        # self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, mode=\"mean\")\n",
        "\n",
        "        # capas de la MLP\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        # self.fc1 = nn.Linear(embed_dim, hidden_size)\n",
        "        # self.fc2 = nn.Linear(hidden_size, num_class)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # La representacion de un documento sera el promedio de los\n",
        "        # embeddings de sus palabras.\n",
        "        # (B, N, 1) -> (B, N, E)\n",
        "        h = self.embedding(batch)\n",
        "        # (B, N, E) -> (B, E)\n",
        "        h = h.mean(dim=1)\n",
        "        # h = self.embedding(batch)\n",
        "\n",
        "        # computar las capas de la red MLP\n",
        "        h = self.fc(h)\n",
        "        # h = F.relu(self.fc1(h))\n",
        "        # h = self.fc2(h)\n",
        "\n",
        "        return h\n",
        "        # return torch.softmax(h, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVq1K4tGl1cH"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PybMd2z_l5BI"
      },
      "source": [
        "Primero, necesitamos definir una funci√≥n que convierta un conjunto de items de nuestro dataset en un batch,recordando que los tensores en pytorch tienen que ser homogeneos. Esta funci√≥n recibe una lista de muestras del dataset y debe retornar tensores que agrupan estas muestras.\n",
        "\n",
        "Por ejemplo, si cada ejemplo de nuestro dataset contiene 2 elementos y nuestro tama√±o de batch es de 16, entonces esta funci√≥n debe retorna una tupla de 2 tensores, cada uno de dimension 16 x ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47v6ZhdkvJ26"
      },
      "outputs": [],
      "source": [
        "#from itertools import zip_longest\n",
        "\n",
        "# creamos lista de tensores\n",
        "#train_dataset, validation_dataset = [\n",
        "#    [\n",
        "#        (\n",
        "#            label_map[item[0]],\n",
        "#            torch.tensor([vocab[token] if token in vocab else 0 for token in tokenizer(item[1])]),\n",
        "#        ) for item in split\n",
        "#    ] for split in [train_split, validation_split]\n",
        "#]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L28eCml2l3DF"
      },
      "outputs": [],
      "source": [
        "from itertools import zip_longest\n",
        "\n",
        "# creamos lista de tensores\n",
        "train_dataset, validation_dataset = [\n",
        "    [\n",
        "        (\n",
        "            label_map[item[0]],\n",
        "            torch.tensor([vocab[token] for token in tokenizer(item[1])]),\n",
        "        ) for item in split\n",
        "    ] for split in [train_split, validation_split]\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhMt7CZAkukz"
      },
      "source": [
        "¬øPero que estamos haciendo en la lista de comprehesion anterior?... Bueno, basicamente estamos entregando los vectores de una forma legible por el computador, de tal forma que el modelo entienda en el entrenamiento una forma numerica de las palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od2Xy8FzkTIH",
        "outputId": "7eb9544e-4842-430c-d1a8-1112a403c0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42, tensor([   7,  156,  213,    0,    4,   58,  147,  884,    4,  194,    5,    7,\n",
            "          45,   21,  110,    9,  244,    5, 1019,    9,   38,  553,    3]))\n",
            "(7, tensor([   6,  100,   72,  411,    2,   14,  487,    6,    4,   39,  245,    9,\n",
            "         237,    0, 6377, 1915,   11,  717,   63,   21,   36,    3]))\n"
          ]
        }
      ],
      "source": [
        "# Lo que ve el comput\n",
        "for data in sample(train_dataset, 2):\n",
        "  print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKZhS0VIkuIn",
        "outputId": "891db0b2-7d8e-4bdd-b39d-aeefe19a8e9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label: Participaci√≥n\n",
            "text: que esta sea vinculante , es decir que la constituci√≥n garantice a trav√©s de ejercicios participativos las grandes decisiones del pa√≠s . \n"
          ]
        }
      ],
      "source": [
        "# Lo que ver√≠a un humano\n",
        "for key in label_map:\n",
        "  if label_map[key] == data[0]:\n",
        "    print(f\"label: {key}\")\n",
        "\n",
        "human_text = ''\n",
        "for i in data[1]:\n",
        "  human_text += vocab.get_itos()[i] + ' '\n",
        "print(f\"text: {human_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHT0-U4vNP2U"
      },
      "outputs": [],
      "source": [
        "def generate_batch(batch):\n",
        "    return (\n",
        "        # En este caso como los labels son n√∫meros,\n",
        "        # el tensor es de una sola dimension de tama√±o batch_size\n",
        "        torch.tensor([item[0] for item in batch]),\n",
        "\n",
        "        # En este caso se retorna un tensor de 2 dimensiones, batch_size x N,\n",
        "        # donde N es mayor largo de los ejemplo en el batch. Aca se realiza\n",
        "        # padding de los ejemplos mas cortos.\n",
        "        torch.tensor(\n",
        "            list(\n",
        "                zip(\n",
        "                    *zip_longest(\n",
        "                        *[item[1] for item in batch], fillvalue=vocab[\"<pad>\"]\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHOKyrL7l7t5"
      },
      "outputs": [],
      "source": [
        "# Ahora creamos funciones para entrenar y validar el modelo\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def train_func(train_dataset):\n",
        "\n",
        "    # Entranamos el modelo\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=generate_batch,\n",
        "    )\n",
        "    for i, (cls, text) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        cls, text = cls.to(device), text.to(device)\n",
        "        output = model(text)\n",
        "\n",
        "        loss = criterion(output, cls)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Ajustar el learning rate\n",
        "    # scheduler.step()\n",
        "\n",
        "    return train_loss / len(train_dataset), train_acc / len(train_dataset)\n",
        "\n",
        "\n",
        "def test(test_dataset):\n",
        "    test_loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(\n",
        "        test_dataset, batch_size=BATCH_SIZE, collate_fn=generate_batch\n",
        "    )\n",
        "    for cls, text in data:\n",
        "        cls, text = cls.to(device), text.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            loss = criterion(output, cls)\n",
        "            test_loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return test_loss / len(test_dataset), acc / len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkUm9pQal8zo",
        "outputId": "2430fed6-b69a-4e13-c28f-aa196b18c44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.1966(train)\t|\tAcc: 21.9%(train)\n",
            "\tLoss: 0.1771(valid)\t|\tAcc: 31.6%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.1669(train)\t|\tAcc: 34.6%(train)\n",
            "\tLoss: 0.1611(valid)\t|\tAcc: 35.9%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 2 seconds\n",
            "\tLoss: 0.1501(train)\t|\tAcc: 40.7%(train)\n",
            "\tLoss: 0.1499(valid)\t|\tAcc: 41.0%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 2 seconds\n",
            "\tLoss: 0.1379(train)\t|\tAcc: 45.1%(train)\n",
            "\tLoss: 0.1431(valid)\t|\tAcc: 44.5%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.1281(train)\t|\tAcc: 47.9%(train)\n",
            "\tLoss: 0.1380(valid)\t|\tAcc: 45.5%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.1212(train)\t|\tAcc: 51.6%(train)\n",
            "\tLoss: 0.1345(valid)\t|\tAcc: 47.1%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.1141(train)\t|\tAcc: 53.5%(train)\n",
            "\tLoss: 0.1331(valid)\t|\tAcc: 47.1%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.1085(train)\t|\tAcc: 55.6%(train)\n",
            "\tLoss: 0.1314(valid)\t|\tAcc: 47.8%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.1033(train)\t|\tAcc: 57.6%(train)\n",
            "\tLoss: 0.1286(valid)\t|\tAcc: 49.4%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0984(train)\t|\tAcc: 59.0%(train)\n",
            "\tLoss: 0.1280(valid)\t|\tAcc: 50.3%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0944(train)\t|\tAcc: 60.2%(train)\n",
            "\tLoss: 0.1273(valid)\t|\tAcc: 49.6%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0904(train)\t|\tAcc: 62.4%(train)\n",
            "\tLoss: 0.1260(valid)\t|\tAcc: 51.0%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0869(train)\t|\tAcc: 63.8%(train)\n",
            "\tLoss: 0.1271(valid)\t|\tAcc: 50.4%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0826(train)\t|\tAcc: 65.7%(train)\n",
            "\tLoss: 0.1263(valid)\t|\tAcc: 50.9%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0792(train)\t|\tAcc: 67.0%(train)\n",
            "\tLoss: 0.1260(valid)\t|\tAcc: 50.9%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0759(train)\t|\tAcc: 68.2%(train)\n",
            "\tLoss: 0.1259(valid)\t|\tAcc: 51.1%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0730(train)\t|\tAcc: 69.1%(train)\n",
            "\tLoss: 0.1264(valid)\t|\tAcc: 51.2%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0698(train)\t|\tAcc: 70.5%(train)\n",
            "\tLoss: 0.1283(valid)\t|\tAcc: 51.3%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0673(train)\t|\tAcc: 72.3%(train)\n",
            "\tLoss: 0.1269(valid)\t|\tAcc: 51.8%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 1 seconds\n",
            "\tLoss: 0.0644(train)\t|\tAcc: 73.5%(train)\n",
            "\tLoss: 0.1286(valid)\t|\tAcc: 51.5%(valid)\n"
          ]
        }
      ],
      "source": [
        "# Ahora por fin tenemos todo lo necesario para entrenar el modelo.\n",
        "import time\n",
        "\n",
        "N_EPOCHS = 20\n",
        "LEARN_RATE = 2.0\n",
        "STEP_SIZE = 1\n",
        "BATCH_SIZE = 16\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_SIZE = 1024\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ArgumentClassifier(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_class=len(labels),\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    pad_idx=vocab[\"<pad>\"],\n",
        ").to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARN_RATE)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, STEP_SIZE)\n",
        "\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test(validation_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs // 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print(\n",
        "        f\"Epoch: {epoch + 1}\", f\" | time in {mins} minutes, {secs} seconds\",\n",
        "    )\n",
        "    print(\n",
        "        f\"\\tLoss: {train_loss:.4f}(train)\\t|\"\n",
        "        f\"\\tAcc: {train_acc * 100:.1f}%(train)\"\n",
        "    )\n",
        "    print(\n",
        "        f\"\\tLoss: {valid_loss:.4f}(valid)\\t|\"\n",
        "        f\"\\tAcc: {valid_acc * 100:.1f}%(valid)\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2DyCzBUbfwk"
      },
      "source": [
        "# Parte 3: Clasificaci√≥n de texto usando CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HylpfYQcADP"
      },
      "source": [
        "Para este caso vamos a trabajar con un dataset de noticias, el cual es f√°cilmente descargable con la librer√≠a y da muchos mejores resultados (ya que los anteriores estaban ah√≠ nomas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZgbo70IcGrq"
      },
      "outputs": [],
      "source": [
        "# por si las moscas importamos todo denuevo (para los que reci√©n se unen a la sintonia)\n",
        "# https://pytorch.org/text/stable/datasets.html#ag-news\n",
        "import os\n",
        "import torch\n",
        "from random import choice\n",
        "from torchtext.datasets import AG_NEWS\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "train_dataset, test_dataset = AG_NEWS(root=\"data\", split=('train', 'test'))\n",
        "train_list = list(train_dataset)\n",
        "test_list = list(test_dataset)\n",
        "\n",
        "# Informacion relevante del dataset\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "vocab = build_vocab_from_iterator(tokenizer(x[1]) for x in train_list)\n",
        "\n",
        "vocab.set_default_index(0)\n",
        "vocab.insert_token('<pad>', 1)\n",
        "\n",
        "stoi = vocab.get_stoi()\n",
        "\n",
        "num_classes = 4\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTNLFNbTc5rx"
      },
      "source": [
        "Luego, creamos una red no tan profunda pero bien competente para nuestra tarea:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOwf8CZZctxG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from itertools import zip_longest\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=32, num_classes=10,\n",
        "                 cnn_pool_channels=24, cnn_kernel_size=3):\n",
        "\n",
        "        # Inicializamos la clase padre\n",
        "        super().__init__()\n",
        "\n",
        "        # Creamos la capa de embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # Creamos la capa de convoluci√≥n\n",
        "        # `in_channels`: Es el n√∫mero de canales de entrada de la convoluci√≥n. En este caso, como estamos trabajando con texto, s√≥lo tenemos un canal, por lo que `in_channels=1`.\n",
        "        # `out_channels`: Es el n√∫mero de canales de salida de la convoluci√≥n. Especifica la cantidad de filtros que se aplicar√°n a la entrada. En este caso, queremos generar `cnn_pool_channels` canales de salida, por lo que `out_channels=cnn_pool_channels`.\n",
        "        # `kernel_size`: Es el tama√±o del kernel de la convoluci√≥n. En este caso, estamos usando un kernel de tama√±o `cnn_kernel_size * embed_dim`, donde `embed_dim` es la dimensi√≥n de los vectores de embedding. Esto significa que cada filtro de la convoluci√≥n cubrir√° `cnn_kernel_size` palabras (o tokens) en una dimensi√≥n y `embed_dim` en la otra.\n",
        "        # `stride`: Es el desplazamiento que se aplica a la entrada de la convoluci√≥n. En este caso, estamos desplazando la entrada `embed_dim` unidades en cada paso. Esto significa que se aplicar√°n filtros a cada palabra (o token) de la entrada.\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=1,\n",
        "            out_channels=cnn_pool_channels,\n",
        "            kernel_size=cnn_kernel_size * embed_dim,\n",
        "            stride=embed_dim,\n",
        "        )\n",
        "\n",
        "        # Calculamos el tama√±o de entrada de la capa lineal\n",
        "        fc_in_size = cnn_pool_channels\n",
        "\n",
        "        # Creamos la capa lineal\n",
        "        self.fc = nn.Linear(fc_in_size, num_classes)\n",
        "\n",
        "        # Inicializamos los pesos de las capas\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        # Definimos el rango de los valores iniciales de los pesos\n",
        "        initrange = 0.5\n",
        "\n",
        "        # Inicializamos los pesos de la capa de embedding\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "        # Inicializamos los pesos de la capa lineal\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "        # Inicializamos los sesgos de la capa lineal en cero\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "\n",
        "        # Preparamos el input de la capa de embeddings a partir de text y offsets\n",
        "        text = torch.tensor(\n",
        "            list(\n",
        "                zip(\n",
        "                    *zip_longest(\n",
        "                        *([text[o:offsets[i+1]] for i, o in enumerate(offsets[:-1])] + [text[offsets[-1]:len(texts)]]),\n",
        "                        fillvalue=vocab[\"<pad>\"]\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        ).to(text.device)\n",
        "\n",
        "        # Obtenemos la representaci√≥n de la frase a partir de la capa de embedding\n",
        "        h = self.embedding(text)\n",
        "\n",
        "        # Aplicamos la capa de convoluci√≥n\n",
        "        h = h.view(h.size(0), 1, -1)\n",
        "        h = torch.relu(self.conv(h))\n",
        "        h = h.mean(dim=2)\n",
        "\n",
        "        # Obtenemos el resultado final a partir de la capa lineal\n",
        "        output = self.fc(h)\n",
        "\n",
        "        # Aplicamos la funci√≥n de activaci√≥n log-softmax\n",
        "        return F.log_softmax(output, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLOXQIhec4PY"
      },
      "source": [
        "Finalmente, generamos la funci√≥n para cargar por batch y luego entrenamos directamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3HqZeLxA1q5",
        "outputId": "0a14186e-eb70-4139-a924-f5de11dffc75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Epoch: 001\t Phase: train Iter: 469/469\t iter-Acc: 23.958%\t iter-Loss: 1.377\n",
            " train\tAvg. Acc: 26.982%\t Avg. Loss: 0.005\n",
            "Epoch: 001\t Phase: test Iter: 006/006\t iter-Acc: 26.083%\t iter-Loss: 1.383\n",
            " test\tAvg. Acc: 25.118%\t Avg. Loss: 0.001\n",
            "Epoch: 002\t Phase: train Iter: 469/469\t iter-Acc: 26.562%\t iter-Loss: 1.369\n",
            " train\tAvg. Acc: 29.483%\t Avg. Loss: 0.005\n",
            "Epoch: 002\t Phase: test Iter: 006/006\t iter-Acc: 29.667%\t iter-Loss: 1.380\n",
            " test\tAvg. Acc: 29.329%\t Avg. Loss: 0.001\n",
            "Epoch: 003\t Phase: train Iter: 469/469\t iter-Acc: 31.771%\t iter-Loss: 1.357\n",
            " train\tAvg. Acc: 31.831%\t Avg. Loss: 0.005\n",
            "Epoch: 003\t Phase: test Iter: 006/006\t iter-Acc: 33.583%\t iter-Loss: 1.375\n",
            " test\tAvg. Acc: 33.000%\t Avg. Loss: 0.001\n",
            "Epoch: 004\t Phase: train Iter: 469/469\t iter-Acc: 39.583%\t iter-Loss: 1.339\n",
            " train\tAvg. Acc: 34.222%\t Avg. Loss: 0.005\n",
            "Epoch: 004\t Phase: test Iter: 006/006\t iter-Acc: 35.500%\t iter-Loss: 1.367\n",
            " test\tAvg. Acc: 35.013%\t Avg. Loss: 0.001\n",
            "Epoch: 005\t Phase: train Iter: 469/469\t iter-Acc: 40.625%\t iter-Loss: 1.312\n",
            " train\tAvg. Acc: 36.841%\t Avg. Loss: 0.005\n",
            "Epoch: 005\t Phase: test Iter: 006/006\t iter-Acc: 37.667%\t iter-Loss: 1.351\n",
            " test\tAvg. Acc: 37.303%\t Avg. Loss: 0.001\n",
            "Epoch: 006\t Phase: train Iter: 469/469\t iter-Acc: 44.271%\t iter-Loss: 1.269\n",
            " train\tAvg. Acc: 39.628%\t Avg. Loss: 0.005\n",
            "Epoch: 006\t Phase: test Iter: 006/006\t iter-Acc: 40.917%\t iter-Loss: 1.324\n",
            " test\tAvg. Acc: 40.829%\t Avg. Loss: 0.001\n",
            "Epoch: 007\t Phase: train Iter: 469/469\t iter-Acc: 48.438%\t iter-Loss: 1.205\n",
            " train\tAvg. Acc: 43.268%\t Avg. Loss: 0.005\n",
            "Epoch: 007\t Phase: test Iter: 006/006\t iter-Acc: 45.083%\t iter-Loss: 1.279\n",
            " test\tAvg. Acc: 45.303%\t Avg. Loss: 0.001\n",
            "Epoch: 008\t Phase: train Iter: 469/469\t iter-Acc: 53.125%\t iter-Loss: 1.112\n",
            " train\tAvg. Acc: 47.923%\t Avg. Loss: 0.005\n",
            "Epoch: 008\t Phase: test Iter: 006/006\t iter-Acc: 50.250%\t iter-Loss: 1.209\n",
            " test\tAvg. Acc: 50.526%\t Avg. Loss: 0.001\n",
            "Epoch: 009\t Phase: train Iter: 469/469\t iter-Acc: 57.292%\t iter-Loss: 1.004\n",
            " train\tAvg. Acc: 53.368%\t Avg. Loss: 0.004\n",
            "Epoch: 009\t Phase: test Iter: 006/006\t iter-Acc: 55.833%\t iter-Loss: 1.119\n",
            " test\tAvg. Acc: 55.816%\t Avg. Loss: 0.001\n",
            "Epoch: 010\t Phase: train Iter: 469/469\t iter-Acc: 61.979%\t iter-Loss: 0.901\n",
            " train\tAvg. Acc: 58.326%\t Avg. Loss: 0.004\n",
            "Epoch: 010\t Phase: test Iter: 006/006\t iter-Acc: 60.833%\t iter-Loss: 1.028\n",
            " test\tAvg. Acc: 59.855%\t Avg. Loss: 0.001\n",
            "Epoch: 011\t Phase: train Iter: 469/469\t iter-Acc: 65.625%\t iter-Loss: 0.818\n",
            " train\tAvg. Acc: 62.263%\t Avg. Loss: 0.004\n",
            "Epoch: 011\t Phase: test Iter: 006/006\t iter-Acc: 64.500%\t iter-Loss: 0.953\n",
            " test\tAvg. Acc: 63.408%\t Avg. Loss: 0.001\n",
            "Epoch: 012\t Phase: train Iter: 469/469\t iter-Acc: 70.833%\t iter-Loss: 0.740\n",
            " train\tAvg. Acc: 66.037%\t Avg. Loss: 0.003\n",
            "Epoch: 012\t Phase: test Iter: 006/006\t iter-Acc: 66.583%\t iter-Loss: 0.884\n",
            " test\tAvg. Acc: 66.250%\t Avg. Loss: 0.001\n",
            "Epoch: 013\t Phase: train Iter: 469/469\t iter-Acc: 73.438%\t iter-Loss: 0.674\n",
            " train\tAvg. Acc: 69.068%\t Avg. Loss: 0.003\n",
            "Epoch: 013\t Phase: test Iter: 006/006\t iter-Acc: 69.333%\t iter-Loss: 0.824\n",
            " test\tAvg. Acc: 69.250%\t Avg. Loss: 0.001\n",
            "Epoch: 014\t Phase: train Iter: 469/469\t iter-Acc: 75.000%\t iter-Loss: 0.622\n",
            " train\tAvg. Acc: 71.575%\t Avg. Loss: 0.003\n",
            "Epoch: 014\t Phase: test Iter: 006/006\t iter-Acc: 71.333%\t iter-Loss: 0.770\n",
            " test\tAvg. Acc: 72.066%\t Avg. Loss: 0.001\n",
            "Epoch: 015\t Phase: train Iter: 469/469\t iter-Acc: 77.083%\t iter-Loss: 0.585\n",
            " train\tAvg. Acc: 73.690%\t Avg. Loss: 0.003\n",
            "Epoch: 015\t Phase: test Iter: 006/006\t iter-Acc: 73.083%\t iter-Loss: 0.724\n",
            " test\tAvg. Acc: 73.579%\t Avg. Loss: 0.001\n",
            "Epoch: 016\t Phase: train Iter: 469/469\t iter-Acc: 78.125%\t iter-Loss: 0.559\n",
            " train\tAvg. Acc: 75.435%\t Avg. Loss: 0.003\n",
            "Epoch: 016\t Phase: test Iter: 006/006\t iter-Acc: 74.167%\t iter-Loss: 0.684\n",
            " test\tAvg. Acc: 75.013%\t Avg. Loss: 0.001\n",
            "Epoch: 017\t Phase: train Iter: 469/469\t iter-Acc: 79.688%\t iter-Loss: 0.543\n",
            " train\tAvg. Acc: 76.525%\t Avg. Loss: 0.003\n",
            "Epoch: 017\t Phase: test Iter: 006/006\t iter-Acc: 76.250%\t iter-Loss: 0.651\n",
            " test\tAvg. Acc: 76.421%\t Avg. Loss: 0.001\n",
            "Epoch: 018\t Phase: train Iter: 469/469\t iter-Acc: 80.729%\t iter-Loss: 0.527\n",
            " train\tAvg. Acc: 78.055%\t Avg. Loss: 0.002\n",
            "Epoch: 018\t Phase: test Iter: 006/006\t iter-Acc: 76.750%\t iter-Loss: 0.619\n",
            " test\tAvg. Acc: 77.526%\t Avg. Loss: 0.001\n",
            "Epoch: 019\t Phase: train Iter: 469/469\t iter-Acc: 81.771%\t iter-Loss: 0.515\n",
            " train\tAvg. Acc: 79.168%\t Avg. Loss: 0.002\n",
            "Epoch: 019\t Phase: test Iter: 006/006\t iter-Acc: 77.667%\t iter-Loss: 0.593\n",
            " test\tAvg. Acc: 78.539%\t Avg. Loss: 0.000\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def generate_batch(batch):\n",
        "  label = torch.tensor([entry[0]-1 for entry in batch])\n",
        "  texts = [tokenizer(entry[1]) for entry in batch]\n",
        "  offsets = [0] + [len(text) for text in texts]\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  big_text = torch.cat([torch.tensor([vocab[t] if t in stoi else 0 for t in text]) for text in texts])\n",
        "  #big_text = torch.cat([torch.tensor([vocab.stoi[t] for t in text]) for text in texts])\n",
        "\n",
        "  return big_text, offsets, label\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 20\n",
        "TEST_BATCH_SIZE = BATCH_SIZE * 5\n",
        "LR = 1e-1\n",
        "\n",
        "model = CNNClassifier(len(vocab), num_classes=num_classes).to(device)\n",
        "optimizer = SGD(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n",
        "\n",
        "split_size = {'train': len(train_list), 'test': len(test_list)}\n",
        "\n",
        "# train_dataset, test_dataset = AG_NEWS(root=\"data\")\n",
        "for epoch in range(1, NUM_EPOCHS):\n",
        "  train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "  test_loader = DataLoader(test_list, batch_size=TEST_BATCH_SIZE, collate_fn=generate_batch)\n",
        "  loaders = {'train': train_loader, 'test': test_loader}\n",
        "  for phase in ['train', 'test']:\n",
        "    if phase == 'train':\n",
        "      model.train()\n",
        "    else:\n",
        "      model.eval()\n",
        "\n",
        "    total_acc, total_loss = 0, 0\n",
        "    for i, (texts, offsets, cls) in enumerate(loaders[phase]):\n",
        "      texts = texts.to(device)\n",
        "      offsets = offsets.to(device)\n",
        "      cls = cls.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "        output = model(texts, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        total_loss += loss.item()\n",
        "        if phase == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      acc = (output.argmax(1) == cls).sum().item()\n",
        "      total_acc += acc\n",
        "\n",
        "      sys.stdout.write('\\rEpoch: {0:03d}\\t Phase: {1} Iter: {2:03d}/{3:03d}\\t iter-Acc: {4:.3f}%\\t iter-Loss: {5:.3f}'.format(epoch, phase, i+1, len(loaders[phase]), acc/len(offsets)*100, loss.item()))\n",
        "\n",
        "    if phase == 'train':\n",
        "      scheduler.step()\n",
        "    print('\\n {0}\\tAvg. Acc: {1:.3f}%\\t Avg. Loss: {2:.3f}'.format(phase, total_acc/split_size[phase]*100, total_loss/split_size[phase]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NuHEAZsdL1u"
      },
      "source": [
        "Como podemos ver, con esta segunda perspectiva tenemos un clasificador mas competente en relaci√≥n con el anterior. La idea es que tengan diferente perspectivas en la construcci√≥n."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}