{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UwaDuQqCOyLJ"
      },
      "source": [
        "# **Tarea 4 - CC6205 Natural Language Processing üìö**\n",
        "\n",
        "**Integrantes:**\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** Martes 13 de junio.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X4lL5hGw07yP"
      },
      "source": [
        "Bienvenid@s a la cuarta tarea del curso de Natural Language Processing (NLP). \n",
        "En esta tarea estaremos tratando el problema de **tagging** (generaci√≥n de secuencias de etiquetas del mismo largo que la secuencia de input), el uso de **Convolutional Neural Networks** y **Recurrent Neural Networks**, e implementaremos una red usando PyTorch. \n",
        "\n",
        "Usen $\\LaTeX$ para las f√≥rmulas matem√°ticas. En la parte de programaci√≥n pueden usar lo que quieran, pero la [Auxiliar 3](https://youtu.be/36WTXvg3zh0) les puede ser de *gran ayuda*.\n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook.\n",
        "- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav√©s del canal de Discord del curso.\n",
        "\n",
        "Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "- [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/Tjgb-yQOg54), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
        "- [MEMMs and CRFs](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CRF.pdf): [notes 1](http://www.cs.columbia.edu/~mcollins/crf.pdf), [notes 2](http://www.cs.columbia.edu/~mcollins/fb.pdf), [video 1](https://youtu.be/qlI-4lSUDkg), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/ZpUwDy6o28Y)\n",
        "- [Convolutional Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CNN.pdf): [video](https://youtu.be/lLZW5Fn40r8)\n",
        "- [Recurrent Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-RNN.pdf): [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ANqzQ3G9WNw3"
      },
      "source": [
        "# Hidden Markov Models (HMM), Maximum Entropy Markov Models (MEMM) and Conditional Random Field(CRF) (1,5 puntos)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXD3D7RYKJ-"
      },
      "source": [
        "### Pregunta 1 (1 pt)\n",
        "Para un problema de POS tagging se define el conjunto de etiquetas $S = \\{ \\text{DET}, \\text{NOUN}, \\text{VERB}, \\text{ADP} \\}$ y se tiene un Hidden Markov Model con los siguientes par√°metros estimados a partir de un corpus de entrenamiento:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "q(\\text{NOUN}| \\text{ VERB}, \\text{DET}) &= 0.3 \\\\\n",
        "q(\\text{NOUN}|\\ w, \\text{DET}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "q(\\text{DET}| \\text{ VERB}, \\text{NOUN}) &= 0.4 \\\\\n",
        "q(\\text{DET}|\\ w, \\text{NOUN}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "e(the|\\text{ DET}) &= 0.5 \\\\\n",
        "e(pasta|\\text{ NOUN}) &= 0.6\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Luego para la oraci√≥n: `the man is pouring sauce on the pasta`, se tiene una tabla de programaci√≥n din√°mica con los siguientes valores:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\pi(7,\\text{DET},\\text{DET})&=0.1\\\\\n",
        "\\pi(7,\\text{NOUN},\\text{DET})&=0.2\\\\\n",
        "\\pi(7,\\text{VERB},\\text{DET})&=0.01\\\\\n",
        "\\pi(7,\\text{ADP},\\text{DET})&=0.5\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Con esta informaci√≥n, calcule el valor de $\\pi(8,\\text{DET},\\text{NOUN})$. Puede dejar el resultado expresado como una fracci√≥n.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5EzgysW9kGi-"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "`Escriba su respuesta aqu√≠`\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oiwJb_vmkKLZ"
      },
      "source": [
        "### Pregunta 2 (0.5 pts)\n",
        "Comente  sobre las similitudes o diferencias entre los HMMs, MEMMs y CRFs. Para esto, responda las siguientes preguntas.\n",
        "\n",
        "#### 2.1. ¬øPara qu√© tipo de tarea sirven? D√© dos ejemplo de este tipo de tarea y descr√≠balos brevemente. (0.1 pts)\n",
        "\n",
        "**Respuesta:** \n",
        "\n",
        "`Escriba su respuesta aqu√≠`\n",
        "\n",
        "#### 2.2. ¬øQu√© modelos usan features? ¬øQu√© ventajas conlleva esto? (0.1 pts)\n",
        "\n",
        "**Respuesta:** \n",
        "\n",
        "`Escriba su respuesta aqu√≠`\n",
        "\n",
        "#### 2.3. ¬øC√≥mo maneja cada uno de los modelos las palabras con baja frecuencia en el set de train? (0.1 pts)\n",
        "\n",
        "**Respuesta:** \n",
        "\n",
        "`Escriba su respuesta aqu√≠`\n",
        "\n",
        "#### 2.4. ¬øQu√© le permite a los CRF realizar decisiones globales? ¬øQu√© diferencia con respecto a los MEMMs permite lograr esto? ¬øPor qu√© los HMMs tampoco son capaces de tomar decisiones globales? (0.1 pts)\n",
        "\n",
        "**Respuesta:** \n",
        "\n",
        "`Escriba su respuesta aqu√≠`\n",
        "\n",
        "#### 2.5 Dado una secuencia de $x_1, ..., x_m$ ¬øCu√°ntas posibles secuencias de etiquetas se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ ? ¬øAnalizarlas todas ser√≠a computacionalmente tratable? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "`Escriba su respuesta aqu√≠`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "44ACHHZIWGF1"
      },
      "source": [
        "# Convolutional Neural Networks (0,5 puntos)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ClRAHR95Y8aB"
      },
      "source": [
        "### Pregunta 3 (0,5 puntos)\n",
        "\n",
        "Considere la frase $w_{1..7}=$ `El agua moja y el fuego quema` $=[El, agua, moja, y, el, fuego, quema]$.\n",
        "\n",
        "La siguiente matriz de embeddings, donde la i-√©sima fila corresponde al vector de embedding de la i-√©sima palabra, ordenadas seg√∫n aparecen en la frase. (vectores de largo 2).\n",
        "\\begin{equation}\n",
        "E = \\begin{pmatrix}\n",
        "2 & 2\\\\\n",
        "0 & -2\\\\\n",
        "0 & 1\\\\\n",
        "-2 & 1\\\\\n",
        "1 & 0\\\\\n",
        "-1 & 1\\\\\n",
        "1 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Los siguientes 3 filtros\n",
        "\\begin{equation}\n",
        "U = \\begin{pmatrix}\n",
        "-1 & 1 & 0\\\\\n",
        "1 & 1 & 0\\\\\n",
        "0 & 0 & -1\\\\\n",
        "1 & -1 & -1\\\\\n",
        "-1 & -1 & 1\\\\\n",
        "1 & 0 & -1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Y la funci√≥n de activaci√≥n\n",
        "\\begin{equation}\n",
        "tanh = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
        "\\end{equation}\n",
        "\n",
        "Usando estos param√°tros escriba los pasos para calcular la representaci√≥n (vector) resultante de aplicar la operaci√≥n de convoluci√≥n (sin padding) + max pooling. ¬øDe qu√© tama√±o ser√≠a la ventana que debemos usar?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SlQ30Arkq0u4"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "`Escriba su respuesta aqu√≠`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A0rCwen3WREC"
      },
      "source": [
        "# Recurrent Neural Networks (1 punto)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U0et78Z4oKIq"
      },
      "source": [
        "### Pregunta 4 (0,5 puntos)\n",
        "Usando los embeddings de dos dimensiones de la pregunta anteror, la oraci√≥n `el fuego quema` la podemos representar por una secuencia de vectores $(\\vec{x}_1,\\vec{x}_2,\\vec{x}_3)$, con $\\vec{x}_i \\in \\mathbb{R}^{d_x}$ y $d_x=2$.\n",
        "\n",
        "Tenemos una red recurrente *Elman* definidad como: \n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_i &= R_{SRNN}\\left (\\vec{x}_i, \\vec{s}_{i-1}\\right ) = g \\left (\\vec{s}_{i-1}W^s + \\vec{x}_i W^x + \\vec{b}\\right ) \\\\\n",
        "\\vec{y}_i &= O_{SRNN}\\left(\\vec{s}_i\\right) = \\vec{s}_i \\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "donde\n",
        "\\begin{equation}\n",
        "\\vec{s}_i, \\vec{y}_i \\in \\mathbb{R}^{d_s}, \\quad W^x \\in \\mathbb{R}^{d_x \\times d_s}, \\quad W^s \\in \\mathbb{R}^{d_s \\times d_s}, \\quad \\vec{b} \\in \\mathbb{R}^{d_s},\n",
        "\\end{equation}\n",
        "y los vectores de estado $s_i$ son de tres dimensiones, $ds= 3$.\n",
        "\n",
        "Sea\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_0 &= [0,0,0]\\\\\n",
        "W^x &= \\begin{pmatrix}\n",
        "0 &  0 & 1\\\\\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix} \\\\\n",
        "W^s &= \\begin{pmatrix}\n",
        "1 & 0 &  1\\\\\n",
        "0 & 1 & -1\\\\\n",
        "1 & 1 &  1\n",
        "\\end{pmatrix} \\\\\n",
        "\\vec{b} &= [0, 0, 0] \\\\\n",
        "g(x) &= ReLu(x) = max(0, x)\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "<br>\n",
        "\n",
        "Calcule manualmente los valores de los vectores $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ y de $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fim2W8JioPhL"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "`Escriba su respuesta aqu√≠`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W4rAT6ELxRZW"
      },
      "source": [
        "### Pregunta 5 (0.5 puntos)\n",
        "¬øDe qu√© forma las RNN y las CNN logran aprender representaciones espec√≠ficas\n",
        "para la tarea objetivo? Compare la forma en que las RNN y las CNN aprenden con los modelos que usan *features* dise√±adas manualmente."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b6AXbQSgA_t8"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "`Escriba su respuesta aqu√≠`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FRJkBpjWyHnb"
      },
      "source": [
        "# Pregunta 6: Redes Neuronales con Pytorch (3 puntos) üí¨\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.anda.cl/wp-content/uploads/2021/03/0_5vNAtimPjYQr4W72.gif\" alt=\"chatbot\" width=\"400\">\n",
        "</center>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GEla92bUymrQ"
      },
      "source": [
        "En esta secci√≥n de la tarea deber√°n implementar un Chatbot que sea capaz de generar una conversaci√≥n *‚Äúb√°sica‚Äù* utilizando un dataset de *Star Wars*. **El objetivo** de esta pregunta es que puedan aplicar lo aprendido sobre redes neuronales utilizando Pytorch en un ejemplo pr√°ctico.  Durante el desarrollo, se espera que puedan dise√±ar un bot (que tendr√° por atr√°s un clasificador) que sea capaz de clasificar diferentes etiquetas, cosa que una vez identificada la etiqueta entregue una respuesta acorde a lo preguntado.\n",
        "\n",
        "**Aviso:** Antes de comenzar con una descripci√≥n mas profunda de esta secci√≥n, les recomendamos que visualicen y se familiaricen con el dataset entregado, de esta forma comprender√°n mejor la descripci√≥n del enunciado (aqu√≠ una peque√±a ayudita üÜò)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eKOGlMs3Dx-",
        "outputId": "376ced9d-b74d-499a-feb1-67e9574e77ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de tags:  16\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "example_data = pd.read_json('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json')\n",
        "print(\"Cantidad de tags: \", example_data['intents'].shape[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V-6fCE5fHkNS"
      },
      "source": [
        "A continuaci√≥n, ejemplos del contenido del primer registro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axsi27BpHGOx",
        "outputId": "883da5bd-7f10-4a3c-da8d-6e50357413ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'Hey',\n",
              " 'How are you',\n",
              " 'Is anyone there?',\n",
              " 'Hello',\n",
              " 'Good day',\n",
              " \"What's up\",\n",
              " 'Yo!',\n",
              " 'Howdy',\n",
              " 'Nice to meet you.']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_data['intents'][0]['patterns']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV0vGdwoHeg3",
        "outputId": "327fc95d-7dd8-4fa2-a410-1a2225661bcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'Hello, thanks for visiting.',\n",
              " 'Hi there, what can I do for you?',\n",
              " 'Hi there, how can I help?',\n",
              " 'Hello, there.',\n",
              " 'Hello Dear',\n",
              " 'Ooooo Hello, looking for someone or something?',\n",
              " 'Yes, I am here.',\n",
              " 'Listening carefully.',\n",
              " 'Ok, I am with you.']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_data['intents'][0]['responses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0BnYez1oGtx3",
        "outputId": "dd0e649f-cdad-4f57-f848-384c688d38fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'greeting'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_data['intents'][0]['tag']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v6BvAWCw3zPM"
      },
      "source": [
        "Del dataset cargado podemos notar que este viene en un formato `JSON`, por lo que sus datos est√°n almacenados en diccionarios. Las llaves de los diccionarios no son aleatorias y estos nos sirven para identificar puntos relevantes en el desarrollo del bot. A continuaci√≥n, se realiza una peque√±a descripci√≥n de las llaves:\n",
        "\n",
        "- `patterns`: Almacena los patrones con los que entrenaremos el modelo üòÆ, en otras palabras, es el corpus de entrenamiento que contiene solo preguntas o expresiones que deber√° responder el bot.\n",
        "- `responses`: Son las respuestas üôã relacionadas a los `patterns`, estas las utilizaremos en una etapa posterior a la clasificaci√≥n, para dar una respuesta aleator√≠a al usuario.\n",
        "- `tag`: Son las labels con las que entrenaremos nuestro modelo üíª. \n",
        "\n",
        "En s√≠ntesis, las `keys` relevantes para el entrenamiento de nuestra red neuronal ser√°n `patterns` (corpus) y `tag` (etiquetas)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KlOAdMjSSzNN"
      },
      "source": [
        "#### Explicaci√≥n de la tarea a realizar:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9yGApnWVI4cO"
      },
      "source": [
        "**Explicaci√≥n de la tarea a realizar**: Implemente una Class llamada `CNNClassifier` que sea capaz de entrenar un modelo de texto a trav√©s de una red neuronal Feed Forward y una arquitectura convolucional (CNN 1D) [`torch.nn.Conv1d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#conv1d) . Para el dise√±o de las redes tienen completa libertad, pero se le aconseja que se gu√≠en de la √∫ltima auxiliar para la construcci√≥n. Es **important√≠simo** que el modelo a crear posea una capa de `Embedding` que se genere en base al entrenamiento del modelo. Creado el modelo, construya una funci√≥n batch para cargar los datos de entrenamiento del modelo.\n",
        "\n",
        "Construido el modelo, compare los resultados obtenidos para una red feed forward y una cnn. Para la comprobaci√≥n de sus resultados ejecute el chatbot y pruebelo, ¬øqu√© configuraci√≥n tiene mejores resultados?, ¬øa qu√© se deberan estos resultados?\n",
        "\n",
        "Ojo que un ejemplo de prueba con el chatbot puede ser (agregue mas preguntas ud):\n",
        "\n",
        "```\n",
        "Let's chat! (type 'finish_chat' to finish the chat)\n",
        "You: hi\n",
        "GA-97: Yes, I am here.\n",
        "You: can you tell me a joke?\n",
        "GA-97: Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.\n",
        "```\n",
        "\n",
        "El resto del c√≥digo referido a la ejecuci√≥n del chat se los entregamos, por lo que no deber√≠an tener mayores problemas üò∏ (en caso de tener problemas con su c√≥digo, puede modificar cualquier parte sugerida siempre y cuando cumpla lo solicitado).\n",
        "\n",
        "**Igual [mucho texto](https://i0.wp.com/elgeneracionalpost.com/wp-content/uploads/2020/07/mucho-texto.jpg?fit=1280%2C720&ssl=1).... En resumen, ¬øQu√© se solicita?:**\n",
        "\n",
        "- [ ] Dise√±ar una red neuronal Feed Forward.\n",
        "- [ ] Dise√±ar un red convolucional.\n",
        "- [ ] Utilizar una capa de embeddings para generar representaciones vectoriales del corpus.\n",
        "- [ ] Crear el m√©todo forward de la clase `CNNClassifier`.\n",
        "- [ ] Crear la funci√≥n BATCH.\n",
        "- [ ] Probar el modelo y comparar los resultados obtenidos con la red Feed Forward y la red CNN. Comente sus resultados de forma cualitativa, se√±alando con qu√© tipo de red obtuvo mejores resultados con el chatbot.\n",
        "\n",
        "**Nota-1:** El modelo creado debe tener la opci√≥n de entrenar a traves de una feed forward y una CNN. Esto no significa que entrenar√° una FF y una CN, el modelo deber√° recibir un booleano que especifique que tipo de red utilizar√°.\n",
        "\n",
        "**Nota-2:** El dataset se descargar√° autom√°ticamente en la secci√≥n `Carga de Dataset üìö`, no os preocup√©is."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a4bKfAdEy3oD"
      },
      "source": [
        "#### Pasemos al C√≥digo ü¶æ\n",
        "\n",
        "Esqueleto propuesto (se **RECOMIENDA** que cambien **SOLO** la red neuronal y la funci√≥n Batch) ü¶¥:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RUwxivx2MpMV"
      },
      "source": [
        "##### Instalamos librerias necesarias e importamos üòÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TjSZkBsk1H4f"
      },
      "outputs": [],
      "source": [
        "# Esto toma su tiempo en ejecutarse\n",
        "#%%capture\n",
        "#!pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RfZ6SL-Q1Kwd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from random import choice\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from itertools import zip_longest\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oj-Epe7XJLrL"
      },
      "source": [
        "##### Carga de Dataset üìö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvlLqYRrVN6l",
        "outputId": "e6817cb7-ac85-471a-f426-f07537f357b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-06-19 09:04:02--  https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14469 (14K) [text/plain]\n",
            "Saving to: ‚Äòstar_wars_chatbot.json‚Äô\n",
            "\n",
            "star_wars_chatbot.j 100%[===================>]  14,13K  --.-KB/s    in 0,002s  \n",
            "\n",
            "2023-06-19 09:04:02 (6,10 MB/s) - ‚Äòstar_wars_chatbot.json‚Äô saved [14469/14469]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# we obtain the dataset\n",
        "!wget 'https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbbIsFUG1TXW",
        "outputId": "7ad12487-4295-4f5f-a3b2-c9e50729f680"
      },
      "outputs": [],
      "source": [
        "# Load the dataset using json\n",
        "with open('star_wars_chatbot.json', 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Create a vocab with the dataset and get the number of classes that have\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "vocab = build_vocab_from_iterator(tokenizer(x) for list_words in dataset['intents'] for x in list_words['patterns'])\n",
        "num_classes = len(dataset['intents'])\n",
        "\n",
        "#stoi = vocab.get_stoi()\n",
        "\n",
        "\n",
        "# Define a list with the labels\n",
        "labels = sorted(set([tag for tag in [intents['tag'] for intents in dataset['intents']]]))\n",
        "# Define a train_list where we can find the info in the format: [(tag_0, text_0)...,(tag_n-1, text_n-1)]\n",
        "train_list = [(labels.index(intents['tag']), text) for intents in dataset['intents'] for text in intents['patterns']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(7, 'Hi'),\n",
              " (7, 'Hey'),\n",
              " (7, 'How are you'),\n",
              " (7, 'Is anyone there?'),\n",
              " (7, 'Hello'),\n",
              " (7, 'Good day'),\n",
              " (7, \"What's up\"),\n",
              " (7, 'Yo!'),\n",
              " (7, 'Howdy'),\n",
              " (7, 'Nice to meet you.'),\n",
              " (6, 'Bye'),\n",
              " (6, 'See you later.'),\n",
              " (6, 'Goodbye'),\n",
              " (6, 'Have a great day.'),\n",
              " (6, 'See you next time.')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_list[0:15]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a52SUNKPJQxi"
      },
      "source": [
        "##### Creaci√≥n del modelo (2 puntos en total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "n-vQ24tMJG5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from itertools import zip_longest\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Construya el modelo\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=32, num_classes=10, \n",
        "                 use_cnn=True, cnn_pool_channels=24, cnn_kernel_size=3):\n",
        "      \n",
        "      super().__init__()\n",
        "\n",
        "      # Creamos la capa de embedding\n",
        "      self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "      # Creamos la capa de convoluci√≥n\n",
        "      # `in_channels`: Es el n√∫mero de canales de entrada de la convoluci√≥n. En este caso, como estamos trabajando con texto, s√≥lo tenemos un canal, por lo que `in_channels=1`.\n",
        "      # `out_channels`: Es el n√∫mero de canales de salida de la convoluci√≥n. Especifica la cantidad de filtros que se aplicar√°n a la entrada. En este caso, queremos generar `cnn_pool_channels` canales de salida, por lo que `out_channels=cnn_pool_channels`.\n",
        "      # `kernel_size`: Es el tama√±o del kernel de la convoluci√≥n. En este caso, estamos usando un kernel de tama√±o `cnn_kernel_size * embed_dim`, donde `embed_dim` es la dimensi√≥n de los vectores de embedding. Esto significa que cada filtro de la convoluci√≥n cubrir√° `cnn_kernel_size` palabras (o tokens) en una dimensi√≥n y `embed_dim` en la otra.\n",
        "      # `stride`: Es el desplazamiento que se aplica a la entrada de la convoluci√≥n. En este caso, estamos desplazando la entrada `embed_dim` unidades en cada paso. Esto significa que se aplicar√°n filtros a cada palabra (o token) de la entrada.\n",
        "      self.conv = nn.Conv1d(\n",
        "          in_channels=1,\n",
        "          out_channels=cnn_pool_channels,\n",
        "          kernel_size=cnn_kernel_size * embed_dim,\n",
        "          stride=embed_dim)\n",
        "      \n",
        "      # Calculamos el tama√±o de entrada de la capa lineal\n",
        "      fc_in_size = cnn_pool_channels\n",
        "\n",
        "      # Creamos la capa lineal\n",
        "      self.fc = nn.Linear(fc_in_size, num_classes)\n",
        "\n",
        "      # Inicializamos los pesos de las capas\n",
        "      self.init_weights()\n",
        "      \n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        # Definimos el rango de los valores iniciales de los pesos\n",
        "        initrange = 0.5\n",
        "\n",
        "        # Inicializamos los pesos de la capa de embedding\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "        # Inicializamos los pesos de la capa lineal\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "        # Inicializamos los sesgos de la capa lineal en cero\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "       \n",
        "               # Preparamos el input de la capa de embeddings a partir de text y offsets\n",
        "        text = torch.tensor(\n",
        "            list(\n",
        "                zip(\n",
        "                    *zip_longest(\n",
        "                        *([text[o:offsets[i+1]] for i, o in enumerate(offsets[:-1])] + [text[offsets[-1]:len(texts)]]),\n",
        "                        fillvalue=vocab[\"<pad>\"]\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        ).to(text.device)\n",
        "\n",
        "        # Obtenemos la representaci√≥n de la frase a partir de la capa de embedding\n",
        "        h = self.embedding(text)\n",
        "\n",
        "        # Aplicamos la capa de convoluci√≥n\n",
        "        h = h.view(h.size(0), 1, -1)\n",
        "        h = torch.relu(self.conv(h))\n",
        "        h = h.mean(dim=2)\n",
        "\n",
        "        # Obtenemos el resultado final a partir de la capa lineal\n",
        "        output = self.fc(h)\n",
        "\n",
        "        # Aplicamos la funci√≥n de activaci√≥n log-softmax\n",
        "        return F.log_softmax(output, dim=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dGN-T0JoJtmS"
      },
      "source": [
        "##### Funci√≥n Batch üë∑ (0,5 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K1AZpXc7JxTa"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def generate_batch(batch):\n",
        "  label = torch.tensor([entry[0]-1 for entry in batch])\n",
        "  texts = [tokenizer(entry[1]) for entry in batch]\n",
        "  offsets = [0] + [len(text) for text in texts]\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  big_text = torch.cat([torch.tensor([vocab[t] if t in stoi else 0 for t in text]) for text in texts])\n",
        "  #big_text = torch.cat([torch.tensor([vocab.stoi[t] for t in text]) for text in texts])\n",
        "\n",
        "  return big_text, offsets, label"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YChwpNrrNRBe"
      },
      "source": [
        "##### Entrenamiento ü•ä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5eRWRD_J0Km",
        "outputId": "89f923fd-8f1d-4258-ad74-4e5915c3d53a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Token <pad> not found and default index is not set\nException raised from __getitem__ at /__w/text/text/pytorch/text/torchtext/csrc/vocab.cpp:43 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f3d9c1984d7 in /home/ismael/.local/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f3d9c16236b in /home/ismael/.local/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: torchtext::Vocab::__getitem__(c10::basic_string_view<char> const&) const + 0x384 (0x7f3ccd8c1de4 in /home/ismael/.local/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so)\nframe #3: <unknown function> + 0x1e3d7 (0x7f3d8da7d3d7 in /home/ismael/.local/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #4: <unknown function> + 0x3bde7 (0x7f3d8da9ade7 in /home/ismael/.local/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #5: <unknown function> + 0x15cc9e (0x55b3e4efcc9e in /bin/python3)\nframe #6: _PyObject_MakeTpCall + 0x25b (0x55b3e4ef372b in /bin/python3)\nframe #7: <unknown function> + 0x16b1eb (0x55b3e4f0b1eb in /bin/python3)\nframe #8: <unknown function> + 0x1c6081 (0x55b3e4f66081 in /bin/python3)\nframe #9: <unknown function> + 0x1c5b5e (0x55b3e4f65b5e in /bin/python3)\nframe #10: _PyEval_EvalFrameDefault + 0xcaf (0x55b3e4ee5fff in /bin/python3)\nframe #11: <unknown function> + 0x1c5d2e (0x55b3e4f65d2e in /bin/python3)\nframe #12: <unknown function> + 0x1c5b5e (0x55b3e4f65b5e in /bin/python3)\nframe #13: _PyEval_EvalFrameDefault + 0xcaf (0x55b3e4ee5fff in /bin/python3)\nframe #14: <unknown function> + 0x16b05e (0x55b3e4f0b05e in /bin/python3)\nframe #15: _PyEval_EvalFrameDefault + 0x2a37 (0x55b3e4ee7d87 in /bin/python3)\nframe #16: _PyObject_FastCallDictTstate + 0xc4 (0x55b3e4ef28b4 in /bin/python3)\nframe #17: _PyObject_Call_Prepend + 0x5c (0x55b3e4f07f9c in /bin/python3)\nframe #18: <unknown function> + 0x285050 (0x55b3e5025050 in /bin/python3)\nframe #19: _PyObject_MakeTpCall + 0x25b (0x55b3e4ef372b in /bin/python3)\nframe #20: _PyEval_EvalFrameDefault + 0x67dc (0x55b3e4eebb2c in /bin/python3)\nframe #21: <unknown function> + 0x142176 (0x55b3e4ee2176 in /bin/python3)\nframe #22: PyEval_EvalCode + 0x86 (0x55b3e4fd7c56 in /bin/python3)\nframe #23: <unknown function> + 0x23d93d (0x55b3e4fdd93d in /bin/python3)\nframe #24: <unknown function> + 0x15d749 (0x55b3e4efd749 in /bin/python3)\nframe #25: _PyEval_EvalFrameDefault + 0x6cd (0x55b3e4ee5a1d in /bin/python3)\nframe #26: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #27: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #28: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #29: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #30: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #31: <unknown function> + 0x25985f (0x55b3e4ff985f in /bin/python3)\nframe #32: <unknown function> + 0x1689fa (0x55b3e4f089fa in /bin/python3)\nframe #33: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #34: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #35: _PyEval_EvalFrameDefault + 0x6cd (0x55b3e4ee5a1d in /bin/python3)\nframe #36: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #37: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #38: <unknown function> + 0x16af11 (0x55b3e4f0af11 in /bin/python3)\nframe #39: PyObject_Call + 0x122 (0x55b3e4f0bbc2 in /bin/python3)\nframe #40: _PyEval_EvalFrameDefault + 0x2a37 (0x55b3e4ee7d87 in /bin/python3)\nframe #41: <unknown function> + 0x16af11 (0x55b3e4f0af11 in /bin/python3)\nframe #42: _PyEval_EvalFrameDefault + 0x1a1b (0x55b3e4ee6d6b in /bin/python3)\nframe #43: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #44: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #45: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #46: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #47: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #48: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #49: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #50: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #51: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #52: <unknown function> + 0x962e (0x7f3da2e7862e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #53: <unknown function> + 0xaf6b (0x7f3da2e79f6b in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #54: <unknown function> + 0x15c6b4 (0x55b3e4efc6b4 in /bin/python3)\nframe #55: <unknown function> + 0x239845 (0x55b3e4fd9845 in /bin/python3)\nframe #56: <unknown function> + 0x2ea682 (0x55b3e508a682 in /bin/python3)\nframe #57: <unknown function> + 0x15062b (0x55b3e4ef062b in /bin/python3)\nframe #58: _PyEval_EvalFrameDefault + 0x2a37 (0x55b3e4ee7d87 in /bin/python3)\nframe #59: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #60: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #61: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #62: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #63: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb Cell 38\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m output \u001b[39m=\u001b[39m model(texts, offsets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, \u001b[39mcls\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb Cell 38\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, text, offsets):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m    \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m            \u001b[39m# Preparamos el input de la capa de embeddings a partir de text y offsets\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     text \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         \u001b[39mlist\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m             \u001b[39mzip\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m                 \u001b[39m*\u001b[39mzip_longest(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m                     \u001b[39m*\u001b[39m([text[o:offsets[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]] \u001b[39mfor\u001b[39;00m i, o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(offsets[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])] \u001b[39m+\u001b[39m [text[offsets[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\u001b[39mlen\u001b[39m(texts)]]),\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                     fillvalue\u001b[39m=\u001b[39mvocab[\u001b[39m\"\u001b[39;49m\u001b[39m<pad>\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                 )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m             )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     )\u001b[39m.\u001b[39mto(text\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39m# Obtenemos la representaci√≥n de la frase a partir de la capa de embedding\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ismael/Desktop/NLP/Tarea_4/Tarea_4_enunciado.ipynb#X52sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(text)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtext/vocab/vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mexport\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, token: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m     58\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab[token]\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Token <pad> not found and default index is not set\nException raised from __getitem__ at /__w/text/text/pytorch/text/torchtext/csrc/vocab.cpp:43 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f3d9c1984d7 in /home/ismael/.local/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f3d9c16236b in /home/ismael/.local/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: torchtext::Vocab::__getitem__(c10::basic_string_view<char> const&) const + 0x384 (0x7f3ccd8c1de4 in /home/ismael/.local/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so)\nframe #3: <unknown function> + 0x1e3d7 (0x7f3d8da7d3d7 in /home/ismael/.local/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #4: <unknown function> + 0x3bde7 (0x7f3d8da9ade7 in /home/ismael/.local/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #5: <unknown function> + 0x15cc9e (0x55b3e4efcc9e in /bin/python3)\nframe #6: _PyObject_MakeTpCall + 0x25b (0x55b3e4ef372b in /bin/python3)\nframe #7: <unknown function> + 0x16b1eb (0x55b3e4f0b1eb in /bin/python3)\nframe #8: <unknown function> + 0x1c6081 (0x55b3e4f66081 in /bin/python3)\nframe #9: <unknown function> + 0x1c5b5e (0x55b3e4f65b5e in /bin/python3)\nframe #10: _PyEval_EvalFrameDefault + 0xcaf (0x55b3e4ee5fff in /bin/python3)\nframe #11: <unknown function> + 0x1c5d2e (0x55b3e4f65d2e in /bin/python3)\nframe #12: <unknown function> + 0x1c5b5e (0x55b3e4f65b5e in /bin/python3)\nframe #13: _PyEval_EvalFrameDefault + 0xcaf (0x55b3e4ee5fff in /bin/python3)\nframe #14: <unknown function> + 0x16b05e (0x55b3e4f0b05e in /bin/python3)\nframe #15: _PyEval_EvalFrameDefault + 0x2a37 (0x55b3e4ee7d87 in /bin/python3)\nframe #16: _PyObject_FastCallDictTstate + 0xc4 (0x55b3e4ef28b4 in /bin/python3)\nframe #17: _PyObject_Call_Prepend + 0x5c (0x55b3e4f07f9c in /bin/python3)\nframe #18: <unknown function> + 0x285050 (0x55b3e5025050 in /bin/python3)\nframe #19: _PyObject_MakeTpCall + 0x25b (0x55b3e4ef372b in /bin/python3)\nframe #20: _PyEval_EvalFrameDefault + 0x67dc (0x55b3e4eebb2c in /bin/python3)\nframe #21: <unknown function> + 0x142176 (0x55b3e4ee2176 in /bin/python3)\nframe #22: PyEval_EvalCode + 0x86 (0x55b3e4fd7c56 in /bin/python3)\nframe #23: <unknown function> + 0x23d93d (0x55b3e4fdd93d in /bin/python3)\nframe #24: <unknown function> + 0x15d749 (0x55b3e4efd749 in /bin/python3)\nframe #25: _PyEval_EvalFrameDefault + 0x6cd (0x55b3e4ee5a1d in /bin/python3)\nframe #26: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #27: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #28: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #29: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #30: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #31: <unknown function> + 0x25985f (0x55b3e4ff985f in /bin/python3)\nframe #32: <unknown function> + 0x1689fa (0x55b3e4f089fa in /bin/python3)\nframe #33: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #34: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #35: _PyEval_EvalFrameDefault + 0x6cd (0x55b3e4ee5a1d in /bin/python3)\nframe #36: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #37: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #38: <unknown function> + 0x16af11 (0x55b3e4f0af11 in /bin/python3)\nframe #39: PyObject_Call + 0x122 (0x55b3e4f0bbc2 in /bin/python3)\nframe #40: _PyEval_EvalFrameDefault + 0x2a37 (0x55b3e4ee7d87 in /bin/python3)\nframe #41: <unknown function> + 0x16af11 (0x55b3e4f0af11 in /bin/python3)\nframe #42: _PyEval_EvalFrameDefault + 0x1a1b (0x55b3e4ee6d6b in /bin/python3)\nframe #43: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #44: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #45: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #46: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #47: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #48: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #49: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #50: _PyEval_EvalFrameDefault + 0x287f (0x55b3e4ee7bcf in /bin/python3)\nframe #51: <unknown function> + 0x17a640 (0x55b3e4f1a640 in /bin/python3)\nframe #52: <unknown function> + 0x962e (0x7f3da2e7862e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #53: <unknown function> + 0xaf6b (0x7f3da2e79f6b in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #54: <unknown function> + 0x15c6b4 (0x55b3e4efc6b4 in /bin/python3)\nframe #55: <unknown function> + 0x239845 (0x55b3e4fd9845 in /bin/python3)\nframe #56: <unknown function> + 0x2ea682 (0x55b3e508a682 in /bin/python3)\nframe #57: <unknown function> + 0x15062b (0x55b3e4ef062b in /bin/python3)\nframe #58: _PyEval_EvalFrameDefault + 0x2a37 (0x55b3e4ee7d87 in /bin/python3)\nframe #59: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #60: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #61: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\nframe #62: _PyEval_EvalFrameDefault + 0x8c4 (0x55b3e4ee5c14 in /bin/python3)\nframe #63: _PyFunction_Vectorcall + 0x7c (0x55b3e4efd4ec in /bin/python3)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"GPU is avaible: {device}\")\n",
        "\n",
        "# Define the different inputs in our model\n",
        "num_epochs = 1000\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-1\n",
        "INPUT_SIZE = len(vocab)\n",
        "OUTPUT_SIZE = num_classes\n",
        "USE_CNN = False\n",
        "\n",
        "# Define model, optimizer, loss and scheduler (Q: ¬øWhat is it?)\n",
        "model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n",
        "optimizer = SGD(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n",
        "\n",
        "print(f'train: {len(train_list)} elements')\n",
        "\n",
        "# We train the model using the intents\n",
        "loss_list= []\n",
        "for epoch in range(1, num_epochs):\n",
        "  train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for i, (texts, offsets, cls) in enumerate(train_loader):\n",
        "    texts = texts.to(device)\n",
        "    offsets = offsets.to(device)\n",
        "    cls = cls.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(texts, offsets)\n",
        "    loss = criterion(output, cls)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  loss_list.append(loss.item())\n",
        "  sys.stdout.write('\\rEpoch: {0:03d} \\t iter-Loss: {1:.3f}'.format(epoch+1, loss.item()))\n",
        "\n",
        "print(f'final loss: {loss.item():.4f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9dlS4_X-L3DN"
      },
      "source": [
        "##### A probar! üß™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6IhhAKFXL3eH",
        "outputId": "6a28628b-d2d0-4bf0-9479-ccabbef085e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'funny'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is working?, Try the next example!\n",
        "qText = \"'Do you know any joke?'\" # this must classify the label \"funny\"\n",
        "\n",
        "X = torch.tensor([vocab.stoi[t] for t in tokenizer(qText)]).to(device)\n",
        "\n",
        "model.eval()\n",
        "output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n",
        "_, predicted = torch.max(output, dim=1)\n",
        "labels[predicted]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "udemze3zL549"
      },
      "source": [
        "Ya pero prometiste hacer un chatbot, no una simple clasificaci√≥n.... "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OpSYGx2tL0tC"
      },
      "source": [
        "##### Guardamos modelo ü¶∫ (opcional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBC4TyiqLzDv",
        "outputId": "0a743164-69aa-4b6e-a219-37da8ea699bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete. file saved to data.pth\n"
          ]
        }
      ],
      "source": [
        "# We save de model using pytorch (this is optional, just to learn how to do this in pytorch)\n",
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": INPUT_SIZE,\n",
        "\"output_size\": OUTPUT_SIZE,\n",
        "\"use_cnn\": USE_CNN,\n",
        "\"labels\": labels\n",
        "        }\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(f'training complete. file saved to {FILE}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYClbTtsMCjE"
      },
      "source": [
        "##### Chatbot üí¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c249zUwiMBxb",
        "outputId": "03d5c400-9860-4ea1-b8c6-f711067d2727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hi\n",
            "GA-97: Yes, I am here.\n",
            "You: can you tell me a joke?\n",
            "GA-97: Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.\n",
            "You: exit\n",
            "GA-97: Hello Dear\n",
            "You: finish_chat\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with open('star_wars_chatbot.json', 'r') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "INPUT_SIZE = data[\"input_size\"]\n",
        "OUTPUT_SIZE = data[\"output_size\"]\n",
        "USE_CNN = data[\"use_cnn\"]\n",
        "labels = data['labels']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n",
        "\n",
        "# Dictionary with the answers\n",
        "responses = {key['tag']: key['responses'] for key in dataset['intents']}\n",
        "\n",
        "bot_name = \"GA-97\"\n",
        "print(\"Let's chat! (type 'finish_chat' to finish the chat)\")\n",
        "while True:\n",
        "    q_text = input(\"You: \")\n",
        "    q_text = q_text\n",
        "    if q_text == 'finish_chat':\n",
        "        break\n",
        "\n",
        "    X = torch.tensor([vocab.stoi[t] for t in tokenizer(q_text)]).to(device)\n",
        "    output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = labels[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.50:\n",
        "      print(f\"{bot_name}: {random.choice(responses[tag])}\")\n",
        "    else:\n",
        "      print(f\"{bot_name}: My model can't understand you...\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hu2QTuSURCt"
      },
      "source": [
        "#### Comente los resultados aqu√≠ (0,5 puntos)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fdFV63WVUX32"
      },
      "source": [
        "``Comente los resultados aqu√≠``"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
