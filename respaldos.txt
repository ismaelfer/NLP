        self.alpha = alpha
        self.classes_ = None
        self.class_count_ = None
        self.feature_count_ = None
        self.feature_log_prob_ = None
        self.class_log_prior_ = None
        self.n_features_ = None
        self.n_classes_ = None
        self.n_samples = None
    
    def fit(self, X, y):
        X, y = check_X_y(X, y, accept_sparse='csr')
        self.n_samples = X.shape[0]
        self.n_features_ = X.shape[1]
        self.classes_ = np.unique(y)
        self.n_classes_ = len(self.classes_)
        self.class_count_ = np.zeros(self.n_classes_)
        self.feature_count_ = np.zeros((self.n_classes_, self.n_features_))
        self.feature_log_prob_ = np.zeros((self.n_classes_, self.n_features_))
        self.class_log_prior_ = np.zeros(self.n_classes_)
        for i in range(self.n_samples):
            self.class_count_[y[i]] += 1
            self.feature_count_[y[i]] += X[i]
            self.feature_log_prob_ = np.log((self.feature_count_ + self.alpha) / (self.class_count_[:, np.newaxis] + self.alpha * self.n_features_))
            self.class_log_prior_ = np.log(self.class_count_ / self.n_samples)
        return self
    
    def predict(self, X):
        X = check_array(X, accept_sparse='csr')
        return self.classes_[np.argmax(self.predict_log_proba(X), axis=1)]
    
    def predict_log_proba(self, X):
        X = check_array(X, accept_sparse='csr')
        jll = safe_sparse_dot(X, self.feature_log_prob_.T)
        jll += self.class_log_prior_
        return jll
    
    def predict_proba(self, X):
        return np.exp(self.predict_log_proba(X))
    
    def score(self, X, y):
        return np.mean(self.predict(X) == y)
    
    def get_params(self, deep=True):
        return {"alpha": self.alpha}
    
    def set_params(self, **parameters):
        for parameter, value in parameters.items():
            setattr(self, parameter, value)
        return self

----------------------------------------------------------------------------------------

from sklearn.base import BaseEstimator, ClassifierMixin
import numpy as np

#Naive bayes multinomial classifier
class MyMultinomialNB(BaseEstimator, ClassifierMixin):

    def __init__(self, alpha=1.0):
        self.alpha = alpha
        self.classes = None
        self.n_classes = None
        self.n_features = None
        self.n_samples = None
        self.n_samples_class = None
        self.prior = None
        self.likelihood = None

    def fit(self, X, y):
        self.classes = np.unique(y)
        self.n_classes = len(self.classes)
        self.n_features = X.shape[1]
        self.n_samples = X.shape[0]
        
        self.n_samples_class = np.zeros(self.n_classes)
        self.prior = np.zeros(self.n_classes)
        self.likelihood = np.zeros((self.n_classes, self.n_features))

        for i in range(self.n_classes):
            X_i = X[y == self.classes[i]]
            self.n_samples_class[i] = X_i.shape[0]
            self.prior[i] = self.n_samples_class[i] / self.n_samples
            self.likelihood[i] = (np.sum(X_i, axis=0) + self.alpha) / (np.sum(X_i) + self.alpha * self.n_features)
        return self
    

    def predict(self, X):
        n_samples = X.shape[0]
        y_pred = np.zeros(n_samples)
        for i in range(n_samples):
            y_pred[i] = self.classes[np.argmax(np.log(self.prior) + np.sum(np.log(self.likelihood) * X[i], axis=1))]
        return y_pred
        